{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bjjSfkZ9K30",
        "outputId": "7ee1c80b-ebcf-4cb5-f3b7-b268b042a763"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Learning-With-Retrospection'...\n",
            "remote: Enumerating objects: 112, done.\u001b[K\n",
            "remote: Counting objects: 100% (112/112), done.\u001b[K\n",
            "remote: Compressing objects: 100% (84/84), done.\u001b[K\n",
            "remote: Total 112 (delta 44), reused 41 (delta 17), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (112/112), 95.99 KiB | 24.00 MiB/s, done.\n",
            "Resolving deltas: 100% (44/44), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/meetgandhi123/Learning-With-Retrospection\n",
        "# !cd Learning-With-Retrospection/ && git pull && cd ..\n",
        "# !pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGvUsjAz_L2u"
      },
      "source": [
        "# ResNet56"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wj4gybsw_TiH"
      },
      "source": [
        "## CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPQapp7P8RiC",
        "outputId": "706de916-b64e-440f-d45a-1e25c8429498"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==> Preparing dataset: cifar10\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /root/data/cifar-10-python.tar.gz\n",
            "100% 170498071/170498071 [00:02<00:00, 64869284.26it/s]\n",
            "Extracting /root/data/cifar-10-python.tar.gz to /root/data/\n",
            "Files already downloaded and verified\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Number of train dataset:  50000\n",
            "Number of validation dataset:  10000\n",
            "==> Building model: resnet56\n",
            "1\n",
            "Using CUDA..\n",
            "[2022-11-10 17:15:27,684] [main] Learning-With-Retrospection/CS-KD_techinque/cs-kd/train.py --sgpu 0 --lr 0.1 --epoch 200 --model resnet56 --name cifar10_resnet56 --decay 1e-4 --dataset cifar10 --dataroot /root/data/ -cls --lamda 1\n",
            "[2022-11-10 17:15:27,684] [main] Namespace(batch_size=128, cls=True, dataroot='/root/data/', dataset='cifar10', decay=0.0001, epoch=200, lamda=1.0, lr=0.1, model='resnet56', name='cifar10_resnet56', ngpu=1, resume=False, saveroot='./results', sgpu=0, temp=4.0)\n",
            "\n",
            "Epoch: 0\n",
            " [=====================================================================================>]  Step: 167ms | Tot: 45s430ms | Loss: 2.186 | Acc: 22.950% (11475/50000) | Cls: 0.319  391/391 \n",
            "[2022-11-10 17:16:20,468] [train] [Epoch 0] [Loss 2.186] [cls 0.319] [Acc 22.950]\n",
            " [====================================================================================>.]  Step: 28ms | Tot: 2s585ms | Loss: 1.926 | Acc: 31.210% (3121/10000)  79/79 \n",
            "[2022-11-10 17:16:23,393] [val] [Epoch 0] [Loss 1.926] [Acc 31.210]\n",
            "Saving..\n",
            "\n",
            "Epoch: 1\n",
            " [=====================================================================================>]  Step: 82ms | Tot: 46s609ms | Loss: 1.851 | Acc: 34.422% (17211/50000) | Cls: 0.236  391/391 \n",
            "[2022-11-10 17:17:10,804] [train] [Epoch 1] [Loss 1.851] [cls 0.236] [Acc 34.422]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s550ms | Loss: 1.728 | Acc: 38.820% (3882/10000)  79/79 \n",
            "[2022-11-10 17:17:13,677] [val] [Epoch 1] [Loss 1.728] [Acc 38.820]\n",
            "Saving..\n",
            "\n",
            "Epoch: 2\n",
            " [=====================================================================================>]  Step: 81ms | Tot: 46s12ms | Loss: 1.718 | Acc: 40.072% (20036/50000) | Cls: 0.285  391/391 \n",
            "[2022-11-10 17:18:00,627] [train] [Epoch 2] [Loss 1.718] [cls 0.285] [Acc 40.072]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s540ms | Loss: 1.677 | Acc: 42.170% (4217/10000)  79/79 \n",
            "[2022-11-10 17:18:03,536] [val] [Epoch 2] [Loss 1.677] [Acc 42.170]\n",
            "Saving..\n",
            "\n",
            "Epoch: 3\n",
            " [=====================================================================================>]  Step: 72ms | Tot: 47s271ms | Loss: 1.583 | Acc: 46.076% (23038/50000) | Cls: 0.332  391/391 \n",
            "[2022-11-10 17:18:51,697] [train] [Epoch 3] [Loss 1.583] [cls 0.332] [Acc 46.076]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s499ms | Loss: 1.500 | Acc: 50.900% (5090/10000)  79/79 \n",
            "[2022-11-10 17:18:54,579] [val] [Epoch 3] [Loss 1.500] [Acc 50.900]\n",
            "Saving..\n",
            "\n",
            "Epoch: 4\n",
            " [=====================================================================================>]  Step: 78ms | Tot: 46s387ms | Loss: 1.435 | Acc: 52.410% (26205/50000) | Cls: 0.374  391/391 \n",
            "[2022-11-10 17:19:41,782] [train] [Epoch 4] [Loss 1.435] [cls 0.374] [Acc 52.410]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s610ms | Loss: 1.378 | Acc: 55.590% (5559/10000)  79/79 \n",
            "[2022-11-10 17:19:44,707] [val] [Epoch 4] [Loss 1.378] [Acc 55.590]\n",
            "Saving..\n",
            "\n",
            "Epoch: 5\n",
            " [=====================================================================================>]  Step: 77ms | Tot: 47s3ms | Loss: 1.281 | Acc: 58.616% (29308/50000) | Cls: 0.405  391/391 \n",
            "[2022-11-10 17:20:32,546] [train] [Epoch 5] [Loss 1.281] [cls 0.405] [Acc 58.616]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s624ms | Loss: 1.209 | Acc: 60.070% (6007/10000)  79/79 \n",
            "[2022-11-10 17:20:35,513] [val] [Epoch 5] [Loss 1.209] [Acc 60.070]\n",
            "Saving..\n",
            "\n",
            "Epoch: 6\n",
            " [=====================================================================================>]  Step: 78ms | Tot: 46s503ms | Loss: 1.158 | Acc: 63.044% (31522/50000) | Cls: 0.425  391/391 \n",
            "[2022-11-10 17:21:22,848] [train] [Epoch 6] [Loss 1.158] [cls 0.425] [Acc 63.044]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s654ms | Loss: 1.072 | Acc: 64.730% (6473/10000)  79/79 \n",
            "[2022-11-10 17:21:25,815] [val] [Epoch 6] [Loss 1.072] [Acc 64.730]\n",
            "Saving..\n",
            "\n",
            "Epoch: 7\n",
            " [=====================================================================================>]  Step: 73ms | Tot: 46s119ms | Loss: 1.057 | Acc: 67.098% (33549/50000) | Cls: 0.438  391/391 \n",
            "[2022-11-10 17:22:12,625] [train] [Epoch 7] [Loss 1.057] [cls 0.438] [Acc 67.098]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s562ms | Loss: 0.966 | Acc: 69.390% (6939/10000)  79/79 \n",
            "[2022-11-10 17:22:15,541] [val] [Epoch 7] [Loss 0.966] [Acc 69.390]\n",
            "Saving..\n",
            "\n",
            "Epoch: 8\n",
            " [=====================================================================================>]  Step: 76ms | Tot: 47s175ms | Loss: 0.973 | Acc: 70.404% (35202/50000) | Cls: 0.438  391/391 \n",
            "[2022-11-10 17:23:03,394] [train] [Epoch 8] [Loss 0.973] [cls 0.438] [Acc 70.404]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s612ms | Loss: 0.919 | Acc: 72.240% (7224/10000)  79/79 \n",
            "[2022-11-10 17:23:06,312] [val] [Epoch 8] [Loss 0.919] [Acc 72.240]\n",
            "Saving..\n",
            "\n",
            "Epoch: 9\n",
            " [=====================================================================================>]  Step: 79ms | Tot: 45s859ms | Loss: 0.900 | Acc: 72.968% (36484/50000) | Cls: 0.441  391/391 \n",
            "[2022-11-10 17:23:53,023] [train] [Epoch 9] [Loss 0.900] [cls 0.441] [Acc 72.968]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s466ms | Loss: 0.854 | Acc: 74.210% (7421/10000)  79/79 \n",
            "[2022-11-10 17:23:55,889] [val] [Epoch 9] [Loss 0.854] [Acc 74.210]\n",
            "Saving..\n",
            "\n",
            "Epoch: 10\n",
            " [=====================================================================================>]  Step: 78ms | Tot: 46s139ms | Loss: 0.848 | Acc: 74.956% (37478/50000) | Cls: 0.436  391/391 \n",
            "[2022-11-10 17:24:42,873] [train] [Epoch 10] [Loss 0.848] [cls 0.436] [Acc 74.956]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s525ms | Loss: 0.864 | Acc: 72.620% (7262/10000)  79/79 \n",
            "[2022-11-10 17:24:45,718] [val] [Epoch 10] [Loss 0.864] [Acc 72.620]\n",
            "\n",
            "Epoch: 11\n",
            " [=====================================================================================>]  Step: 83ms | Tot: 45s967ms | Loss: 0.806 | Acc: 76.230% (38115/50000) | Cls: 0.439  391/391 \n",
            "[2022-11-10 17:25:32,436] [train] [Epoch 11] [Loss 0.806] [cls 0.439] [Acc 76.230]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s642ms | Loss: 0.796 | Acc: 75.620% (7562/10000)  79/79 \n",
            "[2022-11-10 17:25:35,401] [val] [Epoch 11] [Loss 0.796] [Acc 75.620]\n",
            "Saving..\n",
            "\n",
            "Epoch: 12\n",
            " [=====================================================================================>]  Step: 77ms | Tot: 46s411ms | Loss: 0.768 | Acc: 77.692% (38846/50000) | Cls: 0.432  391/391 \n",
            "[2022-11-10 17:26:22,713] [train] [Epoch 12] [Loss 0.768] [cls 0.432] [Acc 77.692]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s560ms | Loss: 0.809 | Acc: 74.550% (7455/10000)  79/79 \n",
            "[2022-11-10 17:26:25,659] [val] [Epoch 12] [Loss 0.809] [Acc 74.550]\n",
            "\n",
            "Epoch: 13\n",
            " [=====================================================================================>]  Step: 79ms | Tot: 46s175ms | Loss: 0.729 | Acc: 78.866% (39433/50000) | Cls: 0.430  391/391 \n",
            "[2022-11-10 17:27:12,629] [train] [Epoch 13] [Loss 0.729] [cls 0.430] [Acc 78.866]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s506ms | Loss: 0.747 | Acc: 77.930% (7793/10000)  79/79 \n",
            "[2022-11-10 17:27:15,525] [val] [Epoch 13] [Loss 0.747] [Acc 77.930]\n",
            "Saving..\n",
            "\n",
            "Epoch: 14\n",
            " [=====================================================================================>]  Step: 77ms | Tot: 47s71ms | Loss: 0.702 | Acc: 79.826% (39913/50000) | Cls: 0.425  391/391 \n",
            "[2022-11-10 17:28:03,272] [train] [Epoch 14] [Loss 0.702] [cls 0.425] [Acc 79.826]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s470ms | Loss: 0.682 | Acc: 79.770% (7977/10000)  79/79 \n",
            "[2022-11-10 17:28:06,130] [val] [Epoch 14] [Loss 0.682] [Acc 79.770]\n",
            "Saving..\n",
            "\n",
            "Epoch: 15\n",
            " [=====================================================================================>]  Step: 80ms | Tot: 45s833ms | Loss: 0.680 | Acc: 80.486% (40243/50000) | Cls: 0.423  391/391 \n",
            "[2022-11-10 17:28:52,773] [train] [Epoch 15] [Loss 0.680] [cls 0.423] [Acc 80.486]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s484ms | Loss: 0.723 | Acc: 77.270% (7727/10000)  79/79 \n",
            "[2022-11-10 17:28:55,624] [val] [Epoch 15] [Loss 0.723] [Acc 77.270]\n",
            "\n",
            "Epoch: 16\n",
            " [=====================================================================================>]  Step: 77ms | Tot: 45s961ms | Loss: 0.658 | Acc: 81.508% (40754/50000) | Cls: 0.421  391/391 \n",
            "[2022-11-10 17:29:42,372] [train] [Epoch 16] [Loss 0.658] [cls 0.421] [Acc 81.508]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s530ms | Loss: 0.689 | Acc: 79.800% (7980/10000)  79/79 \n",
            "[2022-11-10 17:29:45,303] [val] [Epoch 16] [Loss 0.689] [Acc 79.800]\n",
            "Saving..\n",
            "\n",
            "Epoch: 17\n",
            " [=====================================================================================>]  Step: 78ms | Tot: 45s730ms | Loss: 0.639 | Acc: 81.784% (40892/50000) | Cls: 0.413  391/391 \n",
            "[2022-11-10 17:30:31,882] [train] [Epoch 17] [Loss 0.639] [cls 0.413] [Acc 81.784]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s549ms | Loss: 0.644 | Acc: 80.380% (8038/10000)  79/79 \n",
            "[2022-11-10 17:30:34,789] [val] [Epoch 17] [Loss 0.644] [Acc 80.380]\n",
            "Saving..\n",
            "\n",
            "Epoch: 18\n",
            " [=====================================================================================>]  Step: 77ms | Tot: 46s413ms | Loss: 0.629 | Acc: 82.258% (41129/50000) | Cls: 0.411  391/391 \n",
            "[2022-11-10 17:31:22,039] [train] [Epoch 18] [Loss 0.629] [cls 0.411] [Acc 82.258]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s639ms | Loss: 0.705 | Acc: 79.010% (7901/10000)  79/79 \n",
            "[2022-11-10 17:31:24,998] [val] [Epoch 18] [Loss 0.705] [Acc 79.010]\n",
            "\n",
            "Epoch: 19\n",
            " [=====================================================================================>]  Step: 83ms | Tot: 45s699ms | Loss: 0.603 | Acc: 83.058% (41529/50000) | Cls: 0.410  391/391 \n",
            "[2022-11-10 17:32:11,567] [train] [Epoch 19] [Loss 0.603] [cls 0.410] [Acc 83.058]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s878ms | Loss: 0.687 | Acc: 80.270% (8027/10000)  79/79 \n",
            "[2022-11-10 17:32:15,006] [val] [Epoch 19] [Loss 0.687] [Acc 80.270]\n",
            "\n",
            "Epoch: 20\n",
            " [=====================================================================================>]  Step: 78ms | Tot: 45s767ms | Loss: 0.591 | Acc: 83.348% (41674/50000) | Cls: 0.403  391/391 \n",
            "[2022-11-10 17:33:01,514] [train] [Epoch 20] [Loss 0.591] [cls 0.403] [Acc 83.348]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s527ms | Loss: 0.632 | Acc: 81.400% (8140/10000)  79/79 \n",
            "[2022-11-10 17:33:04,395] [val] [Epoch 20] [Loss 0.632] [Acc 81.400]\n",
            "Saving..\n",
            "\n",
            "Epoch: 21\n",
            " [=====================================================================================>]  Step: 85ms | Tot: 45s685ms | Loss: 0.573 | Acc: 84.010% (42005/50000) | Cls: 0.406  391/391 \n",
            "[2022-11-10 17:33:50,944] [train] [Epoch 21] [Loss 0.573] [cls 0.406] [Acc 84.010]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s544ms | Loss: 0.610 | Acc: 81.420% (8142/10000)  79/79 \n",
            "[2022-11-10 17:33:53,794] [val] [Epoch 21] [Loss 0.610] [Acc 81.420]\n",
            "Saving..\n",
            "\n",
            "Epoch: 22\n",
            " [=====================================================================================>]  Step: 90ms | Tot: 45s669ms | Loss: 0.562 | Acc: 84.318% (42159/50000) | Cls: 0.395  391/391 \n",
            "[2022-11-10 17:34:40,307] [train] [Epoch 22] [Loss 0.562] [cls 0.395] [Acc 84.318]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s488ms | Loss: 0.624 | Acc: 82.060% (8206/10000)  79/79 \n",
            "[2022-11-10 17:34:43,152] [val] [Epoch 22] [Loss 0.624] [Acc 82.060]\n",
            "Saving..\n",
            "\n",
            "Epoch: 23\n",
            " [=====================================================================================>]  Step: 77ms | Tot: 45s911ms | Loss: 0.551 | Acc: 84.618% (42309/50000) | Cls: 0.393  391/391 \n",
            "[2022-11-10 17:35:29,893] [train] [Epoch 23] [Loss 0.551] [cls 0.393] [Acc 84.618]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s445ms | Loss: 0.605 | Acc: 82.660% (8266/10000)  79/79 \n",
            "[2022-11-10 17:35:32,752] [val] [Epoch 23] [Loss 0.605] [Acc 82.660]\n",
            "Saving..\n",
            "\n",
            "Epoch: 24\n",
            " [=====================================================================================>]  Step: 75ms | Tot: 45s869ms | Loss: 0.537 | Acc: 85.086% (42543/50000) | Cls: 0.391  391/391 \n",
            "[2022-11-10 17:36:19,429] [train] [Epoch 24] [Loss 0.537] [cls 0.391] [Acc 85.086]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s545ms | Loss: 0.602 | Acc: 81.410% (8141/10000)  79/79 \n",
            "[2022-11-10 17:36:22,291] [val] [Epoch 24] [Loss 0.602] [Acc 81.410]\n",
            "\n",
            "Epoch: 25\n",
            " [=====================================================================================>]  Step: 81ms | Tot: 47s175ms | Loss: 0.530 | Acc: 85.350% (42675/50000) | Cls: 0.389  391/391 \n",
            "[2022-11-10 17:37:10,262] [train] [Epoch 25] [Loss 0.530] [cls 0.389] [Acc 85.350]\n",
            " [====================================================================================>.]  Step: 10ms | Tot: 2s603ms | Loss: 0.580 | Acc: 82.570% (8257/10000)  79/79 \n",
            "[2022-11-10 17:37:13,235] [val] [Epoch 25] [Loss 0.580] [Acc 82.570]\n",
            "\n",
            "Epoch: 26\n",
            " [=====================================================================================>]  Step: 75ms | Tot: 47s116ms | Loss: 0.518 | Acc: 85.692% (42846/50000) | Cls: 0.388  391/391 \n",
            "[2022-11-10 17:38:01,102] [train] [Epoch 26] [Loss 0.518] [cls 0.388] [Acc 85.692]\n",
            " [====================================================================================>.]  Step: 10ms | Tot: 2s500ms | Loss: 0.547 | Acc: 84.340% (8434/10000)  79/79 \n",
            "[2022-11-10 17:38:03,974] [val] [Epoch 26] [Loss 0.547] [Acc 84.340]\n",
            "Saving..\n",
            "\n",
            "Epoch: 27\n",
            " [=====================================================================================>]  Step: 79ms | Tot: 45s519ms | Loss: 0.514 | Acc: 85.710% (42855/50000) | Cls: 0.383  391/391 \n",
            "[2022-11-10 17:38:50,370] [train] [Epoch 27] [Loss 0.514] [cls 0.383] [Acc 85.710]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s548ms | Loss: 0.573 | Acc: 83.330% (8333/10000)  79/79 \n",
            "[2022-11-10 17:38:53,231] [val] [Epoch 27] [Loss 0.573] [Acc 83.330]\n",
            "\n",
            "Epoch: 28\n",
            " [=====================================================================================>]  Step: 74ms | Tot: 45s619ms | Loss: 0.499 | Acc: 86.230% (43115/50000) | Cls: 0.382  391/391 \n",
            "[2022-11-10 17:39:39,631] [train] [Epoch 28] [Loss 0.499] [cls 0.382] [Acc 86.230]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s478ms | Loss: 0.564 | Acc: 83.290% (8329/10000)  79/79 \n",
            "[2022-11-10 17:39:42,481] [val] [Epoch 28] [Loss 0.564] [Acc 83.290]\n",
            "\n",
            "Epoch: 29\n",
            " [=====================================================================================>]  Step: 75ms | Tot: 45s601ms | Loss: 0.495 | Acc: 86.336% (43168/50000) | Cls: 0.380  391/391 \n",
            "[2022-11-10 17:40:28,734] [train] [Epoch 29] [Loss 0.495] [cls 0.380] [Acc 86.336]\n",
            " [====================================================================================>.]  Step: 12ms | Tot: 2s665ms | Loss: 0.546 | Acc: 83.450% (8345/10000)  79/79 \n",
            "[2022-11-10 17:40:31,714] [val] [Epoch 29] [Loss 0.546] [Acc 83.450]\n",
            "\n",
            "Epoch: 30\n",
            " [=====================================================================================>]  Step: 77ms | Tot: 46s940ms | Loss: 0.483 | Acc: 86.668% (43334/50000) | Cls: 0.377  391/391 \n",
            "[2022-11-10 17:41:19,396] [train] [Epoch 30] [Loss 0.483] [cls 0.377] [Acc 86.668]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s515ms | Loss: 0.539 | Acc: 83.930% (8393/10000)  79/79 \n",
            "[2022-11-10 17:41:22,321] [val] [Epoch 30] [Loss 0.539] [Acc 83.930]\n",
            "\n",
            "Epoch: 31\n",
            " [=====================================================================================>]  Step: 77ms | Tot: 45s488ms | Loss: 0.476 | Acc: 87.028% (43514/50000) | Cls: 0.372  391/391 \n",
            "[2022-11-10 17:42:08,540] [train] [Epoch 31] [Loss 0.476] [cls 0.372] [Acc 87.028]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s460ms | Loss: 0.550 | Acc: 84.180% (8418/10000)  79/79 \n",
            "[2022-11-10 17:42:11,401] [val] [Epoch 31] [Loss 0.550] [Acc 84.180]\n",
            "\n",
            "Epoch: 32\n",
            " [=====================================================================================>]  Step: 76ms | Tot: 44s759ms | Loss: 0.467 | Acc: 87.216% (43608/50000) | Cls: 0.369  391/391 \n",
            "[2022-11-10 17:42:56,966] [train] [Epoch 32] [Loss 0.467] [cls 0.369] [Acc 87.216]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s471ms | Loss: 0.552 | Acc: 83.340% (8334/10000)  79/79 \n",
            "[2022-11-10 17:42:59,788] [val] [Epoch 32] [Loss 0.552] [Acc 83.340]\n",
            "\n",
            "Epoch: 33\n",
            " [=====================================================================================>]  Step: 84ms | Tot: 45s26ms | Loss: 0.462 | Acc: 87.368% (43684/50000) | Cls: 0.369  391/391 \n",
            "[2022-11-10 17:43:45,506] [train] [Epoch 33] [Loss 0.462] [cls 0.369] [Acc 87.368]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s452ms | Loss: 0.562 | Acc: 83.060% (8306/10000)  79/79 \n",
            "[2022-11-10 17:43:48,304] [val] [Epoch 33] [Loss 0.562] [Acc 83.060]\n",
            "\n",
            "Epoch: 34\n",
            " [=====================================================================================>]  Step: 77ms | Tot: 45s274ms | Loss: 0.456 | Acc: 87.662% (43831/50000) | Cls: 0.366  391/391 \n",
            "[2022-11-10 17:44:34,264] [train] [Epoch 34] [Loss 0.456] [cls 0.366] [Acc 87.662]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s521ms | Loss: 0.494 | Acc: 84.840% (8484/10000)  79/79 \n",
            "[2022-11-10 17:44:37,109] [val] [Epoch 34] [Loss 0.494] [Acc 84.840]\n",
            "Saving..\n",
            "\n",
            "Epoch: 35\n",
            " [=====================================================================================>]  Step: 78ms | Tot: 45s18ms | Loss: 0.447 | Acc: 87.870% (43935/50000) | Cls: 0.364  391/391 \n",
            "[2022-11-10 17:45:22,862] [train] [Epoch 35] [Loss 0.447] [cls 0.364] [Acc 87.870]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s567ms | Loss: 0.547 | Acc: 83.940% (8394/10000)  79/79 \n",
            "[2022-11-10 17:45:25,762] [val] [Epoch 35] [Loss 0.547] [Acc 83.940]\n",
            "\n",
            "Epoch: 36\n",
            " [=====================================================================================>]  Step: 79ms | Tot: 46s198ms | Loss: 0.443 | Acc: 87.858% (43929/50000) | Cls: 0.363  391/391 \n",
            "[2022-11-10 17:46:12,687] [train] [Epoch 36] [Loss 0.443] [cls 0.363] [Acc 87.858]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s511ms | Loss: 0.568 | Acc: 83.140% (8314/10000)  79/79 \n",
            "[2022-11-10 17:46:15,571] [val] [Epoch 36] [Loss 0.568] [Acc 83.140]\n",
            "\n",
            "Epoch: 37\n",
            " [=====================================================================================>]  Step: 83ms | Tot: 45s96ms | Loss: 0.440 | Acc: 88.136% (44068/50000) | Cls: 0.362  391/391 \n",
            "[2022-11-10 17:47:01,437] [train] [Epoch 37] [Loss 0.440] [cls 0.362] [Acc 88.136]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s531ms | Loss: 0.494 | Acc: 85.940% (8594/10000)  79/79 \n",
            "[2022-11-10 17:47:04,277] [val] [Epoch 37] [Loss 0.494] [Acc 85.940]\n",
            "Saving..\n",
            "\n",
            "Epoch: 38\n",
            " [=====================================================================================>]  Step: 84ms | Tot: 45s12ms | Loss: 0.433 | Acc: 88.360% (44180/50000) | Cls: 0.354  391/391 \n",
            "[2022-11-10 17:47:50,127] [train] [Epoch 38] [Loss 0.433] [cls 0.354] [Acc 88.360]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s461ms | Loss: 0.468 | Acc: 86.290% (8629/10000)  79/79 \n",
            "[2022-11-10 17:47:52,947] [val] [Epoch 38] [Loss 0.468] [Acc 86.290]\n",
            "Saving..\n",
            "\n",
            "Epoch: 39\n",
            " [=====================================================================================>]  Step: 79ms | Tot: 45s188ms | Loss: 0.423 | Acc: 88.660% (44330/50000) | Cls: 0.354  391/391 \n",
            "[2022-11-10 17:48:38,956] [train] [Epoch 39] [Loss 0.423] [cls 0.354] [Acc 88.660]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s527ms | Loss: 0.509 | Acc: 84.780% (8478/10000)  79/79 \n",
            "[2022-11-10 17:48:41,807] [val] [Epoch 39] [Loss 0.509] [Acc 84.780]\n",
            "\n",
            "Epoch: 40\n",
            " [=====================================================================================>]  Step: 76ms | Tot: 45s171ms | Loss: 0.419 | Acc: 88.704% (44352/50000) | Cls: 0.357  391/391 \n",
            "[2022-11-10 17:49:27,723] [train] [Epoch 40] [Loss 0.419] [cls 0.357] [Acc 88.704]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s512ms | Loss: 0.513 | Acc: 84.890% (8489/10000)  79/79 \n",
            "[2022-11-10 17:49:30,608] [val] [Epoch 40] [Loss 0.513] [Acc 84.890]\n",
            "\n",
            "Epoch: 41\n",
            " [=====================================================================================>]  Step: 77ms | Tot: 45s963ms | Loss: 0.413 | Acc: 88.936% (44468/50000) | Cls: 0.350  391/391 \n",
            "[2022-11-10 17:50:17,297] [train] [Epoch 41] [Loss 0.413] [cls 0.350] [Acc 88.936]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s469ms | Loss: 0.555 | Acc: 83.650% (8365/10000)  79/79 \n",
            "[2022-11-10 17:50:20,126] [val] [Epoch 41] [Loss 0.555] [Acc 83.650]\n",
            "\n",
            "Epoch: 42\n",
            " [=====================================================================================>]  Step: 79ms | Tot: 44s721ms | Loss: 0.410 | Acc: 89.004% (44502/50000) | Cls: 0.350  391/391 \n",
            "[2022-11-10 17:51:05,635] [train] [Epoch 42] [Loss 0.410] [cls 0.350] [Acc 89.004]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s409ms | Loss: 0.568 | Acc: 83.790% (8379/10000)  79/79 \n",
            "[2022-11-10 17:51:08,433] [val] [Epoch 42] [Loss 0.568] [Acc 83.790]\n",
            "\n",
            "Epoch: 43\n",
            " [=====================================================================================>]  Step: 77ms | Tot: 44s868ms | Loss: 0.414 | Acc: 88.838% (44419/50000) | Cls: 0.354  391/391 \n",
            "[2022-11-10 17:51:54,031] [train] [Epoch 43] [Loss 0.414] [cls 0.354] [Acc 88.838]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s412ms | Loss: 0.497 | Acc: 84.710% (8471/10000)  79/79 \n",
            "[2022-11-10 17:51:56,830] [val] [Epoch 43] [Loss 0.497] [Acc 84.710]\n",
            "\n",
            "Epoch: 44\n",
            " [=====================================================================================>]  Step: 77ms | Tot: 44s881ms | Loss: 0.399 | Acc: 89.294% (44647/50000) | Cls: 0.349  391/391 \n",
            "[2022-11-10 17:52:42,476] [train] [Epoch 44] [Loss 0.399] [cls 0.349] [Acc 89.294]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s493ms | Loss: 0.486 | Acc: 86.100% (8610/10000)  79/79 \n",
            "[2022-11-10 17:52:45,291] [val] [Epoch 44] [Loss 0.486] [Acc 86.100]\n",
            "\n",
            "Epoch: 45\n",
            " [=====================================================================================>]  Step: 84ms | Tot: 44s642ms | Loss: 0.393 | Acc: 89.680% (44840/50000) | Cls: 0.345  391/391 \n",
            "[2022-11-10 17:53:30,727] [train] [Epoch 45] [Loss 0.393] [cls 0.345] [Acc 89.680]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s442ms | Loss: 0.482 | Acc: 86.360% (8636/10000)  79/79 \n",
            "[2022-11-10 17:53:33,530] [val] [Epoch 45] [Loss 0.482] [Acc 86.360]\n",
            "Saving..\n",
            "\n",
            "Epoch: 46\n",
            " [=====================================================================================>]  Step: 87ms | Tot: 46s279ms | Loss: 0.400 | Acc: 89.216% (44608/50000) | Cls: 0.348  391/391 \n",
            "[2022-11-10 17:54:20,645] [train] [Epoch 46] [Loss 0.400] [cls 0.348] [Acc 89.216]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s651ms | Loss: 0.474 | Acc: 86.010% (8601/10000)  79/79 \n",
            "[2022-11-10 17:54:23,640] [val] [Epoch 46] [Loss 0.474] [Acc 86.010]\n",
            "\n",
            "Epoch: 47\n",
            " [=====================================================================================>]  Step: 79ms | Tot: 49s242ms | Loss: 0.389 | Acc: 89.622% (44811/50000) | Cls: 0.342  391/391 \n",
            "[2022-11-10 17:55:13,690] [train] [Epoch 47] [Loss 0.389] [cls 0.342] [Acc 89.622]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s823ms | Loss: 0.510 | Acc: 84.600% (8460/10000)  79/79 \n",
            "[2022-11-10 17:55:16,836] [val] [Epoch 47] [Loss 0.510] [Acc 84.600]\n",
            "\n",
            "Epoch: 48\n",
            " [=====================================================================================>]  Step: 78ms | Tot: 49s191ms | Loss: 0.381 | Acc: 89.904% (44952/50000) | Cls: 0.343  391/391 \n",
            "[2022-11-10 17:56:06,833] [train] [Epoch 48] [Loss 0.381] [cls 0.343] [Acc 89.904]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s651ms | Loss: 0.508 | Acc: 84.860% (8486/10000)  79/79 \n",
            "[2022-11-10 17:56:09,913] [val] [Epoch 48] [Loss 0.508] [Acc 84.860]\n",
            "\n",
            "Epoch: 49\n",
            " [=====================================================================================>]  Step: 76ms | Tot: 47s902ms | Loss: 0.386 | Acc: 89.740% (44870/50000) | Cls: 0.340  391/391 \n",
            "[2022-11-10 17:56:58,640] [train] [Epoch 49] [Loss 0.386] [cls 0.340] [Acc 89.740]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s739ms | Loss: 0.423 | Acc: 87.520% (8752/10000)  79/79 \n",
            "[2022-11-10 17:57:01,767] [val] [Epoch 49] [Loss 0.423] [Acc 87.520]\n",
            "Saving..\n",
            "\n",
            "Epoch: 50\n",
            " [=====================================================================================>]  Step: 78ms | Tot: 47s295ms | Loss: 0.378 | Acc: 89.916% (44958/50000) | Cls: 0.336  391/391 \n",
            "[2022-11-10 17:57:49,947] [train] [Epoch 50] [Loss 0.378] [cls 0.336] [Acc 89.916]\n",
            " [====================================================================================>.]  Step: 11ms | Tot: 2s682ms | Loss: 0.499 | Acc: 86.000% (8600/10000)  79/79 \n",
            "[2022-11-10 17:57:52,980] [val] [Epoch 50] [Loss 0.499] [Acc 86.000]\n",
            "\n",
            "Epoch: 51\n",
            " [=====================================================================================>]  Step: 77ms | Tot: 48s242ms | Loss: 0.380 | Acc: 90.000% (45000/50000) | Cls: 0.335  391/391 \n",
            "[2022-11-10 17:58:42,015] [train] [Epoch 51] [Loss 0.380] [cls 0.335] [Acc 90.000]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s691ms | Loss: 0.444 | Acc: 87.300% (8730/10000)  79/79 \n",
            "[2022-11-10 17:58:45,093] [val] [Epoch 51] [Loss 0.444] [Acc 87.300]\n",
            "\n",
            "Epoch: 52\n",
            " [=====================================================================================>]  Step: 81ms | Tot: 49s103ms | Loss: 0.365 | Acc: 90.444% (45222/50000) | Cls: 0.332  391/391 \n",
            "[2022-11-10 17:59:35,038] [train] [Epoch 52] [Loss 0.365] [cls 0.332] [Acc 90.444]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s505ms | Loss: 0.504 | Acc: 85.380% (8538/10000)  79/79 \n",
            "[2022-11-10 17:59:37,926] [val] [Epoch 52] [Loss 0.504] [Acc 85.380]\n",
            "\n",
            "Epoch: 53\n",
            " [=====================================================================================>]  Step: 73ms | Tot: 47s634ms | Loss: 0.369 | Acc: 90.324% (45162/50000) | Cls: 0.335  391/391 \n",
            "[2022-11-10 18:00:26,347] [train] [Epoch 53] [Loss 0.369] [cls 0.335] [Acc 90.324]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s488ms | Loss: 0.510 | Acc: 85.180% (8518/10000)  79/79 \n",
            "[2022-11-10 18:00:29,257] [val] [Epoch 53] [Loss 0.510] [Acc 85.180]\n",
            "\n",
            "Epoch: 54\n",
            " [=====================================================================================>]  Step: 70ms | Tot: 46s958ms | Loss: 0.363 | Acc: 90.314% (45157/50000) | Cls: 0.331  391/391 \n",
            "[2022-11-10 18:01:17,074] [train] [Epoch 54] [Loss 0.363] [cls 0.331] [Acc 90.314]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s596ms | Loss: 0.454 | Acc: 86.520% (8652/10000)  79/79 \n",
            "[2022-11-10 18:01:19,993] [val] [Epoch 54] [Loss 0.454] [Acc 86.520]\n",
            "\n",
            "Epoch: 55\n",
            " [=====================================================================================>]  Step: 80ms | Tot: 46s911ms | Loss: 0.371 | Acc: 90.186% (45093/50000) | Cls: 0.334  391/391 \n",
            "[2022-11-10 18:02:07,725] [train] [Epoch 55] [Loss 0.371] [cls 0.334] [Acc 90.186]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s649ms | Loss: 0.505 | Acc: 85.480% (8548/10000)  79/79 \n",
            "[2022-11-10 18:02:10,741] [val] [Epoch 55] [Loss 0.505] [Acc 85.480]\n",
            "\n",
            "Epoch: 56\n",
            " [=====================================================================================>]  Step: 77ms | Tot: 47s204ms | Loss: 0.366 | Acc: 90.332% (45166/50000) | Cls: 0.331  391/391 \n",
            "[2022-11-10 18:02:58,737] [train] [Epoch 56] [Loss 0.366] [cls 0.331] [Acc 90.332]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s709ms | Loss: 0.499 | Acc: 85.790% (8579/10000)  79/79 \n",
            "[2022-11-10 18:03:01,830] [val] [Epoch 56] [Loss 0.499] [Acc 85.790]\n",
            "\n",
            "Epoch: 57\n",
            " [=====================================================================================>]  Step: 75ms | Tot: 48s477ms | Loss: 0.357 | Acc: 90.482% (45241/50000) | Cls: 0.332  391/391 \n",
            "[2022-11-10 18:03:51,056] [train] [Epoch 57] [Loss 0.357] [cls 0.332] [Acc 90.482]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s551ms | Loss: 0.512 | Acc: 85.100% (8510/10000)  79/79 \n",
            "[2022-11-10 18:03:53,997] [val] [Epoch 57] [Loss 0.512] [Acc 85.100]\n",
            "\n",
            "Epoch: 58\n",
            " [=====================================================================================>]  Step: 80ms | Tot: 47s139ms | Loss: 0.358 | Acc: 90.410% (45205/50000) | Cls: 0.329  391/391 \n",
            "[2022-11-10 18:04:41,893] [train] [Epoch 58] [Loss 0.358] [cls 0.329] [Acc 90.410]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s532ms | Loss: 0.454 | Acc: 86.600% (8660/10000)  79/79 \n",
            "[2022-11-10 18:04:44,801] [val] [Epoch 58] [Loss 0.454] [Acc 86.600]\n",
            "\n",
            "Epoch: 59\n",
            " [=====================================================================================>]  Step: 78ms | Tot: 46s702ms | Loss: 0.354 | Acc: 90.582% (45291/50000) | Cls: 0.330  391/391 \n",
            "[2022-11-10 18:05:32,245] [train] [Epoch 59] [Loss 0.354] [cls 0.330] [Acc 90.582]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s543ms | Loss: 0.500 | Acc: 85.380% (8538/10000)  79/79 \n",
            "[2022-11-10 18:05:35,177] [val] [Epoch 59] [Loss 0.500] [Acc 85.380]\n",
            "\n",
            "Epoch: 60\n",
            " [=====================================================================================>]  Step: 78ms | Tot: 46s619ms | Loss: 0.351 | Acc: 90.710% (45355/50000) | Cls: 0.328  391/391 \n",
            "[2022-11-10 18:06:22,438] [train] [Epoch 60] [Loss 0.351] [cls 0.328] [Acc 90.710]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s574ms | Loss: 0.471 | Acc: 85.430% (8543/10000)  79/79 \n",
            "[2022-11-10 18:06:25,392] [val] [Epoch 60] [Loss 0.471] [Acc 85.430]\n",
            "\n",
            "Epoch: 61\n",
            " [=====================================================================================>]  Step: 78ms | Tot: 46s701ms | Loss: 0.339 | Acc: 91.112% (45556/50000) | Cls: 0.324  391/391 \n",
            "[2022-11-10 18:07:12,921] [train] [Epoch 61] [Loss 0.339] [cls 0.324] [Acc 91.112]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s494ms | Loss: 0.520 | Acc: 85.250% (8525/10000)  79/79 \n",
            "[2022-11-10 18:07:15,810] [val] [Epoch 61] [Loss 0.520] [Acc 85.250]\n",
            "\n",
            "Epoch: 62\n",
            " [=====================================================================================>]  Step: 76ms | Tot: 47s583ms | Loss: 0.345 | Acc: 90.936% (45468/50000) | Cls: 0.322  391/391 \n",
            "[2022-11-10 18:08:04,101] [train] [Epoch 62] [Loss 0.345] [cls 0.322] [Acc 90.936]\n",
            " [====================================================================================>.]  Step: 10ms | Tot: 2s635ms | Loss: 0.436 | Acc: 87.090% (8709/10000)  79/79 \n",
            "[2022-11-10 18:08:07,038] [val] [Epoch 62] [Loss 0.436] [Acc 87.090]\n",
            "\n",
            "Epoch: 63\n",
            " [=====================================================================================>]  Step: 77ms | Tot: 46s562ms | Loss: 0.341 | Acc: 91.008% (45504/50000) | Cls: 0.318  391/391 \n",
            "[2022-11-10 18:08:54,348] [train] [Epoch 63] [Loss 0.341] [cls 0.318] [Acc 91.008]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s532ms | Loss: 0.473 | Acc: 86.040% (8604/10000)  79/79 \n",
            "[2022-11-10 18:08:57,235] [val] [Epoch 63] [Loss 0.473] [Acc 86.040]\n",
            "\n",
            "Epoch: 64\n",
            " [=====================================================================================>]  Step: 75ms | Tot: 46s443ms | Loss: 0.338 | Acc: 91.186% (45593/50000) | Cls: 0.320  391/391 \n",
            "[2022-11-10 18:09:44,466] [train] [Epoch 64] [Loss 0.338] [cls 0.320] [Acc 91.186]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s635ms | Loss: 0.496 | Acc: 85.840% (8584/10000)  79/79 \n",
            "[2022-11-10 18:09:47,406] [val] [Epoch 64] [Loss 0.496] [Acc 85.840]\n",
            "\n",
            "Epoch: 65\n",
            " [=====================================================================================>]  Step: 78ms | Tot: 46s409ms | Loss: 0.341 | Acc: 91.018% (45509/50000) | Cls: 0.325  391/391 \n",
            "[2022-11-10 18:10:34,499] [train] [Epoch 65] [Loss 0.341] [cls 0.325] [Acc 91.018]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s562ms | Loss: 0.451 | Acc: 86.900% (8690/10000)  79/79 \n",
            "[2022-11-10 18:10:37,421] [val] [Epoch 65] [Loss 0.451] [Acc 86.900]\n",
            "\n",
            "Epoch: 66\n",
            " [=====================================================================================>]  Step: 75ms | Tot: 46s227ms | Loss: 0.341 | Acc: 90.988% (45494/50000) | Cls: 0.327  391/391 \n",
            "[2022-11-10 18:11:24,383] [train] [Epoch 66] [Loss 0.341] [cls 0.327] [Acc 90.988]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s608ms | Loss: 0.436 | Acc: 86.730% (8673/10000)  79/79 \n",
            "[2022-11-10 18:11:27,313] [val] [Epoch 66] [Loss 0.436] [Acc 86.730]\n",
            "\n",
            "Epoch: 67\n",
            " [=====================================================================================>]  Step: 84ms | Tot: 47s335ms | Loss: 0.338 | Acc: 91.072% (45536/50000) | Cls: 0.316  391/391 \n",
            "[2022-11-10 18:12:15,403] [train] [Epoch 67] [Loss 0.338] [cls 0.316] [Acc 91.072]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s507ms | Loss: 0.469 | Acc: 86.320% (8632/10000)  79/79 \n",
            "[2022-11-10 18:12:18,281] [val] [Epoch 67] [Loss 0.469] [Acc 86.320]\n",
            "\n",
            "Epoch: 68\n",
            " [=====================================================================================>]  Step: 83ms | Tot: 45s932ms | Loss: 0.331 | Acc: 91.248% (45624/50000) | Cls: 0.313  391/391 \n",
            "[2022-11-10 18:13:04,976] [train] [Epoch 68] [Loss 0.331] [cls 0.313] [Acc 91.248]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s476ms | Loss: 0.424 | Acc: 87.890% (8789/10000)  79/79 \n",
            "[2022-11-10 18:13:07,841] [val] [Epoch 68] [Loss 0.424] [Acc 87.890]\n",
            "Saving..\n",
            "\n",
            "Epoch: 69\n",
            " [=====================================================================================>]  Step: 77ms | Tot: 45s93ms | Loss: 0.329 | Acc: 91.376% (45688/50000) | Cls: 0.319  391/391 \n",
            "[2022-11-10 18:13:53,795] [train] [Epoch 69] [Loss 0.329] [cls 0.319] [Acc 91.376]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s509ms | Loss: 0.455 | Acc: 86.760% (8676/10000)  79/79 \n",
            "[2022-11-10 18:13:56,683] [val] [Epoch 69] [Loss 0.455] [Acc 86.760]\n",
            "\n",
            "Epoch: 70\n",
            " [=====================================================================================>]  Step: 80ms | Tot: 46s286ms | Loss: 0.331 | Acc: 91.412% (45706/50000) | Cls: 0.317  391/391 \n",
            "[2022-11-10 18:14:43,735] [train] [Epoch 70] [Loss 0.331] [cls 0.317] [Acc 91.412]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s557ms | Loss: 0.413 | Acc: 88.300% (8830/10000)  79/79 \n",
            "[2022-11-10 18:14:46,588] [val] [Epoch 70] [Loss 0.413] [Acc 88.300]\n",
            "Saving..\n",
            "\n",
            "Epoch: 71\n",
            " [=====================================================================================>]  Step: 81ms | Tot: 45s19ms | Loss: 0.326 | Acc: 91.396% (45698/50000) | Cls: 0.315  391/391 \n",
            "[2022-11-10 18:15:32,408] [train] [Epoch 71] [Loss 0.326] [cls 0.315] [Acc 91.396]\n",
            " [====================================================================================>.]  Step: 12ms | Tot: 2s490ms | Loss: 0.488 | Acc: 85.980% (8598/10000)  79/79 \n",
            "[2022-11-10 18:15:35,241] [val] [Epoch 71] [Loss 0.488] [Acc 85.980]\n",
            "\n",
            "Epoch: 72\n",
            " [=====================================================================================>]  Step: 84ms | Tot: 45s424ms | Loss: 0.325 | Acc: 91.520% (45760/50000) | Cls: 0.313  391/391 \n",
            "[2022-11-10 18:16:21,365] [train] [Epoch 72] [Loss 0.325] [cls 0.313] [Acc 91.520]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s533ms | Loss: 0.489 | Acc: 86.300% (8630/10000)  79/79 \n",
            "[2022-11-10 18:16:24,325] [val] [Epoch 72] [Loss 0.489] [Acc 86.300]\n",
            "\n",
            "Epoch: 73\n",
            " [=====================================================================================>]  Step: 76ms | Tot: 46s633ms | Loss: 0.321 | Acc: 91.564% (45782/50000) | Cls: 0.315  391/391 \n",
            "[2022-11-10 18:17:11,798] [train] [Epoch 73] [Loss 0.321] [cls 0.315] [Acc 91.564]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s470ms | Loss: 0.432 | Acc: 86.910% (8691/10000)  79/79 \n",
            "[2022-11-10 18:17:14,669] [val] [Epoch 73] [Loss 0.432] [Acc 86.910]\n",
            "\n",
            "Epoch: 74\n",
            " [=====================================================================================>]  Step: 76ms | Tot: 45s487ms | Loss: 0.319 | Acc: 91.700% (45850/50000) | Cls: 0.312  391/391 \n",
            "[2022-11-10 18:18:00,856] [train] [Epoch 74] [Loss 0.319] [cls 0.312] [Acc 91.700]\n",
            " [====================================================================================>.]  Step: 10ms | Tot: 2s603ms | Loss: 0.415 | Acc: 88.150% (8815/10000)  79/79 \n",
            "[2022-11-10 18:18:03,767] [val] [Epoch 74] [Loss 0.415] [Acc 88.150]\n",
            "\n",
            "Epoch: 75\n",
            " [=====================================================================================>]  Step: 80ms | Tot: 45s378ms | Loss: 0.317 | Acc: 91.818% (45909/50000) | Cls: 0.310  391/391 \n",
            "[2022-11-10 18:18:49,916] [train] [Epoch 75] [Loss 0.317] [cls 0.310] [Acc 91.818]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s487ms | Loss: 0.473 | Acc: 86.440% (8644/10000)  79/79 \n",
            "[2022-11-10 18:18:52,717] [val] [Epoch 75] [Loss 0.473] [Acc 86.440]\n",
            "\n",
            "Epoch: 76\n",
            " [=====================================================================================>]  Step: 77ms | Tot: 45s847ms | Loss: 0.319 | Acc: 91.700% (45850/50000) | Cls: 0.314  391/391 \n",
            "[2022-11-10 18:19:39,315] [train] [Epoch 76] [Loss 0.319] [cls 0.314] [Acc 91.700]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s534ms | Loss: 0.459 | Acc: 86.860% (8686/10000)  79/79 \n",
            "[2022-11-10 18:19:42,158] [val] [Epoch 76] [Loss 0.459] [Acc 86.860]\n",
            "\n",
            "Epoch: 77\n",
            " [=====================================================================================>]  Step: 79ms | Tot: 45s953ms | Loss: 0.319 | Acc: 91.742% (45871/50000) | Cls: 0.311  391/391 \n",
            "[2022-11-10 18:20:28,911] [train] [Epoch 77] [Loss 0.319] [cls 0.311] [Acc 91.742]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s469ms | Loss: 0.453 | Acc: 87.160% (8716/10000)  79/79 \n",
            "[2022-11-10 18:20:31,780] [val] [Epoch 77] [Loss 0.453] [Acc 87.160]\n",
            "\n",
            "Epoch: 78\n",
            " [=====================================================================================>]  Step: 79ms | Tot: 46s292ms | Loss: 0.319 | Acc: 91.636% (45818/50000) | Cls: 0.317  391/391 \n",
            "[2022-11-10 18:21:18,808] [train] [Epoch 78] [Loss 0.319] [cls 0.317] [Acc 91.636]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s476ms | Loss: 0.425 | Acc: 87.670% (8767/10000)  79/79 \n",
            "[2022-11-10 18:21:21,629] [val] [Epoch 78] [Loss 0.425] [Acc 87.670]\n",
            "\n",
            "Epoch: 79\n",
            " [=====================================================================================>]  Step: 79ms | Tot: 46s430ms | Loss: 0.306 | Acc: 92.080% (46040/50000) | Cls: 0.304  391/391 \n",
            "[2022-11-10 18:22:08,744] [train] [Epoch 79] [Loss 0.306] [cls 0.304] [Acc 92.080]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s563ms | Loss: 0.428 | Acc: 87.670% (8767/10000)  79/79 \n",
            "[2022-11-10 18:22:11,628] [val] [Epoch 79] [Loss 0.428] [Acc 87.670]\n",
            "\n",
            "Epoch: 80\n",
            " [=====================================================================================>]  Step: 80ms | Tot: 45s472ms | Loss: 0.313 | Acc: 91.934% (45967/50000) | Cls: 0.306  391/391 \n",
            "[2022-11-10 18:22:57,888] [train] [Epoch 80] [Loss 0.313] [cls 0.306] [Acc 91.934]\n",
            " [====================================================================================>.]  Step: 14ms | Tot: 2s524ms | Loss: 0.520 | Acc: 85.320% (8532/10000)  79/79 \n",
            "[2022-11-10 18:23:00,734] [val] [Epoch 80] [Loss 0.520] [Acc 85.320]\n",
            "\n",
            "Epoch: 81\n",
            " [=====================================================================================>]  Step: 76ms | Tot: 45s733ms | Loss: 0.311 | Acc: 91.952% (45976/50000) | Cls: 0.307  391/391 \n",
            "[2022-11-10 18:23:47,202] [train] [Epoch 81] [Loss 0.311] [cls 0.307] [Acc 91.952]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s548ms | Loss: 0.462 | Acc: 86.400% (8640/10000)  79/79 \n",
            "[2022-11-10 18:23:50,132] [val] [Epoch 81] [Loss 0.462] [Acc 86.400]\n",
            "\n",
            "Epoch: 82\n",
            " [=====================================================================================>]  Step: 79ms | Tot: 45s247ms | Loss: 0.312 | Acc: 91.924% (45962/50000) | Cls: 0.310  391/391 \n",
            "[2022-11-10 18:24:36,166] [train] [Epoch 82] [Loss 0.312] [cls 0.310] [Acc 91.924]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s558ms | Loss: 0.432 | Acc: 87.980% (8798/10000)  79/79 \n",
            "[2022-11-10 18:24:39,041] [val] [Epoch 82] [Loss 0.432] [Acc 87.980]\n",
            "\n",
            "Epoch: 83\n",
            " [=====================================================================================>]  Step: 77ms | Tot: 46s566ms | Loss: 0.305 | Acc: 92.116% (46058/50000) | Cls: 0.306  391/391 \n",
            "[2022-11-10 18:25:26,424] [train] [Epoch 83] [Loss 0.305] [cls 0.306] [Acc 92.116]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s593ms | Loss: 0.437 | Acc: 87.870% (8787/10000)  79/79 \n",
            "[2022-11-10 18:25:29,419] [val] [Epoch 83] [Loss 0.437] [Acc 87.870]\n",
            "\n",
            "Epoch: 84\n",
            " [=====================================================================================>]  Step: 79ms | Tot: 45s395ms | Loss: 0.301 | Acc: 92.206% (46103/50000) | Cls: 0.300  391/391 \n",
            "[2022-11-10 18:26:15,630] [train] [Epoch 84] [Loss 0.301] [cls 0.300] [Acc 92.206]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s453ms | Loss: 0.440 | Acc: 86.400% (8640/10000)  79/79 \n",
            "[2022-11-10 18:26:18,468] [val] [Epoch 84] [Loss 0.440] [Acc 86.400]\n",
            "\n",
            "Epoch: 85\n",
            " [=====================================================================================>]  Step: 76ms | Tot: 45s265ms | Loss: 0.308 | Acc: 92.026% (46013/50000) | Cls: 0.309  391/391 \n",
            "[2022-11-10 18:27:04,405] [train] [Epoch 85] [Loss 0.308] [cls 0.309] [Acc 92.026]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s424ms | Loss: 0.418 | Acc: 88.080% (8808/10000)  79/79 \n",
            "[2022-11-10 18:27:07,210] [val] [Epoch 85] [Loss 0.418] [Acc 88.080]\n",
            "\n",
            "Epoch: 86\n",
            " [=====================================================================================>]  Step: 77ms | Tot: 46s278ms | Loss: 0.301 | Acc: 92.174% (46087/50000) | Cls: 0.303  391/391 \n",
            "[2022-11-10 18:27:54,291] [train] [Epoch 86] [Loss 0.301] [cls 0.303] [Acc 92.174]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s454ms | Loss: 0.467 | Acc: 86.240% (8624/10000)  79/79 \n",
            "[2022-11-10 18:27:57,180] [val] [Epoch 86] [Loss 0.467] [Acc 86.240]\n",
            "\n",
            "Epoch: 87\n",
            " [=====================================================================================>]  Step: 82ms | Tot: 45s145ms | Loss: 0.300 | Acc: 92.266% (46133/50000) | Cls: 0.302  391/391 \n",
            "[2022-11-10 18:28:43,079] [train] [Epoch 87] [Loss 0.300] [cls 0.302] [Acc 92.266]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s492ms | Loss: 0.463 | Acc: 86.960% (8696/10000)  79/79 \n",
            "[2022-11-10 18:28:45,884] [val] [Epoch 87] [Loss 0.463] [Acc 86.960]\n",
            "\n",
            "Epoch: 88\n",
            " [=====================================================================================>]  Step: 78ms | Tot: 45s224ms | Loss: 0.301 | Acc: 92.286% (46143/50000) | Cls: 0.305  391/391 \n",
            "[2022-11-10 18:29:31,839] [train] [Epoch 88] [Loss 0.301] [cls 0.305] [Acc 92.286]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 3s534ms | Loss: 0.410 | Acc: 88.120% (8812/10000)  79/79 \n",
            "[2022-11-10 18:29:35,765] [val] [Epoch 88] [Loss 0.410] [Acc 88.120]\n",
            "\n",
            "Epoch: 89\n",
            " [=====================================================================================>]  Step: 80ms | Tot: 45s478ms | Loss: 0.302 | Acc: 92.230% (46115/50000) | Cls: 0.304  391/391 \n",
            "[2022-11-10 18:30:22,046] [train] [Epoch 89] [Loss 0.302] [cls 0.304] [Acc 92.230]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s452ms | Loss: 0.461 | Acc: 87.000% (8700/10000)  79/79 \n",
            "[2022-11-10 18:30:24,885] [val] [Epoch 89] [Loss 0.461] [Acc 87.000]\n",
            "\n",
            "Epoch: 90\n",
            " [=====================================================================================>]  Step: 80ms | Tot: 45s266ms | Loss: 0.295 | Acc: 92.462% (46231/50000) | Cls: 0.298  391/391 \n",
            "[2022-11-10 18:31:10,855] [train] [Epoch 90] [Loss 0.295] [cls 0.298] [Acc 92.462]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s603ms | Loss: 0.436 | Acc: 87.610% (8761/10000)  79/79 \n",
            "[2022-11-10 18:31:13,766] [val] [Epoch 90] [Loss 0.436] [Acc 87.610]\n",
            "\n",
            "Epoch: 91\n",
            " [=====================================================================================>]  Step: 74ms | Tot: 44s894ms | Loss: 0.296 | Acc: 92.316% (46158/50000) | Cls: 0.305  391/391 \n",
            "[2022-11-10 18:31:59,466] [train] [Epoch 91] [Loss 0.296] [cls 0.305] [Acc 92.316]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s453ms | Loss: 0.413 | Acc: 88.230% (8823/10000)  79/79 \n",
            "[2022-11-10 18:32:02,304] [val] [Epoch 91] [Loss 0.413] [Acc 88.230]\n",
            "\n",
            "Epoch: 92\n",
            " [=====================================================================================>]  Step: 87ms | Tot: 45s226ms | Loss: 0.302 | Acc: 92.276% (46138/50000) | Cls: 0.306  391/391 \n",
            "[2022-11-10 18:32:48,249] [train] [Epoch 92] [Loss 0.302] [cls 0.306] [Acc 92.276]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s502ms | Loss: 0.450 | Acc: 87.530% (8753/10000)  79/79 \n",
            "[2022-11-10 18:32:51,138] [val] [Epoch 92] [Loss 0.450] [Acc 87.530]\n",
            "\n",
            "Epoch: 93\n",
            " [=====================================================================================>]  Step: 77ms | Tot: 45s499ms | Loss: 0.292 | Acc: 92.506% (46253/50000) | Cls: 0.297  391/391 \n",
            "[2022-11-10 18:33:37,416] [train] [Epoch 93] [Loss 0.292] [cls 0.297] [Acc 92.506]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s506ms | Loss: 0.427 | Acc: 87.710% (8771/10000)  79/79 \n",
            "[2022-11-10 18:33:40,280] [val] [Epoch 93] [Loss 0.427] [Acc 87.710]\n",
            "\n",
            "Epoch: 94\n",
            " [=====================================================================================>]  Step: 84ms | Tot: 46s175ms | Loss: 0.295 | Acc: 92.332% (46166/50000) | Cls: 0.302  391/391 \n",
            "[2022-11-10 18:34:27,228] [train] [Epoch 94] [Loss 0.295] [cls 0.302] [Acc 92.332]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s519ms | Loss: 0.458 | Acc: 87.050% (8705/10000)  79/79 \n",
            "[2022-11-10 18:34:30,050] [val] [Epoch 94] [Loss 0.458] [Acc 87.050]\n",
            "\n",
            "Epoch: 95\n",
            " [=====================================================================================>]  Step: 73ms | Tot: 44s641ms | Loss: 0.287 | Acc: 92.610% (46305/50000) | Cls: 0.294  391/391 \n",
            "[2022-11-10 18:35:15,398] [train] [Epoch 95] [Loss 0.287] [cls 0.294] [Acc 92.610]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s501ms | Loss: 0.374 | Acc: 89.110% (8911/10000)  79/79 \n",
            "[2022-11-10 18:35:18,266] [val] [Epoch 95] [Loss 0.374] [Acc 89.110]\n",
            "Saving..\n",
            "\n",
            "Epoch: 96\n",
            " [=====================================================================================>]  Step: 78ms | Tot: 44s480ms | Loss: 0.289 | Acc: 92.640% (46320/50000) | Cls: 0.298  391/391 \n",
            "[2022-11-10 18:36:03,580] [train] [Epoch 96] [Loss 0.289] [cls 0.298] [Acc 92.640]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s488ms | Loss: 0.450 | Acc: 87.480% (8748/10000)  79/79 \n",
            "[2022-11-10 18:36:06,404] [val] [Epoch 96] [Loss 0.450] [Acc 87.480]\n",
            "\n",
            "Epoch: 97\n",
            " [=====================================================================================>]  Step: 79ms | Tot: 44s823ms | Loss: 0.288 | Acc: 92.608% (46304/50000) | Cls: 0.295  391/391 \n",
            "[2022-11-10 18:36:51,958] [train] [Epoch 97] [Loss 0.288] [cls 0.295] [Acc 92.608]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s447ms | Loss: 0.402 | Acc: 88.110% (8811/10000)  79/79 \n",
            "[2022-11-10 18:36:54,781] [val] [Epoch 97] [Loss 0.402] [Acc 88.110]\n",
            "\n",
            "Epoch: 98\n",
            " [=====================================================================================>]  Step: 79ms | Tot: 45s488ms | Loss: 0.290 | Acc: 92.532% (46266/50000) | Cls: 0.298  391/391 \n",
            "[2022-11-10 18:37:41,052] [train] [Epoch 98] [Loss 0.290] [cls 0.298] [Acc 92.532]\n",
            " [====================================================================================>.]  Step: 10ms | Tot: 2s490ms | Loss: 0.378 | Acc: 89.190% (8919/10000)  79/79 \n",
            "[2022-11-10 18:37:43,928] [val] [Epoch 98] [Loss 0.378] [Acc 89.190]\n",
            "Saving..\n",
            "\n",
            "Epoch: 99\n",
            " [=====================================================================================>]  Step: 77ms | Tot: 47s4ms | Loss: 0.283 | Acc: 92.932% (46466/50000) | Cls: 0.295  391/391 \n",
            "[2022-11-10 18:38:31,751] [train] [Epoch 99] [Loss 0.283] [cls 0.295] [Acc 92.932]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s507ms | Loss: 0.439 | Acc: 87.170% (8717/10000)  79/79 \n",
            "[2022-11-10 18:38:34,648] [val] [Epoch 99] [Loss 0.439] [Acc 87.170]\n",
            "\n",
            "Epoch: 100\n",
            " [=====================================================================================>]  Step: 77ms | Tot: 45s474ms | Loss: 0.286 | Acc: 92.746% (46373/50000) | Cls: 0.294  391/391 \n",
            "[2022-11-10 18:39:20,914] [train] [Epoch 100] [Loss 0.286] [cls 0.294] [Acc 92.746]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s651ms | Loss: 0.421 | Acc: 88.130% (8813/10000)  79/79 \n",
            "[2022-11-10 18:39:23,890] [val] [Epoch 100] [Loss 0.421] [Acc 88.130]\n",
            "\n",
            "Epoch: 101\n",
            " [=====================================================================================>]  Step: 81ms | Tot: 46s77ms | Loss: 0.175 | Acc: 95.958% (47979/50000) | Cls: 0.216  391/391 \n",
            "[2022-11-10 18:40:10,738] [train] [Epoch 101] [Loss 0.175] [cls 0.216] [Acc 95.958]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s561ms | Loss: 0.288 | Acc: 92.030% (9203/10000)  79/79 \n",
            "[2022-11-10 18:40:13,591] [val] [Epoch 101] [Loss 0.288] [Acc 92.030]\n",
            "Saving..\n",
            "\n",
            "Epoch: 102\n",
            " [=====================================================================================>]  Step: 79ms | Tot: 45s544ms | Loss: 0.134 | Acc: 96.906% (48453/50000) | Cls: 0.186  391/391 \n",
            "[2022-11-10 18:41:00,023] [train] [Epoch 102] [Loss 0.134] [cls 0.186] [Acc 96.906]\n",
            " [====================================================================================>.]  Step: 13ms | Tot: 2s502ms | Loss: 0.281 | Acc: 92.240% (9224/10000)  79/79 \n",
            "[2022-11-10 18:41:02,831] [val] [Epoch 102] [Loss 0.281] [Acc 92.240]\n",
            "Saving..\n",
            "\n",
            "Epoch: 103\n",
            " [=====================================================================================>]  Step: 84ms | Tot: 45s850ms | Loss: 0.122 | Acc: 97.228% (48614/50000) | Cls: 0.173  391/391 \n",
            "[2022-11-10 18:41:49,517] [train] [Epoch 103] [Loss 0.122] [cls 0.173] [Acc 97.228]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s486ms | Loss: 0.277 | Acc: 92.270% (9227/10000)  79/79 \n",
            "[2022-11-10 18:41:52,401] [val] [Epoch 103] [Loss 0.277] [Acc 92.270]\n",
            "Saving..\n",
            "\n",
            "Epoch: 104\n",
            " [=====================================================================================>]  Step: 86ms | Tot: 46s858ms | Loss: 0.112 | Acc: 97.468% (48734/50000) | Cls: 0.163  391/391 \n",
            "[2022-11-10 18:42:40,021] [train] [Epoch 104] [Loss 0.112] [cls 0.163] [Acc 97.468]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s557ms | Loss: 0.272 | Acc: 92.490% (9249/10000)  79/79 \n",
            "[2022-11-10 18:42:42,953] [val] [Epoch 104] [Loss 0.272] [Acc 92.490]\n",
            "Saving..\n",
            "\n",
            "Epoch: 105\n",
            " [=====================================================================================>]  Step: 83ms | Tot: 46s545ms | Loss: 0.104 | Acc: 97.716% (48858/50000) | Cls: 0.157  391/391 \n",
            "[2022-11-10 18:43:30,205] [train] [Epoch 105] [Loss 0.104] [cls 0.157] [Acc 97.716]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s457ms | Loss: 0.279 | Acc: 92.410% (9241/10000)  79/79 \n",
            "[2022-11-10 18:43:33,036] [val] [Epoch 105] [Loss 0.279] [Acc 92.410]\n",
            "\n",
            "Epoch: 106\n",
            " [=====================================================================================>]  Step: 84ms | Tot: 46s439ms | Loss: 0.101 | Acc: 97.808% (48904/50000) | Cls: 0.149  391/391 \n",
            "[2022-11-10 18:44:20,205] [train] [Epoch 106] [Loss 0.101] [cls 0.149] [Acc 97.808]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s561ms | Loss: 0.278 | Acc: 92.470% (9247/10000)  79/79 \n",
            "[2022-11-10 18:44:23,129] [val] [Epoch 106] [Loss 0.278] [Acc 92.470]\n",
            "\n",
            "Epoch: 107\n",
            " [=====================================================================================>]  Step: 81ms | Tot: 46s285ms | Loss: 0.093 | Acc: 98.044% (49022/50000) | Cls: 0.142  391/391 \n",
            "[2022-11-10 18:45:10,260] [train] [Epoch 107] [Loss 0.093] [cls 0.142] [Acc 98.044]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s612ms | Loss: 0.279 | Acc: 92.370% (9237/10000)  79/79 \n",
            "[2022-11-10 18:45:13,224] [val] [Epoch 107] [Loss 0.279] [Acc 92.370]\n",
            "\n",
            "Epoch: 108\n",
            " [=====================================================================================>]  Step: 74ms | Tot: 46s214ms | Loss: 0.086 | Acc: 98.132% (49066/50000) | Cls: 0.140  391/391 \n",
            "[2022-11-10 18:46:00,175] [train] [Epoch 108] [Loss 0.086] [cls 0.140] [Acc 98.132]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s528ms | Loss: 0.275 | Acc: 92.590% (9259/10000)  79/79 \n",
            "[2022-11-10 18:46:03,105] [val] [Epoch 108] [Loss 0.275] [Acc 92.590]\n",
            "Saving..\n",
            "\n",
            "Epoch: 109\n",
            " [=====================================================================================>]  Step: 78ms | Tot: 47s9ms | Loss: 0.083 | Acc: 98.232% (49116/50000) | Cls: 0.135  391/391 \n",
            "[2022-11-10 18:46:50,979] [train] [Epoch 109] [Loss 0.083] [cls 0.135] [Acc 98.232]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s641ms | Loss: 0.275 | Acc: 92.450% (9245/10000)  79/79 \n",
            "[2022-11-10 18:46:53,939] [val] [Epoch 109] [Loss 0.275] [Acc 92.450]\n",
            "\n",
            "Epoch: 110\n",
            " [=====================================================================================>]  Step: 81ms | Tot: 46s881ms | Loss: 0.083 | Acc: 98.224% (49112/50000) | Cls: 0.132  391/391 \n",
            "[2022-11-10 18:47:41,612] [train] [Epoch 110] [Loss 0.083] [cls 0.132] [Acc 98.224]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s562ms | Loss: 0.283 | Acc: 92.580% (9258/10000)  79/79 \n",
            "[2022-11-10 18:47:44,550] [val] [Epoch 110] [Loss 0.283] [Acc 92.580]\n",
            "\n",
            "Epoch: 111\n",
            " [=====================================================================================>]  Step: 79ms | Tot: 46s579ms | Loss: 0.078 | Acc: 98.362% (49181/50000) | Cls: 0.129  391/391 \n",
            "[2022-11-10 18:48:31,873] [train] [Epoch 111] [Loss 0.078] [cls 0.129] [Acc 98.362]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s592ms | Loss: 0.276 | Acc: 92.620% (9262/10000)  79/79 \n",
            "[2022-11-10 18:48:34,817] [val] [Epoch 111] [Loss 0.276] [Acc 92.620]\n",
            "Saving..\n",
            "\n",
            "Epoch: 112\n",
            " [=====================================================================================>]  Step: 81ms | Tot: 46s489ms | Loss: 0.076 | Acc: 98.420% (49210/50000) | Cls: 0.122  391/391 \n",
            "[2022-11-10 18:49:22,036] [train] [Epoch 112] [Loss 0.076] [cls 0.122] [Acc 98.420]\n",
            " [====================================================================================>.]  Step: 11ms | Tot: 2s565ms | Loss: 0.284 | Acc: 92.390% (9239/10000)  79/79 \n",
            "[2022-11-10 18:49:24,910] [val] [Epoch 112] [Loss 0.284] [Acc 92.390]\n",
            "\n",
            "Epoch: 113\n",
            " [=====================================================================================>]  Step: 77ms | Tot: 46s401ms | Loss: 0.071 | Acc: 98.466% (49233/50000) | Cls: 0.121  391/391 \n",
            "[2022-11-10 18:50:12,104] [train] [Epoch 113] [Loss 0.071] [cls 0.121] [Acc 98.466]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s533ms | Loss: 0.278 | Acc: 92.570% (9257/10000)  79/79 \n",
            "[2022-11-10 18:50:14,987] [val] [Epoch 113] [Loss 0.278] [Acc 92.570]\n",
            "\n",
            "Epoch: 114\n",
            " [=====================================================================================>]  Step: 77ms | Tot: 47s605ms | Loss: 0.070 | Acc: 98.578% (49289/50000) | Cls: 0.118  391/391 \n",
            "[2022-11-10 18:51:03,378] [train] [Epoch 114] [Loss 0.070] [cls 0.118] [Acc 98.578]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s660ms | Loss: 0.285 | Acc: 92.540% (9254/10000)  79/79 \n",
            "[2022-11-10 18:51:06,337] [val] [Epoch 114] [Loss 0.285] [Acc 92.540]\n",
            "\n",
            "Epoch: 115\n",
            " [=====================================================================================>]  Step: 80ms | Tot: 46s987ms | Loss: 0.067 | Acc: 98.652% (49326/50000) | Cls: 0.115  391/391 \n",
            "[2022-11-10 18:51:54,103] [train] [Epoch 115] [Loss 0.067] [cls 0.115] [Acc 98.652]\n",
            " [====================================================================================>.]  Step: 10ms | Tot: 2s606ms | Loss: 0.288 | Acc: 92.410% (9241/10000)  79/79 \n",
            "[2022-11-10 18:51:57,111] [val] [Epoch 115] [Loss 0.288] [Acc 92.410]\n",
            "\n",
            "Epoch: 116\n",
            " [=====================================================================================>]  Step: 66ms | Tot: 47s138ms | Loss: 0.064 | Acc: 98.672% (49336/50000) | Cls: 0.115  391/391 \n",
            "[2022-11-10 18:52:45,053] [train] [Epoch 116] [Loss 0.064] [cls 0.115] [Acc 98.672]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s611ms | Loss: 0.293 | Acc: 92.380% (9238/10000)  79/79 \n",
            "[2022-11-10 18:52:48,016] [val] [Epoch 116] [Loss 0.293] [Acc 92.380]\n",
            "\n",
            "Epoch: 117\n",
            " [=====================================================================================>]  Step: 82ms | Tot: 46s813ms | Loss: 0.063 | Acc: 98.708% (49354/50000) | Cls: 0.110  391/391 \n",
            "[2022-11-10 18:53:35,604] [train] [Epoch 117] [Loss 0.063] [cls 0.110] [Acc 98.708]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s629ms | Loss: 0.290 | Acc: 92.550% (9255/10000)  79/79 \n",
            "[2022-11-10 18:53:38,609] [val] [Epoch 117] [Loss 0.290] [Acc 92.550]\n",
            "\n",
            "Epoch: 118\n",
            " [=====================================================================================>]  Step: 75ms | Tot: 46s845ms | Loss: 0.060 | Acc: 98.742% (49371/50000) | Cls: 0.105  391/391 \n",
            "[2022-11-10 18:54:26,219] [train] [Epoch 118] [Loss 0.060] [cls 0.105] [Acc 98.742]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s624ms | Loss: 0.300 | Acc: 92.240% (9224/10000)  79/79 \n",
            "[2022-11-10 18:54:29,157] [val] [Epoch 118] [Loss 0.300] [Acc 92.240]\n",
            "\n",
            "Epoch: 119\n",
            " [=====================================================================================>]  Step: 77ms | Tot: 47s705ms | Loss: 0.060 | Acc: 98.750% (49375/50000) | Cls: 0.109  391/391 \n",
            "[2022-11-10 18:55:17,600] [train] [Epoch 119] [Loss 0.060] [cls 0.109] [Acc 98.750]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s588ms | Loss: 0.296 | Acc: 92.410% (9241/10000)  79/79 \n",
            "[2022-11-10 18:55:20,556] [val] [Epoch 119] [Loss 0.296] [Acc 92.410]\n",
            "\n",
            "Epoch: 120\n",
            " [=====================================================================================>]  Step: 80ms | Tot: 46s653ms | Loss: 0.057 | Acc: 98.866% (49433/50000) | Cls: 0.106  391/391 \n",
            "[2022-11-10 18:56:08,030] [train] [Epoch 120] [Loss 0.057] [cls 0.106] [Acc 98.866]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s591ms | Loss: 0.290 | Acc: 92.490% (9249/10000)  79/79 \n",
            "[2022-11-10 18:56:11,033] [val] [Epoch 120] [Loss 0.290] [Acc 92.490]\n",
            "\n",
            "Epoch: 121\n",
            " [=====================================================================================>]  Step: 74ms | Tot: 46s515ms | Loss: 0.059 | Acc: 98.792% (49396/50000) | Cls: 0.104  391/391 \n",
            "[2022-11-10 18:56:58,342] [train] [Epoch 121] [Loss 0.059] [cls 0.104] [Acc 98.792]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s532ms | Loss: 0.309 | Acc: 92.060% (9206/10000)  79/79 \n",
            "[2022-11-10 18:57:01,261] [val] [Epoch 121] [Loss 0.309] [Acc 92.060]\n",
            "\n",
            "Epoch: 122\n",
            " [=====================================================================================>]  Step: 79ms | Tot: 46s129ms | Loss: 0.056 | Acc: 98.872% (49436/50000) | Cls: 0.104  391/391 \n",
            "[2022-11-10 18:57:48,206] [train] [Epoch 122] [Loss 0.056] [cls 0.104] [Acc 98.872]\n",
            " [====================================================================================>.]  Step: 13ms | Tot: 2s520ms | Loss: 0.297 | Acc: 92.410% (9241/10000)  79/79 \n",
            "[2022-11-10 18:57:51,081] [val] [Epoch 122] [Loss 0.297] [Acc 92.410]\n",
            "\n",
            "Epoch: 123\n",
            " [=====================================================================================>]  Step: 82ms | Tot: 46s447ms | Loss: 0.057 | Acc: 98.820% (49410/50000) | Cls: 0.104  391/391 \n",
            "[2022-11-10 18:58:38,273] [train] [Epoch 123] [Loss 0.057] [cls 0.104] [Acc 98.820]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s715ms | Loss: 0.291 | Acc: 92.570% (9257/10000)  79/79 \n",
            "[2022-11-10 18:58:41,349] [val] [Epoch 123] [Loss 0.291] [Acc 92.570]\n",
            "\n",
            "Epoch: 124\n",
            " [=====================================================================================>]  Step: 78ms | Tot: 46s924ms | Loss: 0.056 | Acc: 98.818% (49409/50000) | Cls: 0.104  391/391 \n",
            "[2022-11-10 18:59:29,138] [train] [Epoch 124] [Loss 0.056] [cls 0.104] [Acc 98.818]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s450ms | Loss: 0.302 | Acc: 92.530% (9253/10000)  79/79 \n",
            "[2022-11-10 18:59:31,916] [val] [Epoch 124] [Loss 0.302] [Acc 92.530]\n",
            "\n",
            "Epoch: 125\n",
            " [=====================================================================================>]  Step: 82ms | Tot: 45s525ms | Loss: 0.055 | Acc: 98.920% (49460/50000) | Cls: 0.100  391/391 \n",
            "[2022-11-10 19:00:18,230] [train] [Epoch 125] [Loss 0.055] [cls 0.100] [Acc 98.920]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s564ms | Loss: 0.312 | Acc: 92.120% (9212/10000)  79/79 \n",
            "[2022-11-10 19:00:21,126] [val] [Epoch 125] [Loss 0.312] [Acc 92.120]\n",
            "\n",
            "Epoch: 126\n",
            " [=====================================================================================>]  Step: 80ms | Tot: 45s954ms | Loss: 0.049 | Acc: 99.040% (49520/50000) | Cls: 0.099  391/391 \n",
            "[2022-11-10 19:01:07,796] [train] [Epoch 126] [Loss 0.049] [cls 0.099] [Acc 99.040]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s516ms | Loss: 0.321 | Acc: 92.140% (9214/10000)  79/79 \n",
            "[2022-11-10 19:01:10,702] [val] [Epoch 126] [Loss 0.321] [Acc 92.140]\n",
            "\n",
            "Epoch: 127\n",
            "Traceback (most recent call last):\n",
            "  File \"Learning-With-Retrospection/CS-KD_techinque/cs-kd/train.py\", line 229, in <module>\n",
            "    train_loss, train_acc, train_cls_loss = train(epoch)\n",
            "  File \"Learning-With-Retrospection/CS-KD_techinque/cs-kd/train.py\", line 132, in train\n",
            "    outputs = net(inputs[:batch_size//2])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/Learning-With-Retrospection/CS-KD_techinque/cs-kd/models/resnet.py\", line 115, in forward\n",
            "    out = self.layer3(out)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\", line 139, in forward\n",
            "    input = module(input)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/Learning-With-Retrospection/CS-KD_techinque/cs-kd/models/resnet.py\", line 77, in forward\n",
            "    out = F.relu(self.bn1(self.conv1(x)))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\", line 457, in forward\n",
            "    return self._conv_forward(input, self.weight, self.bias)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\", line 454, in _conv_forward\n",
            "    self.padding, self.dilation, self.groups)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!python Learning-With-Retrospection/CS-KD_techinque/cs-kd/train.py --sgpu 0 --lr 0.1 --epoch 200 --model resnet56 --name cifar10_resnet56 --decay 1e-4 --dataset cifar10 --dataroot ~/data/ -cls --lamda 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8N_S6WrIh-Oh",
        "outputId": "e482ff5d-03a4-41fc-cbf0-1badb99ba3b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==> Preparing dataset: cifar10\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /root/data/cifar-10-python.tar.gz\n",
            "100% 170498071/170498071 [00:14<00:00, 11845116.70it/s]\n",
            "Extracting /root/data/cifar-10-python.tar.gz to /root/data/\n",
            "Files already downloaded and verified\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Number of train dataset:  50000\n",
            "Number of validation dataset:  10000\n",
            "==> Building model: resnet56\n",
            "1\n",
            "Using CUDA..\n",
            "\"./results/cifar10/resnet56/cifar10_resnet56\" exists. Overwrite [Y/n]? Y\n",
            "[2022-11-13 15:17:32,911] [main] Learning-With-Retrospection/CS-KD_techinque/cs-kd/train.py --resume --sgpu 0 --lr 0.1 --epoch 200 --model resnet56 --name cifar10_resnet56 --decay 1e-4 --dataset cifar10 --dataroot /root/data/ -cls --lamda 1\n",
            "[2022-11-13 15:17:32,912] [main] Namespace(batch_size=128, cls=True, dataroot='/root/data/', dataset='cifar10', decay=0.0001, epoch=200, lamda=1.0, lr=0.1, model='resnet56', name='cifar10_resnet56', ngpu=1, resume=True, saveroot='./results', sgpu=0, temp=4.0)\n",
            "==> Resuming from checkpoint..\n",
            "\n",
            "Epoch: 112\n",
            " [=====================================================================================>]  Step: 172ms | Tot: 43s262ms | Loss: 0.074 | Acc: 98.448% (49224/50000) | Cls: 0.123  391/391 \n",
            "[2022-11-13 15:18:24,187] [train] [Epoch 112] [Loss 0.074] [cls 0.123] [Acc 98.448]\n",
            " [====================================================================================>.]  Step: 35ms | Tot: 3s138ms | Loss: 0.277 | Acc: 92.710% (9271/10000)  79/79 \n",
            "[2022-11-13 15:18:27,797] [val] [Epoch 112] [Loss 0.277] [Acc 92.710]\n",
            "Saving..\n",
            "\n",
            "Epoch: 113\n",
            " [=====================================================================================>]  Step: 73ms | Tot: 43s108ms | Loss: 0.073 | Acc: 98.526% (49263/50000) | Cls: 0.116  391/391 \n",
            "[2022-11-13 15:19:12,212] [train] [Epoch 113] [Loss 0.073] [cls 0.116] [Acc 98.526]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s308ms | Loss: 0.280 | Acc: 92.640% (9264/10000)  79/79 \n",
            "[2022-11-13 15:19:14,929] [val] [Epoch 113] [Loss 0.280] [Acc 92.640]\n",
            "\n",
            "Epoch: 114\n",
            " [=====================================================================================>]  Step: 75ms | Tot: 44s540ms | Loss: 0.070 | Acc: 98.516% (49258/50000) | Cls: 0.122  391/391 \n",
            "[2022-11-13 15:20:00,232] [train] [Epoch 114] [Loss 0.070] [cls 0.122] [Acc 98.516]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s318ms | Loss: 0.281 | Acc: 92.570% (9257/10000)  79/79 \n",
            "[2022-11-13 15:20:02,949] [val] [Epoch 114] [Loss 0.281] [Acc 92.570]\n",
            "\n",
            "Epoch: 115\n",
            " [=====================================================================================>]  Step: 74ms | Tot: 44s473ms | Loss: 0.069 | Acc: 98.636% (49318/50000) | Cls: 0.112  391/391 \n",
            "[2022-11-13 15:20:48,139] [train] [Epoch 115] [Loss 0.069] [cls 0.112] [Acc 98.636]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s337ms | Loss: 0.287 | Acc: 92.470% (9247/10000)  79/79 \n",
            "[2022-11-13 15:20:50,903] [val] [Epoch 115] [Loss 0.287] [Acc 92.470]\n",
            "\n",
            "Epoch: 116\n",
            " [=====================================================================================>]  Step: 74ms | Tot: 44s719ms | Loss: 0.065 | Acc: 98.670% (49335/50000) | Cls: 0.112  391/391 \n",
            "[2022-11-13 15:21:36,430] [train] [Epoch 116] [Loss 0.065] [cls 0.112] [Acc 98.670]\n",
            " [====================================================================================>.]  Step: 10ms | Tot: 2s397ms | Loss: 0.279 | Acc: 92.700% (9270/10000)  79/79 \n",
            "[2022-11-13 15:21:39,183] [val] [Epoch 116] [Loss 0.279] [Acc 92.700]\n",
            "\n",
            "Epoch: 117\n",
            " [=====================================================================================>]  Step: 75ms | Tot: 43s477ms | Loss: 0.061 | Acc: 98.724% (49362/50000) | Cls: 0.110  391/391 \n",
            "[2022-11-13 15:22:23,412] [train] [Epoch 117] [Loss 0.061] [cls 0.110] [Acc 98.724]\n",
            " [====================================================================================>.]  Step: 11ms | Tot: 3s71ms | Loss: 0.294 | Acc: 92.420% (9242/10000)  79/79 \n",
            "[2022-11-13 15:22:26,941] [val] [Epoch 117] [Loss 0.294] [Acc 92.420]\n",
            "\n",
            "Epoch: 118\n",
            " [=====================================================================================>]  Step: 80ms | Tot: 43s895ms | Loss: 0.062 | Acc: 98.742% (49371/50000) | Cls: 0.109  391/391 \n",
            "[2022-11-13 15:23:11,918] [train] [Epoch 118] [Loss 0.062] [cls 0.109] [Acc 98.742]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s301ms | Loss: 0.299 | Acc: 92.030% (9203/10000)  79/79 \n",
            "[2022-11-13 15:23:14,634] [val] [Epoch 118] [Loss 0.299] [Acc 92.030]\n",
            "\n",
            "Epoch: 119\n",
            " [=====================================================================================>]  Step: 76ms | Tot: 44s576ms | Loss: 0.059 | Acc: 98.874% (49437/50000) | Cls: 0.110  391/391 \n",
            "[2022-11-13 15:24:00,003] [train] [Epoch 119] [Loss 0.059] [cls 0.110] [Acc 98.874]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s443ms | Loss: 0.293 | Acc: 92.550% (9255/10000)  79/79 \n",
            "[2022-11-13 15:24:02,758] [val] [Epoch 119] [Loss 0.293] [Acc 92.550]\n",
            "\n",
            "Epoch: 120\n",
            " [=====================================================================================>]  Step: 82ms | Tot: 44s993ms | Loss: 0.059 | Acc: 98.832% (49416/50000) | Cls: 0.111  391/391 \n",
            "[2022-11-13 15:24:48,519] [train] [Epoch 120] [Loss 0.059] [cls 0.111] [Acc 98.832]\n",
            " [====================================================================================>.]  Step: 11ms | Tot: 2s412ms | Loss: 0.296 | Acc: 92.390% (9239/10000)  79/79 \n",
            "[2022-11-13 15:24:51,320] [val] [Epoch 120] [Loss 0.296] [Acc 92.390]\n",
            "\n",
            "Epoch: 121\n",
            " [=====================================================================================>]  Step: 64ms | Tot: 45s35ms | Loss: 0.055 | Acc: 98.962% (49481/50000) | Cls: 0.100  391/391 \n",
            "[2022-11-13 15:25:37,093] [train] [Epoch 121] [Loss 0.055] [cls 0.100] [Acc 98.962]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s454ms | Loss: 0.297 | Acc: 92.520% (9252/10000)  79/79 \n",
            "[2022-11-13 15:25:39,890] [val] [Epoch 121] [Loss 0.297] [Acc 92.520]\n",
            "\n",
            "Epoch: 122\n",
            " [=====================================================================================>]  Step: 74ms | Tot: 43s325ms | Loss: 0.056 | Acc: 98.850% (49425/50000) | Cls: 0.104  391/391 \n",
            "[2022-11-13 15:26:23,985] [train] [Epoch 122] [Loss 0.056] [cls 0.104] [Acc 98.850]\n",
            " [====================================================================================>.]  Step: 19ms | Tot: 3s225ms | Loss: 0.308 | Acc: 92.300% (9230/10000)  79/79 \n",
            "[2022-11-13 15:26:27,622] [val] [Epoch 122] [Loss 0.308] [Acc 92.300]\n",
            "\n",
            "Epoch: 123\n",
            " [=====================================================================================>]  Step: 80ms | Tot: 43s710ms | Loss: 0.054 | Acc: 98.932% (49466/50000) | Cls: 0.103  391/391 \n",
            "[2022-11-13 15:27:12,554] [train] [Epoch 123] [Loss 0.054] [cls 0.103] [Acc 98.932]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s337ms | Loss: 0.300 | Acc: 92.390% (9239/10000)  79/79 \n",
            "[2022-11-13 15:27:15,286] [val] [Epoch 123] [Loss 0.300] [Acc 92.390]\n",
            "\n",
            "Epoch: 124\n",
            " [=====================================================================================>]  Step: 79ms | Tot: 45s152ms | Loss: 0.057 | Acc: 98.796% (49398/50000) | Cls: 0.107  391/391 \n",
            "[2022-11-13 15:28:01,231] [train] [Epoch 124] [Loss 0.057] [cls 0.107] [Acc 98.796]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s363ms | Loss: 0.308 | Acc: 92.260% (9226/10000)  79/79 \n",
            "[2022-11-13 15:28:03,984] [val] [Epoch 124] [Loss 0.308] [Acc 92.260]\n",
            "\n",
            "Epoch: 125\n",
            " [=====================================================================================>]  Step: 76ms | Tot: 44s968ms | Loss: 0.052 | Acc: 98.978% (49489/50000) | Cls: 0.099  391/391 \n",
            "[2022-11-13 15:28:49,580] [train] [Epoch 125] [Loss 0.052] [cls 0.099] [Acc 98.978]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s376ms | Loss: 0.308 | Acc: 92.370% (9237/10000)  79/79 \n",
            "[2022-11-13 15:28:52,378] [val] [Epoch 125] [Loss 0.308] [Acc 92.370]\n",
            "\n",
            "Epoch: 126\n",
            " [=====================================================================================>]  Step: 74ms | Tot: 45s114ms | Loss: 0.055 | Acc: 98.904% (49452/50000) | Cls: 0.101  391/391 \n",
            "[2022-11-13 15:29:38,299] [train] [Epoch 126] [Loss 0.055] [cls 0.101] [Acc 98.904]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s803ms | Loss: 0.298 | Acc: 92.450% (9245/10000)  79/79 \n",
            "[2022-11-13 15:29:41,422] [val] [Epoch 126] [Loss 0.298] [Acc 92.450]\n",
            "\n",
            "Epoch: 127\n",
            " [=====================================================================================>]  Step: 75ms | Tot: 43s533ms | Loss: 0.050 | Acc: 99.008% (49504/50000) | Cls: 0.099  391/391 \n",
            "[2022-11-13 15:30:25,724] [train] [Epoch 127] [Loss 0.050] [cls 0.099] [Acc 99.008]\n",
            " [====================================================================================>.]  Step: 11ms | Tot: 3s367ms | Loss: 0.310 | Acc: 92.110% (9211/10000)  79/79 \n",
            "[2022-11-13 15:30:29,515] [val] [Epoch 127] [Loss 0.310] [Acc 92.110]\n",
            "\n",
            "Epoch: 128\n",
            " [=====================================================================================>]  Step: 75ms | Tot: 43s884ms | Loss: 0.050 | Acc: 99.070% (49535/50000) | Cls: 0.093  391/391 \n",
            "[2022-11-13 15:31:14,487] [train] [Epoch 128] [Loss 0.050] [cls 0.093] [Acc 99.070]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s407ms | Loss: 0.317 | Acc: 92.150% (9215/10000)  79/79 \n",
            "[2022-11-13 15:31:17,299] [val] [Epoch 128] [Loss 0.317] [Acc 92.150]\n",
            "\n",
            "Epoch: 129\n",
            " [=====================================================================================>]  Step: 74ms | Tot: 45s174ms | Loss: 0.048 | Acc: 99.070% (49535/50000) | Cls: 0.093  391/391 \n",
            "[2022-11-13 15:32:03,263] [train] [Epoch 129] [Loss 0.048] [cls 0.093] [Acc 99.070]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s330ms | Loss: 0.320 | Acc: 92.270% (9227/10000)  79/79 \n",
            "[2022-11-13 15:32:06,014] [val] [Epoch 129] [Loss 0.320] [Acc 92.270]\n",
            "\n",
            "Epoch: 130\n",
            " [=====================================================================================>]  Step: 78ms | Tot: 45s497ms | Loss: 0.051 | Acc: 99.012% (49506/50000) | Cls: 0.102  391/391 \n",
            "[2022-11-13 15:32:52,232] [train] [Epoch 130] [Loss 0.051] [cls 0.102] [Acc 99.012]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s505ms | Loss: 0.309 | Acc: 92.420% (9242/10000)  79/79 \n",
            "[2022-11-13 15:32:55,077] [val] [Epoch 130] [Loss 0.309] [Acc 92.420]\n",
            "\n",
            "Epoch: 131\n",
            " [=====================================================================================>]  Step: 77ms | Tot: 45s197ms | Loss: 0.050 | Acc: 99.008% (49504/50000) | Cls: 0.092  391/391 \n",
            "[2022-11-13 15:33:41,097] [train] [Epoch 131] [Loss 0.050] [cls 0.092] [Acc 99.008]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s448ms | Loss: 0.307 | Acc: 92.420% (9242/10000)  79/79 \n",
            "[2022-11-13 15:33:43,888] [val] [Epoch 131] [Loss 0.307] [Acc 92.420]\n",
            "\n",
            "Epoch: 132\n",
            " [=====================================================================================>]  Step: 86ms | Tot: 44s531ms | Loss: 0.049 | Acc: 99.050% (49525/50000) | Cls: 0.094  391/391 \n",
            "[2022-11-13 15:34:29,205] [train] [Epoch 132] [Loss 0.049] [cls 0.094] [Acc 99.050]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s588ms | Loss: 0.305 | Acc: 92.480% (9248/10000)  79/79 \n",
            "[2022-11-13 15:34:32,366] [val] [Epoch 132] [Loss 0.305] [Acc 92.480]\n",
            "\n",
            "Epoch: 133\n",
            " [=====================================================================================>]  Step: 77ms | Tot: 43s844ms | Loss: 0.049 | Acc: 99.046% (49523/50000) | Cls: 0.092  391/391 \n",
            "[2022-11-13 15:35:16,914] [train] [Epoch 133] [Loss 0.049] [cls 0.092] [Acc 99.046]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s483ms | Loss: 0.311 | Acc: 92.480% (9248/10000)  79/79 \n",
            "[2022-11-13 15:35:19,804] [val] [Epoch 133] [Loss 0.311] [Acc 92.480]\n",
            "\n",
            "Epoch: 134\n",
            " [=====================================================================================>]  Step: 76ms | Tot: 45s4ms | Loss: 0.047 | Acc: 99.098% (49549/50000) | Cls: 0.091  391/391 \n",
            "[2022-11-13 15:36:05,566] [train] [Epoch 134] [Loss 0.047] [cls 0.091] [Acc 99.098]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s312ms | Loss: 0.306 | Acc: 92.310% (9231/10000)  79/79 \n",
            "[2022-11-13 15:36:08,273] [val] [Epoch 134] [Loss 0.306] [Acc 92.310]\n",
            "\n",
            "Epoch: 135\n",
            " [=====================================================================================>]  Step: 80ms | Tot: 45s188ms | Loss: 0.047 | Acc: 99.082% (49541/50000) | Cls: 0.091  391/391 \n",
            "[2022-11-13 15:36:54,273] [train] [Epoch 135] [Loss 0.047] [cls 0.091] [Acc 99.082]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s393ms | Loss: 0.325 | Acc: 92.090% (9209/10000)  79/79 \n",
            "[2022-11-13 15:36:57,056] [val] [Epoch 135] [Loss 0.325] [Acc 92.090]\n",
            "\n",
            "Epoch: 136\n",
            " [=====================================================================================>]  Step: 76ms | Tot: 45s265ms | Loss: 0.052 | Acc: 99.008% (49504/50000) | Cls: 0.095  391/391 \n",
            "[2022-11-13 15:37:43,123] [train] [Epoch 136] [Loss 0.052] [cls 0.095] [Acc 99.008]\n",
            " [====================================================================================>.]  Step: 12ms | Tot: 2s355ms | Loss: 0.309 | Acc: 92.340% (9234/10000)  79/79 \n",
            "[2022-11-13 15:37:45,865] [val] [Epoch 136] [Loss 0.309] [Acc 92.340]\n",
            "\n",
            "Epoch: 137\n",
            " [=====================================================================================>]  Step: 83ms | Tot: 45s279ms | Loss: 0.048 | Acc: 99.084% (49542/50000) | Cls: 0.091  391/391 \n",
            "[2022-11-13 15:38:31,949] [train] [Epoch 137] [Loss 0.048] [cls 0.091] [Acc 99.084]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s419ms | Loss: 0.308 | Acc: 92.330% (9233/10000)  79/79 \n",
            "[2022-11-13 15:38:34,775] [val] [Epoch 137] [Loss 0.308] [Acc 92.330]\n",
            "\n",
            "Epoch: 138\n",
            " [=====================================================================================>]  Step: 76ms | Tot: 44s136ms | Loss: 0.048 | Acc: 99.060% (49530/50000) | Cls: 0.093  391/391 \n",
            "[2022-11-13 15:39:19,765] [train] [Epoch 138] [Loss 0.048] [cls 0.093] [Acc 99.060]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s592ms | Loss: 0.318 | Acc: 92.130% (9213/10000)  79/79 \n",
            "[2022-11-13 15:39:22,703] [val] [Epoch 138] [Loss 0.318] [Acc 92.130]\n",
            "\n",
            "Epoch: 139\n",
            " [=====================================================================================>]  Step: 79ms | Tot: 45s342ms | Loss: 0.050 | Acc: 98.982% (49491/50000) | Cls: 0.099  391/391 \n",
            "[2022-11-13 15:40:08,808] [train] [Epoch 139] [Loss 0.050] [cls 0.099] [Acc 98.982]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s460ms | Loss: 0.329 | Acc: 92.140% (9214/10000)  79/79 \n",
            "[2022-11-13 15:40:11,638] [val] [Epoch 139] [Loss 0.329] [Acc 92.140]\n",
            "\n",
            "Epoch: 140\n",
            " [=====================================================================================>]  Step: 77ms | Tot: 45s597ms | Loss: 0.045 | Acc: 99.104% (49552/50000) | Cls: 0.095  391/391 \n",
            "[2022-11-13 15:40:57,961] [train] [Epoch 140] [Loss 0.045] [cls 0.095] [Acc 99.104]\n",
            " [====================================================================================>.]  Step: 12ms | Tot: 2s419ms | Loss: 0.326 | Acc: 92.020% (9202/10000)  79/79 \n",
            "[2022-11-13 15:41:00,758] [val] [Epoch 140] [Loss 0.326] [Acc 92.020]\n",
            "\n",
            "Epoch: 141\n",
            " [=====================================================================================>]  Step: 75ms | Tot: 45s171ms | Loss: 0.045 | Acc: 99.114% (49557/50000) | Cls: 0.095  391/391 \n",
            "[2022-11-13 15:41:46,642] [train] [Epoch 141] [Loss 0.045] [cls 0.095] [Acc 99.114]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s404ms | Loss: 0.318 | Acc: 91.960% (9196/10000)  79/79 \n",
            "[2022-11-13 15:41:49,442] [val] [Epoch 141] [Loss 0.318] [Acc 91.960]\n",
            "\n",
            "Epoch: 142\n",
            " [=====================================================================================>]  Step: 76ms | Tot: 45s255ms | Loss: 0.051 | Acc: 99.000% (49500/50000) | Cls: 0.093  391/391 \n",
            "[2022-11-13 15:42:35,516] [train] [Epoch 142] [Loss 0.051] [cls 0.093] [Acc 99.000]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s478ms | Loss: 0.314 | Acc: 92.340% (9234/10000)  79/79 \n",
            "[2022-11-13 15:42:38,375] [val] [Epoch 142] [Loss 0.314] [Acc 92.340]\n",
            "\n",
            "Epoch: 143\n",
            " [=====================================================================================>]  Step: 76ms | Tot: 44s254ms | Loss: 0.047 | Acc: 99.086% (49543/50000) | Cls: 0.095  391/391 \n",
            "[2022-11-13 15:43:23,469] [train] [Epoch 143] [Loss 0.047] [cls 0.095] [Acc 99.086]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s653ms | Loss: 0.321 | Acc: 92.090% (9209/10000)  79/79 \n",
            "[2022-11-13 15:43:26,500] [val] [Epoch 143] [Loss 0.321] [Acc 92.090]\n",
            "\n",
            "Epoch: 144\n",
            " [=====================================================================================>]  Step: 77ms | Tot: 46s24ms | Loss: 0.044 | Acc: 99.134% (49567/50000) | Cls: 0.091  391/391 \n",
            "[2022-11-13 15:44:13,365] [train] [Epoch 144] [Loss 0.044] [cls 0.091] [Acc 99.134]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s462ms | Loss: 0.326 | Acc: 91.920% (9192/10000)  79/79 \n",
            "[2022-11-13 15:44:16,161] [val] [Epoch 144] [Loss 0.326] [Acc 91.920]\n",
            "\n",
            "Epoch: 145\n",
            " [=====================================================================================>]  Step: 79ms | Tot: 45s669ms | Loss: 0.047 | Acc: 99.028% (49514/50000) | Cls: 0.095  391/391 \n",
            "[2022-11-13 15:45:02,561] [train] [Epoch 145] [Loss 0.047] [cls 0.095] [Acc 99.028]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s462ms | Loss: 0.328 | Acc: 91.880% (9188/10000)  79/79 \n",
            "[2022-11-13 15:45:05,348] [val] [Epoch 145] [Loss 0.328] [Acc 91.880]\n",
            "\n",
            "Epoch: 146\n",
            " [=====================================================================================>]  Step: 74ms | Tot: 44s984ms | Loss: 0.047 | Acc: 99.068% (49534/50000) | Cls: 0.090  391/391 \n",
            "[2022-11-13 15:45:51,094] [train] [Epoch 146] [Loss 0.047] [cls 0.090] [Acc 99.068]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s394ms | Loss: 0.321 | Acc: 92.110% (9211/10000)  79/79 \n",
            "[2022-11-13 15:45:53,899] [val] [Epoch 146] [Loss 0.321] [Acc 92.110]\n",
            "\n",
            "Epoch: 147\n",
            " [=====================================================================================>]  Step: 75ms | Tot: 46s3ms | Loss: 0.046 | Acc: 99.098% (49549/50000) | Cls: 0.091  391/391 \n",
            "[2022-11-13 15:46:40,556] [train] [Epoch 147] [Loss 0.046] [cls 0.091] [Acc 99.098]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s364ms | Loss: 0.359 | Acc: 91.340% (9134/10000)  79/79 \n",
            "[2022-11-13 15:46:43,320] [val] [Epoch 147] [Loss 0.359] [Acc 91.340]\n",
            "\n",
            "Epoch: 148\n",
            " [=====================================================================================>]  Step: 77ms | Tot: 43s755ms | Loss: 0.048 | Acc: 99.056% (49528/50000) | Cls: 0.096  391/391 \n",
            "[2022-11-13 15:47:27,929] [train] [Epoch 148] [Loss 0.048] [cls 0.096] [Acc 99.056]\n",
            " [====================================================================================>.]  Step: 11ms | Tot: 3s335ms | Loss: 0.327 | Acc: 92.160% (9216/10000)  79/79 \n",
            "[2022-11-13 15:47:31,688] [val] [Epoch 148] [Loss 0.327] [Acc 92.160]\n",
            "\n",
            "Epoch: 149\n",
            " [=====================================================================================>]  Step: 79ms | Tot: 43s955ms | Loss: 0.044 | Acc: 99.170% (49585/50000) | Cls: 0.087  391/391 \n",
            "[2022-11-13 15:48:16,802] [train] [Epoch 149] [Loss 0.044] [cls 0.087] [Acc 99.170]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s391ms | Loss: 0.342 | Acc: 91.790% (9179/10000)  79/79 \n",
            "[2022-11-13 15:48:19,527] [val] [Epoch 149] [Loss 0.342] [Acc 91.790]\n",
            "\n",
            "Epoch: 150\n",
            " [=====================================================================================>]  Step: 75ms | Tot: 45s189ms | Loss: 0.046 | Acc: 99.082% (49541/50000) | Cls: 0.095  391/391 \n",
            "[2022-11-13 15:49:05,409] [train] [Epoch 150] [Loss 0.046] [cls 0.095] [Acc 99.082]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s532ms | Loss: 0.327 | Acc: 91.900% (9190/10000)  79/79 \n",
            "[2022-11-13 15:49:08,294] [val] [Epoch 150] [Loss 0.327] [Acc 91.900]\n",
            "\n",
            "Epoch: 151\n",
            " [=====================================================================================>]  Step: 78ms | Tot: 47s788ms | Loss: 0.035 | Acc: 99.418% (49709/50000) | Cls: 0.072  391/391 \n",
            "[2022-11-13 15:49:56,830] [train] [Epoch 151] [Loss 0.035] [cls 0.072] [Acc 99.418]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s387ms | Loss: 0.311 | Acc: 92.360% (9236/10000)  79/79 \n",
            "[2022-11-13 15:49:59,619] [val] [Epoch 151] [Loss 0.311] [Acc 92.360]\n",
            "\n",
            "Epoch: 152\n",
            " [=====================================================================================>]  Step: 75ms | Tot: 46s340ms | Loss: 0.030 | Acc: 99.512% (49756/50000) | Cls: 0.064  391/391 \n",
            "[2022-11-13 15:50:46,749] [train] [Epoch 152] [Loss 0.030] [cls 0.064] [Acc 99.512]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s482ms | Loss: 0.312 | Acc: 92.520% (9252/10000)  79/79 \n",
            "[2022-11-13 15:50:49,633] [val] [Epoch 152] [Loss 0.312] [Acc 92.520]\n",
            "\n",
            "Epoch: 153\n",
            " [=====================================================================================>]  Step: 75ms | Tot: 46s89ms | Loss: 0.028 | Acc: 99.572% (49786/50000) | Cls: 0.058  391/391 \n",
            "[2022-11-13 15:51:36,556] [train] [Epoch 153] [Loss 0.028] [cls 0.058] [Acc 99.572]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s509ms | Loss: 0.312 | Acc: 92.560% (9256/10000)  79/79 \n",
            "[2022-11-13 15:51:39,429] [val] [Epoch 153] [Loss 0.312] [Acc 92.560]\n",
            "\n",
            "Epoch: 154\n",
            " [=====================================================================================>]  Step: 73ms | Tot: 44s423ms | Loss: 0.024 | Acc: 99.644% (49822/50000) | Cls: 0.055  391/391 \n",
            "[2022-11-13 15:52:24,653] [train] [Epoch 154] [Loss 0.024] [cls 0.055] [Acc 99.644]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s500ms | Loss: 0.315 | Acc: 92.550% (9255/10000)  79/79 \n",
            "[2022-11-13 15:52:27,496] [val] [Epoch 154] [Loss 0.315] [Acc 92.550]\n",
            "\n",
            "Epoch: 155\n",
            " [=====================================================================================>]  Step: 78ms | Tot: 45s481ms | Loss: 0.024 | Acc: 99.652% (49826/50000) | Cls: 0.054  391/391 \n",
            "[2022-11-13 15:53:13,843] [train] [Epoch 155] [Loss 0.024] [cls 0.054] [Acc 99.652]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s505ms | Loss: 0.312 | Acc: 92.600% (9260/10000)  79/79 \n",
            "[2022-11-13 15:53:16,685] [val] [Epoch 155] [Loss 0.312] [Acc 92.600]\n",
            "\n",
            "Epoch: 156\n",
            " [=====================================================================================>]  Step: 78ms | Tot: 45s655ms | Loss: 0.022 | Acc: 99.706% (49853/50000) | Cls: 0.052  391/391 \n",
            "[2022-11-13 15:54:03,182] [train] [Epoch 156] [Loss 0.022] [cls 0.052] [Acc 99.706]\n",
            " [====================================================================================>.]  Step: 10ms | Tot: 2s458ms | Loss: 0.315 | Acc: 92.700% (9270/10000)  79/79 \n",
            "[2022-11-13 15:54:05,996] [val] [Epoch 156] [Loss 0.315] [Acc 92.700]\n",
            "\n",
            "Epoch: 157\n",
            " [=====================================================================================>]  Step: 76ms | Tot: 45s678ms | Loss: 0.022 | Acc: 99.684% (49842/50000) | Cls: 0.052  391/391 \n",
            "[2022-11-13 15:54:52,503] [train] [Epoch 157] [Loss 0.022] [cls 0.052] [Acc 99.684]\n",
            " [====================================================================================>.]  Step: 12ms | Tot: 2s405ms | Loss: 0.313 | Acc: 92.710% (9271/10000)  79/79 \n",
            "[2022-11-13 15:54:55,317] [val] [Epoch 157] [Loss 0.313] [Acc 92.710]\n",
            "\n",
            "Epoch: 158\n",
            " [=====================================================================================>]  Step: 78ms | Tot: 45s898ms | Loss: 0.021 | Acc: 99.700% (49850/50000) | Cls: 0.050  391/391 \n",
            "[2022-11-13 15:55:42,008] [train] [Epoch 158] [Loss 0.021] [cls 0.050] [Acc 99.700]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s440ms | Loss: 0.314 | Acc: 92.880% (9288/10000)  79/79 \n",
            "[2022-11-13 15:55:44,853] [val] [Epoch 158] [Loss 0.314] [Acc 92.880]\n",
            "Saving..\n",
            "\n",
            "Epoch: 159\n",
            " [=====================================================================================>]  Step: 88ms | Tot: 45s549ms | Loss: 0.021 | Acc: 99.696% (49848/50000) | Cls: 0.049  391/391 \n",
            "[2022-11-13 15:56:31,306] [train] [Epoch 159] [Loss 0.021] [cls 0.049] [Acc 99.696]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s427ms | Loss: 0.314 | Acc: 92.840% (9284/10000)  79/79 \n",
            "[2022-11-13 15:56:34,199] [val] [Epoch 159] [Loss 0.314] [Acc 92.840]\n",
            "\n",
            "Epoch: 160\n",
            " [=====================================================================================>]  Step: 77ms | Tot: 44s303ms | Loss: 0.020 | Acc: 99.734% (49867/50000) | Cls: 0.047  391/391 \n",
            "[2022-11-13 15:57:19,339] [train] [Epoch 160] [Loss 0.020] [cls 0.047] [Acc 99.734]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s498ms | Loss: 0.313 | Acc: 92.930% (9293/10000)  79/79 \n",
            "[2022-11-13 15:57:22,177] [val] [Epoch 160] [Loss 0.313] [Acc 92.930]\n",
            "Saving..\n",
            "\n",
            "Epoch: 161\n",
            " [=====================================================================================>]  Step: 80ms | Tot: 45s509ms | Loss: 0.020 | Acc: 99.736% (49868/50000) | Cls: 0.047  391/391 \n",
            "[2022-11-13 15:58:08,556] [train] [Epoch 161] [Loss 0.020] [cls 0.047] [Acc 99.736]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s637ms | Loss: 0.314 | Acc: 92.880% (9288/10000)  79/79 \n",
            "[2022-11-13 15:58:11,556] [val] [Epoch 161] [Loss 0.314] [Acc 92.880]\n",
            "\n",
            "Epoch: 162\n",
            " [=====================================================================================>]  Step: 72ms | Tot: 45s986ms | Loss: 0.018 | Acc: 99.748% (49874/50000) | Cls: 0.045  391/391 \n",
            "[2022-11-13 15:58:58,302] [train] [Epoch 162] [Loss 0.018] [cls 0.045] [Acc 99.748]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s336ms | Loss: 0.318 | Acc: 92.850% (9285/10000)  79/79 \n",
            "[2022-11-13 15:59:01,055] [val] [Epoch 162] [Loss 0.318] [Acc 92.850]\n",
            "\n",
            "Epoch: 163\n",
            " [=====================================================================================>]  Step: 76ms | Tot: 45s879ms | Loss: 0.017 | Acc: 99.756% (49878/50000) | Cls: 0.045  391/391 \n",
            "[2022-11-13 15:59:47,661] [train] [Epoch 163] [Loss 0.017] [cls 0.045] [Acc 99.756]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s414ms | Loss: 0.317 | Acc: 92.900% (9290/10000)  79/79 \n",
            "[2022-11-13 15:59:50,452] [val] [Epoch 163] [Loss 0.317] [Acc 92.900]\n",
            "\n",
            "Epoch: 164\n",
            " [=====================================================================================>]  Step: 78ms | Tot: 45s903ms | Loss: 0.017 | Acc: 99.786% (49893/50000) | Cls: 0.045  391/391 \n",
            "[2022-11-13 16:00:37,035] [train] [Epoch 164] [Loss 0.017] [cls 0.045] [Acc 99.786]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s406ms | Loss: 0.318 | Acc: 92.790% (9279/10000)  79/79 \n",
            "[2022-11-13 16:00:39,868] [val] [Epoch 164] [Loss 0.318] [Acc 92.790]\n",
            "\n",
            "Epoch: 165\n",
            " [=====================================================================================>]  Step: 74ms | Tot: 44s563ms | Loss: 0.018 | Acc: 99.716% (49858/50000) | Cls: 0.047  391/391 \n",
            "[2022-11-13 16:01:25,247] [train] [Epoch 165] [Loss 0.018] [cls 0.047] [Acc 99.716]\n",
            " [====================================================================================>.]  Step: 14ms | Tot: 3s701ms | Loss: 0.322 | Acc: 92.900% (9290/10000)  79/79 \n",
            "[2022-11-13 16:01:29,360] [val] [Epoch 165] [Loss 0.322] [Acc 92.900]\n",
            "\n",
            "Epoch: 166\n",
            " [=====================================================================================>]  Step: 81ms | Tot: 44s208ms | Loss: 0.017 | Acc: 99.764% (49882/50000) | Cls: 0.046  391/391 \n",
            "[2022-11-13 16:02:14,335] [train] [Epoch 166] [Loss 0.017] [cls 0.046] [Acc 99.764]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s578ms | Loss: 0.323 | Acc: 92.710% (9271/10000)  79/79 \n",
            "[2022-11-13 16:02:17,283] [val] [Epoch 166] [Loss 0.323] [Acc 92.710]\n",
            "\n",
            "Epoch: 167\n",
            " [=====================================================================================>]  Step: 77ms | Tot: 45s891ms | Loss: 0.017 | Acc: 99.754% (49877/50000) | Cls: 0.042  391/391 \n",
            "[2022-11-13 16:03:03,988] [train] [Epoch 167] [Loss 0.017] [cls 0.042] [Acc 99.754]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s472ms | Loss: 0.314 | Acc: 92.960% (9296/10000)  79/79 \n",
            "[2022-11-13 16:03:06,819] [val] [Epoch 167] [Loss 0.314] [Acc 92.960]\n",
            "Saving..\n",
            "\n",
            "Epoch: 168\n",
            " [=====================================================================================>]  Step: 75ms | Tot: 46s270ms | Loss: 0.016 | Acc: 99.802% (49901/50000) | Cls: 0.041  391/391 \n",
            "[2022-11-13 16:03:53,977] [train] [Epoch 168] [Loss 0.016] [cls 0.041] [Acc 99.802]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s410ms | Loss: 0.314 | Acc: 93.010% (9301/10000)  79/79 \n",
            "[2022-11-13 16:03:56,818] [val] [Epoch 168] [Loss 0.314] [Acc 93.010]\n",
            "Saving..\n",
            "\n",
            "Epoch: 169\n",
            " [=====================================================================================>]  Step: 77ms | Tot: 46s297ms | Loss: 0.016 | Acc: 99.808% (49904/50000) | Cls: 0.041  391/391 \n",
            "[2022-11-13 16:04:43,863] [train] [Epoch 169] [Loss 0.016] [cls 0.041] [Acc 99.808]\n",
            " [====================================================================================>.]  Step: 11ms | Tot: 2s497ms | Loss: 0.317 | Acc: 92.930% (9293/10000)  79/79 \n",
            "[2022-11-13 16:04:46,762] [val] [Epoch 169] [Loss 0.317] [Acc 92.930]\n",
            "\n",
            "Epoch: 170\n",
            " [=====================================================================================>]  Step: 87ms | Tot: 47s174ms | Loss: 0.016 | Acc: 99.806% (49903/50000) | Cls: 0.042  391/391 \n",
            "[2022-11-13 16:05:34,697] [train] [Epoch 170] [Loss 0.016] [cls 0.042] [Acc 99.806]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s570ms | Loss: 0.317 | Acc: 92.870% (9287/10000)  79/79 \n",
            "[2022-11-13 16:05:37,606] [val] [Epoch 170] [Loss 0.317] [Acc 92.870]\n",
            "\n",
            "Epoch: 171\n",
            " [=====================================================================================>]  Step: 96ms | Tot: 46s743ms | Loss: 0.017 | Acc: 99.772% (49886/50000) | Cls: 0.044  391/391 \n",
            "[2022-11-13 16:06:25,253] [train] [Epoch 171] [Loss 0.017] [cls 0.044] [Acc 99.772]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s662ms | Loss: 0.320 | Acc: 92.920% (9292/10000)  79/79 \n",
            "[2022-11-13 16:06:28,512] [val] [Epoch 171] [Loss 0.320] [Acc 92.920]\n",
            "\n",
            "Epoch: 172\n",
            " [=====================================================================================>]  Step: 75ms | Tot: 45s157ms | Loss: 0.016 | Acc: 99.790% (49895/50000) | Cls: 0.040  391/391 \n",
            "[2022-11-13 16:07:14,472] [train] [Epoch 172] [Loss 0.016] [cls 0.040] [Acc 99.790]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s495ms | Loss: 0.320 | Acc: 92.940% (9294/10000)  79/79 \n",
            "[2022-11-13 16:07:17,344] [val] [Epoch 172] [Loss 0.320] [Acc 92.940]\n",
            "\n",
            "Epoch: 173\n",
            " [=====================================================================================>]  Step: 79ms | Tot: 46s786ms | Loss: 0.015 | Acc: 99.816% (49908/50000) | Cls: 0.040  391/391 \n",
            "[2022-11-13 16:08:04,939] [train] [Epoch 173] [Loss 0.015] [cls 0.040] [Acc 99.816]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s556ms | Loss: 0.321 | Acc: 92.920% (9292/10000)  79/79 \n",
            "[2022-11-13 16:08:07,867] [val] [Epoch 173] [Loss 0.321] [Acc 92.920]\n",
            "\n",
            "Epoch: 174\n",
            " [=====================================================================================>]  Step: 75ms | Tot: 46s862ms | Loss: 0.016 | Acc: 99.786% (49893/50000) | Cls: 0.043  391/391 \n",
            "[2022-11-13 16:08:55,516] [train] [Epoch 174] [Loss 0.016] [cls 0.043] [Acc 99.786]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s541ms | Loss: 0.319 | Acc: 92.760% (9276/10000)  79/79 \n",
            "[2022-11-13 16:08:58,412] [val] [Epoch 174] [Loss 0.319] [Acc 92.760]\n",
            "\n",
            "Epoch: 175\n",
            " [=====================================================================================>]  Step: 76ms | Tot: 46s854ms | Loss: 0.016 | Acc: 99.774% (49887/50000) | Cls: 0.042  391/391 \n",
            "[2022-11-13 16:09:46,071] [train] [Epoch 175] [Loss 0.016] [cls 0.042] [Acc 99.774]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s494ms | Loss: 0.322 | Acc: 92.870% (9287/10000)  79/79 \n",
            "[2022-11-13 16:09:48,970] [val] [Epoch 175] [Loss 0.322] [Acc 92.870]\n",
            "\n",
            "Epoch: 176\n",
            " [=====================================================================================>]  Step: 76ms | Tot: 46s899ms | Loss: 0.015 | Acc: 99.802% (49901/50000) | Cls: 0.042  391/391 \n",
            "[2022-11-13 16:10:36,727] [train] [Epoch 176] [Loss 0.015] [cls 0.042] [Acc 99.802]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s575ms | Loss: 0.321 | Acc: 92.960% (9296/10000)  79/79 \n",
            "[2022-11-13 16:10:39,642] [val] [Epoch 176] [Loss 0.321] [Acc 92.960]\n",
            "\n",
            "Epoch: 177\n",
            " [=====================================================================================>]  Step: 70ms | Tot: 47s144ms | Loss: 0.015 | Acc: 99.810% (49905/50000) | Cls: 0.040  391/391 \n",
            "[2022-11-13 16:11:27,635] [train] [Epoch 177] [Loss 0.015] [cls 0.040] [Acc 99.810]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s476ms | Loss: 0.322 | Acc: 93.000% (9300/10000)  79/79 \n",
            "[2022-11-13 16:11:30,529] [val] [Epoch 177] [Loss 0.322] [Acc 93.000]\n",
            "\n",
            "Epoch: 178\n",
            " [=====================================================================================>]  Step: 75ms | Tot: 45s297ms | Loss: 0.016 | Acc: 99.786% (49893/50000) | Cls: 0.041  391/391 \n",
            "[2022-11-13 16:12:16,646] [train] [Epoch 178] [Loss 0.016] [cls 0.041] [Acc 99.786]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s536ms | Loss: 0.318 | Acc: 93.050% (9305/10000)  79/79 \n",
            "[2022-11-13 16:12:19,555] [val] [Epoch 178] [Loss 0.318] [Acc 93.050]\n",
            "Saving..\n",
            "\n",
            "Epoch: 179\n",
            " [=====================================================================================>]  Step: 82ms | Tot: 46s766ms | Loss: 0.016 | Acc: 99.814% (49907/50000) | Cls: 0.039  391/391 \n",
            "[2022-11-13 16:13:07,142] [train] [Epoch 179] [Loss 0.016] [cls 0.039] [Acc 99.814]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s516ms | Loss: 0.319 | Acc: 92.790% (9279/10000)  79/79 \n",
            "[2022-11-13 16:13:09,989] [val] [Epoch 179] [Loss 0.319] [Acc 92.790]\n",
            "\n",
            "Epoch: 180\n",
            " [=====================================================================================>]  Step: 79ms | Tot: 46s712ms | Loss: 0.015 | Acc: 99.800% (49900/50000) | Cls: 0.037  391/391 \n",
            "[2022-11-13 16:13:57,504] [train] [Epoch 180] [Loss 0.015] [cls 0.037] [Acc 99.800]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s436ms | Loss: 0.323 | Acc: 93.000% (9300/10000)  79/79 \n",
            "[2022-11-13 16:14:00,324] [val] [Epoch 180] [Loss 0.323] [Acc 93.000]\n",
            "\n",
            "Epoch: 181\n",
            " [=====================================================================================>]  Step: 80ms | Tot: 46s872ms | Loss: 0.015 | Acc: 99.804% (49902/50000) | Cls: 0.037  391/391 \n",
            "[2022-11-13 16:14:47,968] [train] [Epoch 181] [Loss 0.015] [cls 0.037] [Acc 99.804]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s436ms | Loss: 0.321 | Acc: 93.040% (9304/10000)  79/79 \n",
            "[2022-11-13 16:14:50,839] [val] [Epoch 181] [Loss 0.321] [Acc 93.040]\n",
            "\n",
            "Epoch: 182\n",
            " [=====================================================================================>]  Step: 72ms | Tot: 47s9ms | Loss: 0.015 | Acc: 99.824% (49912/50000) | Cls: 0.038  391/391 \n",
            "[2022-11-13 16:15:38,673] [train] [Epoch 182] [Loss 0.015] [cls 0.038] [Acc 99.824]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s535ms | Loss: 0.321 | Acc: 93.100% (9310/10000)  79/79 \n",
            "[2022-11-13 16:15:41,595] [val] [Epoch 182] [Loss 0.321] [Acc 93.100]\n",
            "Saving..\n",
            "\n",
            "Epoch: 183\n",
            " [=====================================================================================>]  Step: 77ms | Tot: 46s941ms | Loss: 0.014 | Acc: 99.838% (49919/50000) | Cls: 0.037  391/391 \n",
            "[2022-11-13 16:16:29,416] [train] [Epoch 183] [Loss 0.014] [cls 0.037] [Acc 99.838]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s479ms | Loss: 0.326 | Acc: 93.050% (9305/10000)  79/79 \n",
            "[2022-11-13 16:16:32,332] [val] [Epoch 183] [Loss 0.326] [Acc 93.050]\n",
            "\n",
            "Epoch: 184\n",
            " [=====================================================================================>]  Step: 87ms | Tot: 45s162ms | Loss: 0.013 | Acc: 99.836% (49918/50000) | Cls: 0.037  391/391 \n",
            "[2022-11-13 16:17:18,235] [train] [Epoch 184] [Loss 0.013] [cls 0.037] [Acc 99.836]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s494ms | Loss: 0.325 | Acc: 93.040% (9304/10000)  79/79 \n",
            "[2022-11-13 16:17:21,161] [val] [Epoch 184] [Loss 0.325] [Acc 93.040]\n",
            "\n",
            "Epoch: 185\n",
            " [=====================================================================================>]  Step: 78ms | Tot: 46s426ms | Loss: 0.014 | Acc: 99.822% (49911/50000) | Cls: 0.040  391/391 \n",
            "[2022-11-13 16:18:08,404] [train] [Epoch 185] [Loss 0.014] [cls 0.040] [Acc 99.822]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s438ms | Loss: 0.326 | Acc: 93.030% (9303/10000)  79/79 \n",
            "[2022-11-13 16:18:11,199] [val] [Epoch 185] [Loss 0.326] [Acc 93.030]\n",
            "\n",
            "Epoch: 186\n",
            " [=====================================================================================>]  Step: 76ms | Tot: 46s286ms | Loss: 0.014 | Acc: 99.842% (49921/50000) | Cls: 0.036  391/391 \n",
            "[2022-11-13 16:18:58,154] [train] [Epoch 186] [Loss 0.014] [cls 0.036] [Acc 99.842]\n",
            " [====================================================================================>.]  Step: 10ms | Tot: 2s583ms | Loss: 0.324 | Acc: 93.090% (9309/10000)  79/79 \n",
            "[2022-11-13 16:19:01,113] [val] [Epoch 186] [Loss 0.324] [Acc 93.090]\n",
            "\n",
            "Epoch: 187\n",
            " [=====================================================================================>]  Step: 76ms | Tot: 46s59ms | Loss: 0.014 | Acc: 99.844% (49922/50000) | Cls: 0.035  391/391 \n",
            "[2022-11-13 16:19:47,815] [train] [Epoch 187] [Loss 0.014] [cls 0.035] [Acc 99.844]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s366ms | Loss: 0.324 | Acc: 93.090% (9309/10000)  79/79 \n",
            "[2022-11-13 16:19:50,589] [val] [Epoch 187] [Loss 0.324] [Acc 93.090]\n",
            "\n",
            "Epoch: 188\n",
            " [=====================================================================================>]  Step: 73ms | Tot: 46s85ms | Loss: 0.014 | Acc: 99.840% (49920/50000) | Cls: 0.038  391/391 \n",
            "[2022-11-13 16:20:37,380] [train] [Epoch 188] [Loss 0.014] [cls 0.038] [Acc 99.840]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s416ms | Loss: 0.323 | Acc: 93.130% (9313/10000)  79/79 \n",
            "[2022-11-13 16:20:40,204] [val] [Epoch 188] [Loss 0.323] [Acc 93.130]\n",
            "Saving..\n",
            "\n",
            "Epoch: 189\n",
            " [=====================================================================================>]  Step: 68ms | Tot: 45s773ms | Loss: 0.013 | Acc: 99.860% (49930/50000) | Cls: 0.035  391/391 \n",
            "[2022-11-13 16:21:26,828] [train] [Epoch 189] [Loss 0.013] [cls 0.035] [Acc 99.860]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s492ms | Loss: 0.329 | Acc: 92.950% (9295/10000)  79/79 \n",
            "[2022-11-13 16:21:29,688] [val] [Epoch 189] [Loss 0.329] [Acc 92.950]\n",
            "\n",
            "Epoch: 190\n",
            " [=====================================================================================>]  Step: 83ms | Tot: 44s469ms | Loss: 0.013 | Acc: 99.852% (49926/50000) | Cls: 0.036  391/391 \n",
            "[2022-11-13 16:22:14,888] [train] [Epoch 190] [Loss 0.013] [cls 0.036] [Acc 99.852]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s470ms | Loss: 0.328 | Acc: 92.980% (9298/10000)  79/79 \n",
            "[2022-11-13 16:22:17,725] [val] [Epoch 190] [Loss 0.328] [Acc 92.980]\n",
            "\n",
            "Epoch: 191\n",
            " [=====================================================================================>]  Step: 74ms | Tot: 45s764ms | Loss: 0.013 | Acc: 99.840% (49920/50000) | Cls: 0.036  391/391 \n",
            "[2022-11-13 16:23:04,281] [train] [Epoch 191] [Loss 0.013] [cls 0.036] [Acc 99.840]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s573ms | Loss: 0.329 | Acc: 92.910% (9291/10000)  79/79 \n",
            "[2022-11-13 16:23:07,271] [val] [Epoch 191] [Loss 0.329] [Acc 92.910]\n",
            "\n",
            "Epoch: 192\n",
            " [=====================================================================================>]  Step: 75ms | Tot: 45s755ms | Loss: 0.014 | Acc: 99.828% (49914/50000) | Cls: 0.036  391/391 \n",
            "[2022-11-13 16:23:53,815] [train] [Epoch 192] [Loss 0.014] [cls 0.036] [Acc 99.828]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s445ms | Loss: 0.330 | Acc: 93.010% (9301/10000)  79/79 \n",
            "[2022-11-13 16:23:56,643] [val] [Epoch 192] [Loss 0.330] [Acc 93.010]\n",
            "\n",
            "Epoch: 193\n",
            " [=====================================================================================>]  Step: 81ms | Tot: 45s687ms | Loss: 0.014 | Acc: 99.832% (49916/50000) | Cls: 0.037  391/391 \n",
            "[2022-11-13 16:24:43,143] [train] [Epoch 193] [Loss 0.014] [cls 0.037] [Acc 99.832]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s415ms | Loss: 0.327 | Acc: 93.080% (9308/10000)  79/79 \n",
            "[2022-11-13 16:24:45,956] [val] [Epoch 193] [Loss 0.327] [Acc 93.080]\n",
            "\n",
            "Epoch: 194\n",
            " [=====================================================================================>]  Step: 77ms | Tot: 45s673ms | Loss: 0.013 | Acc: 99.824% (49912/50000) | Cls: 0.037  391/391 \n",
            "[2022-11-13 16:25:32,389] [train] [Epoch 194] [Loss 0.013] [cls 0.037] [Acc 99.824]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s390ms | Loss: 0.331 | Acc: 92.970% (9297/10000)  79/79 \n",
            "[2022-11-13 16:25:35,179] [val] [Epoch 194] [Loss 0.331] [Acc 92.970]\n",
            "\n",
            "Epoch: 195\n",
            " [=====================================================================================>]  Step: 75ms | Tot: 45s756ms | Loss: 0.013 | Acc: 99.856% (49928/50000) | Cls: 0.035  391/391 \n",
            "[2022-11-13 16:26:21,720] [train] [Epoch 195] [Loss 0.013] [cls 0.035] [Acc 99.856]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s449ms | Loss: 0.330 | Acc: 93.020% (9302/10000)  79/79 \n",
            "[2022-11-13 16:26:24,528] [val] [Epoch 195] [Loss 0.330] [Acc 93.020]\n",
            "\n",
            "Epoch: 196\n",
            " [=====================================================================================>]  Step: 76ms | Tot: 44s186ms | Loss: 0.012 | Acc: 99.852% (49926/50000) | Cls: 0.036  391/391 \n",
            "[2022-11-13 16:27:09,537] [train] [Epoch 196] [Loss 0.012] [cls 0.036] [Acc 99.852]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s458ms | Loss: 0.333 | Acc: 93.000% (9300/10000)  79/79 \n",
            "[2022-11-13 16:27:12,414] [val] [Epoch 196] [Loss 0.333] [Acc 93.000]\n",
            "\n",
            "Epoch: 197\n",
            " [=====================================================================================>]  Step: 75ms | Tot: 47s905ms | Loss: 0.012 | Acc: 99.848% (49924/50000) | Cls: 0.038  391/391 \n",
            "[2022-11-13 16:28:01,115] [train] [Epoch 197] [Loss 0.012] [cls 0.038] [Acc 99.848]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s638ms | Loss: 0.331 | Acc: 92.880% (9288/10000)  79/79 \n",
            "[2022-11-13 16:28:04,208] [val] [Epoch 197] [Loss 0.331] [Acc 92.880]\n",
            "\n",
            "Epoch: 198\n",
            " [=====================================================================================>]  Step: 69ms | Tot: 47s212ms | Loss: 0.013 | Acc: 99.840% (49920/50000) | Cls: 0.035  391/391 \n",
            "[2022-11-13 16:28:52,227] [train] [Epoch 198] [Loss 0.013] [cls 0.035] [Acc 99.840]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s489ms | Loss: 0.330 | Acc: 93.010% (9301/10000)  79/79 \n",
            "[2022-11-13 16:28:55,139] [val] [Epoch 198] [Loss 0.330] [Acc 93.010]\n",
            "\n",
            "Epoch: 199\n",
            " [=====================================================================================>]  Step: 75ms | Tot: 47s250ms | Loss: 0.013 | Acc: 99.840% (49920/50000) | Cls: 0.035  391/391 \n",
            "[2022-11-13 16:29:43,212] [train] [Epoch 199] [Loss 0.013] [cls 0.035] [Acc 99.840]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s533ms | Loss: 0.331 | Acc: 92.990% (9299/10000)  79/79 \n",
            "[2022-11-13 16:29:46,108] [val] [Epoch 199] [Loss 0.331] [Acc 92.990]\n",
            "Best Accuracy : 93.12999725341797\n",
            "[2022-11-13 16:29:46,108] [best] [Acc 93.130]\n"
          ]
        }
      ],
      "source": [
        "!python Learning-With-Retrospection/CS-KD_techinque/cs-kd/train.py --resume --sgpu 0 --lr 0.1 --epoch 200 --model resnet56 --name cifar10_resnet56 --decay 1e-4 --dataset cifar10 --dataroot ~/data/ -cls --lamda 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k36nunYh_WNW"
      },
      "source": [
        "## CIFAR100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1zeGNr8ubc6",
        "outputId": "9996b506-3fe8-4c58-f801-bf865384cd5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==> Preparing dataset: cifar100\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to /root/data/cifar-100-python.tar.gz\n",
            "100% 169001437/169001437 [00:04<00:00, 37796253.09it/s]\n",
            "Extracting /root/data/cifar-100-python.tar.gz to /root/data/\n",
            "Files already downloaded and verified\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Number of train dataset:  50000\n",
            "Number of validation dataset:  10000\n",
            "==> Building model: resnet56\n",
            "1\n",
            "Using CUDA..\n",
            "[2022-11-10 00:24:36,634] [main] Learning-With-Retrospection/CS-KD_techinque/cs-kd/train.py --sgpu 0 --lr 0.1 --epoch 200 --model resnet56 --name cifar100_resnet56 --decay 1e-4 --dataset cifar100 --dataroot /root/data/ -cls --lamda 1\n",
            "[2022-11-10 00:24:36,634] [main] Namespace(batch_size=128, cls=True, dataroot='/root/data/', dataset='cifar100', decay=0.0001, epoch=200, lamda=1.0, lr=0.1, model='resnet56', name='cifar100_resnet56', ngpu=1, resume=False, saveroot='./results', sgpu=0, temp=4.0)\n",
            "\n",
            "Epoch: 0\n",
            " [=====================================================================================>]  Step: 172ms | Tot: 44s287ms | Loss: 4.313 | Acc: 5.194% (2597/50000) | Cls: 0.193  391/391 \n",
            "[2022-11-10 00:25:23,731] [train] [Epoch 0] [Loss 4.313] [cls 0.193] [Acc 5.194]\n",
            " [====================================================================================>.]  Step: 25ms | Tot: 2s582ms | Loss: 3.945 | Acc: 9.700% (970/10000)  79/79 \n",
            "[2022-11-10 00:25:26,678] [val] [Epoch 0] [Loss 3.945] [Acc 9.700]\n",
            "Saving..\n",
            "\n",
            "Epoch: 1\n",
            " [=====================================================================================>]  Step: 73ms | Tot: 44s870ms | Loss: 3.807 | Acc: 12.060% (6030/50000) | Cls: 0.368  391/391 \n",
            "[2022-11-10 00:26:12,391] [train] [Epoch 1] [Loss 3.807] [cls 0.368] [Acc 12.060]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s415ms | Loss: 3.607 | Acc: 15.030% (1503/10000)  79/79 \n",
            "[2022-11-10 00:26:15,218] [val] [Epoch 1] [Loss 3.607] [Acc 15.030]\n",
            "Saving..\n",
            "\n",
            "Epoch: 2\n",
            " [=====================================================================================>]  Step: 71ms | Tot: 45s800ms | Loss: 3.508 | Acc: 17.784% (8892/50000) | Cls: 0.474  391/391 \n",
            "[2022-11-10 00:27:01,893] [train] [Epoch 2] [Loss 3.508] [cls 0.474] [Acc 17.784]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s542ms | Loss: 3.311 | Acc: 21.370% (2137/10000)  79/79 \n",
            "[2022-11-10 00:27:04,746] [val] [Epoch 2] [Loss 3.311] [Acc 21.370]\n",
            "Saving..\n",
            "\n",
            "Epoch: 3\n",
            " [=====================================================================================>]  Step: 73ms | Tot: 44s759ms | Loss: 3.232 | Acc: 23.096% (11548/50000) | Cls: 0.557  391/391 \n",
            "[2022-11-10 00:27:50,215] [train] [Epoch 3] [Loss 3.232] [cls 0.557] [Acc 23.096]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s487ms | Loss: 3.026 | Acc: 25.250% (2525/10000)  79/79 \n",
            "[2022-11-10 00:27:53,032] [val] [Epoch 3] [Loss 3.026] [Acc 25.250]\n",
            "Saving..\n",
            "\n",
            "Epoch: 4\n",
            " [=====================================================================================>]  Step: 72ms | Tot: 44s801ms | Loss: 2.971 | Acc: 28.152% (14076/50000) | Cls: 0.626  391/391 \n",
            "[2022-11-10 00:28:38,684] [train] [Epoch 4] [Loss 2.971] [cls 0.626] [Acc 28.152]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s479ms | Loss: 2.784 | Acc: 30.200% (3020/10000)  79/79 \n",
            "[2022-11-10 00:28:41,550] [val] [Epoch 4] [Loss 2.784] [Acc 30.200]\n",
            "Saving..\n",
            "\n",
            "Epoch: 5\n",
            " [=====================================================================================>]  Step: 72ms | Tot: 44s859ms | Loss: 2.734 | Acc: 33.234% (16617/50000) | Cls: 0.679  391/391 \n",
            "[2022-11-10 00:29:27,231] [train] [Epoch 5] [Loss 2.734] [cls 0.679] [Acc 33.234]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s564ms | Loss: 2.574 | Acc: 35.130% (3513/10000)  79/79 \n",
            "[2022-11-10 00:29:30,228] [val] [Epoch 5] [Loss 2.574] [Acc 35.130]\n",
            "Saving..\n",
            "\n",
            "Epoch: 6\n",
            " [=====================================================================================>]  Step: 74ms | Tot: 45s861ms | Loss: 2.533 | Acc: 37.394% (18697/50000) | Cls: 0.708  391/391 \n",
            "[2022-11-10 00:30:16,894] [train] [Epoch 6] [Loss 2.533] [cls 0.708] [Acc 37.394]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s446ms | Loss: 2.433 | Acc: 37.620% (3762/10000)  79/79 \n",
            "[2022-11-10 00:30:19,727] [val] [Epoch 6] [Loss 2.433] [Acc 37.620]\n",
            "Saving..\n",
            "\n",
            "Epoch: 7\n",
            " [=====================================================================================>]  Step: 69ms | Tot: 44s933ms | Loss: 2.362 | Acc: 41.128% (20564/50000) | Cls: 0.729  391/391 \n",
            "[2022-11-10 00:31:05,540] [train] [Epoch 7] [Loss 2.362] [cls 0.729] [Acc 41.128]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s558ms | Loss: 2.307 | Acc: 40.120% (4012/10000)  79/79 \n",
            "[2022-11-10 00:31:08,398] [val] [Epoch 7] [Loss 2.307] [Acc 40.120]\n",
            "Saving..\n",
            "\n",
            "Epoch: 8\n",
            " [=====================================================================================>]  Step: 75ms | Tot: 45s134ms | Loss: 2.233 | Acc: 43.886% (21943/50000) | Cls: 0.737  391/391 \n",
            "[2022-11-10 00:31:54,371] [train] [Epoch 8] [Loss 2.233] [cls 0.737] [Acc 43.886]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s536ms | Loss: 2.123 | Acc: 44.590% (4459/10000)  79/79 \n",
            "[2022-11-10 00:31:57,301] [val] [Epoch 8] [Loss 2.123] [Acc 44.590]\n",
            "Saving..\n",
            "\n",
            "Epoch: 9\n",
            " [=====================================================================================>]  Step: 74ms | Tot: 46s331ms | Loss: 2.106 | Acc: 46.834% (23417/50000) | Cls: 0.743  391/391 \n",
            "[2022-11-10 00:32:44,417] [train] [Epoch 9] [Loss 2.106] [cls 0.743] [Acc 46.834]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s535ms | Loss: 2.172 | Acc: 43.660% (4366/10000)  79/79 \n",
            "[2022-11-10 00:32:47,286] [val] [Epoch 9] [Loss 2.172] [Acc 43.660]\n",
            "\n",
            "Epoch: 10\n",
            " [=====================================================================================>]  Step: 72ms | Tot: 45s78ms | Loss: 2.015 | Acc: 48.656% (24328/50000) | Cls: 0.745  391/391 \n",
            "[2022-11-10 00:33:33,184] [train] [Epoch 10] [Loss 2.015] [cls 0.745] [Acc 48.656]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s484ms | Loss: 2.038 | Acc: 46.970% (4697/10000)  79/79 \n",
            "[2022-11-10 00:33:36,047] [val] [Epoch 10] [Loss 2.038] [Acc 46.970]\n",
            "Saving..\n",
            "\n",
            "Epoch: 11\n",
            " [=====================================================================================>]  Step: 77ms | Tot: 45s182ms | Loss: 1.934 | Acc: 50.700% (25350/50000) | Cls: 0.742  391/391 \n",
            "[2022-11-10 00:34:21,918] [train] [Epoch 11] [Loss 1.934] [cls 0.742] [Acc 50.700]\n",
            " [====================================================================================>.]  Step: 12ms | Tot: 2s445ms | Loss: 1.985 | Acc: 47.880% (4788/10000)  79/79 \n",
            "[2022-11-10 00:34:24,753] [val] [Epoch 11] [Loss 1.985] [Acc 47.880]\n",
            "Saving..\n",
            "\n",
            "Epoch: 12\n",
            " [=====================================================================================>]  Step: 77ms | Tot: 44s996ms | Loss: 1.871 | Acc: 52.052% (26026/50000) | Cls: 0.743  391/391 \n",
            "[2022-11-10 00:35:10,578] [train] [Epoch 12] [Loss 1.871] [cls 0.743] [Acc 52.052]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s484ms | Loss: 1.872 | Acc: 50.670% (5067/10000)  79/79 \n",
            "[2022-11-10 00:35:13,449] [val] [Epoch 12] [Loss 1.872] [Acc 50.670]\n",
            "Saving..\n",
            "\n",
            "Epoch: 13\n",
            " [=====================================================================================>]  Step: 73ms | Tot: 45s574ms | Loss: 1.801 | Acc: 53.760% (26880/50000) | Cls: 0.734  391/391 \n",
            "[2022-11-10 00:35:59,869] [train] [Epoch 13] [Loss 1.801] [cls 0.734] [Acc 53.760]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s495ms | Loss: 1.975 | Acc: 47.990% (4799/10000)  79/79 \n",
            "[2022-11-10 00:36:02,734] [val] [Epoch 13] [Loss 1.975] [Acc 47.990]\n",
            "\n",
            "Epoch: 14\n",
            " [=====================================================================================>]  Step: 72ms | Tot: 44s969ms | Loss: 1.751 | Acc: 54.858% (27429/50000) | Cls: 0.737  391/391 \n",
            "[2022-11-10 00:36:48,515] [train] [Epoch 14] [Loss 1.751] [cls 0.737] [Acc 54.858]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s497ms | Loss: 1.850 | Acc: 51.670% (5167/10000)  79/79 \n",
            "[2022-11-10 00:36:51,393] [val] [Epoch 14] [Loss 1.850] [Acc 51.670]\n",
            "Saving..\n",
            "\n",
            "Epoch: 15\n",
            " [=====================================================================================>]  Step: 72ms | Tot: 45s243ms | Loss: 1.702 | Acc: 56.222% (28111/50000) | Cls: 0.728  391/391 \n",
            "[2022-11-10 00:37:37,492] [train] [Epoch 15] [Loss 1.702] [cls 0.728] [Acc 56.222]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s599ms | Loss: 1.808 | Acc: 52.670% (5267/10000)  79/79 \n",
            "[2022-11-10 00:37:40,442] [val] [Epoch 15] [Loss 1.808] [Acc 52.670]\n",
            "Saving..\n",
            "\n",
            "Epoch: 16\n",
            " [=====================================================================================>]  Step: 68ms | Tot: 46s125ms | Loss: 1.664 | Acc: 57.024% (28512/50000) | Cls: 0.720  391/391 \n",
            "[2022-11-10 00:38:27,440] [train] [Epoch 16] [Loss 1.664] [cls 0.720] [Acc 57.024]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s522ms | Loss: 1.852 | Acc: 52.100% (5210/10000)  79/79 \n",
            "[2022-11-10 00:38:30,372] [val] [Epoch 16] [Loss 1.852] [Acc 52.100]\n",
            "\n",
            "Epoch: 17\n",
            " [=====================================================================================>]  Step: 69ms | Tot: 45s95ms | Loss: 1.624 | Acc: 57.916% (28958/50000) | Cls: 0.720  391/391 \n",
            "[2022-11-10 00:39:16,227] [train] [Epoch 17] [Loss 1.624] [cls 0.720] [Acc 57.916]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s589ms | Loss: 1.750 | Acc: 54.150% (5415/10000)  79/79 \n",
            "[2022-11-10 00:39:19,132] [val] [Epoch 17] [Loss 1.750] [Acc 54.150]\n",
            "Saving..\n",
            "\n",
            "Epoch: 18\n",
            " [=====================================================================================>]  Step: 70ms | Tot: 45s180ms | Loss: 1.586 | Acc: 58.968% (29484/50000) | Cls: 0.716  391/391 \n",
            "[2022-11-10 00:40:05,150] [train] [Epoch 18] [Loss 1.586] [cls 0.716] [Acc 58.968]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s607ms | Loss: 1.736 | Acc: 54.590% (5459/10000)  79/79 \n",
            "[2022-11-10 00:40:08,097] [val] [Epoch 18] [Loss 1.736] [Acc 54.590]\n",
            "Saving..\n",
            "\n",
            "Epoch: 19\n",
            " [=====================================================================================>]  Step: 73ms | Tot: 45s444ms | Loss: 1.556 | Acc: 59.732% (29866/50000) | Cls: 0.717  391/391 \n",
            "[2022-11-10 00:40:54,370] [train] [Epoch 19] [Loss 1.556] [cls 0.717] [Acc 59.732]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s458ms | Loss: 1.767 | Acc: 53.650% (5365/10000)  79/79 \n",
            "[2022-11-10 00:40:57,232] [val] [Epoch 19] [Loss 1.767] [Acc 53.650]\n",
            "\n",
            "Epoch: 20\n",
            " [=====================================================================================>]  Step: 69ms | Tot: 46s360ms | Loss: 1.522 | Acc: 60.628% (30314/50000) | Cls: 0.709  391/391 \n",
            "[2022-11-10 00:41:44,401] [train] [Epoch 20] [Loss 1.522] [cls 0.709] [Acc 60.628]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s512ms | Loss: 1.722 | Acc: 54.170% (5417/10000)  79/79 \n",
            "[2022-11-10 00:41:47,283] [val] [Epoch 20] [Loss 1.722] [Acc 54.170]\n",
            "\n",
            "Epoch: 21\n",
            " [=====================================================================================>]  Step: 75ms | Tot: 45s702ms | Loss: 1.503 | Acc: 60.966% (30483/50000) | Cls: 0.708  391/391 \n",
            "[2022-11-10 00:42:33,758] [train] [Epoch 21] [Loss 1.503] [cls 0.708] [Acc 60.966]\n",
            " [====================================================================================>.]  Step: 10ms | Tot: 2s482ms | Loss: 1.739 | Acc: 54.500% (5450/10000)  79/79 \n",
            "[2022-11-10 00:42:36,634] [val] [Epoch 21] [Loss 1.739] [Acc 54.500]\n",
            "\n",
            "Epoch: 22\n",
            " [=====================================================================================>]  Step: 70ms | Tot: 45s315ms | Loss: 1.466 | Acc: 62.138% (31069/50000) | Cls: 0.701  391/391 \n",
            "[2022-11-10 00:43:22,760] [train] [Epoch 22] [Loss 1.466] [cls 0.701] [Acc 62.138]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s522ms | Loss: 1.679 | Acc: 56.200% (5620/10000)  79/79 \n",
            "[2022-11-10 00:43:25,643] [val] [Epoch 22] [Loss 1.679] [Acc 56.200]\n",
            "Saving..\n",
            "\n",
            "Epoch: 23\n",
            " [=====================================================================================>]  Step: 73ms | Tot: 45s579ms | Loss: 1.452 | Acc: 62.098% (31049/50000) | Cls: 0.701  391/391 \n",
            "[2022-11-10 00:44:12,075] [train] [Epoch 23] [Loss 1.452] [cls 0.701] [Acc 62.098]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 3s276ms | Loss: 1.784 | Acc: 53.000% (5300/10000)  79/79 \n",
            "[2022-11-10 00:44:15,883] [val] [Epoch 23] [Loss 1.784] [Acc 53.000]\n",
            "\n",
            "Epoch: 24\n",
            " [=====================================================================================>]  Step: 75ms | Tot: 45s19ms | Loss: 1.428 | Acc: 62.778% (31389/50000) | Cls: 0.694  391/391 \n",
            "[2022-11-10 00:45:01,732] [train] [Epoch 24] [Loss 1.428] [cls 0.694] [Acc 62.778]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s599ms | Loss: 1.655 | Acc: 56.360% (5636/10000)  79/79 \n",
            "[2022-11-10 00:45:04,643] [val] [Epoch 24] [Loss 1.655] [Acc 56.360]\n",
            "Saving..\n",
            "\n",
            "Epoch: 25\n",
            " [=====================================================================================>]  Step: 74ms | Tot: 45s647ms | Loss: 1.408 | Acc: 63.482% (31741/50000) | Cls: 0.692  391/391 \n",
            "[2022-11-10 00:45:51,110] [train] [Epoch 25] [Loss 1.408] [cls 0.692] [Acc 63.482]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s468ms | Loss: 1.668 | Acc: 55.920% (5592/10000)  79/79 \n",
            "[2022-11-10 00:45:53,963] [val] [Epoch 25] [Loss 1.668] [Acc 55.920]\n",
            "\n",
            "Epoch: 26\n",
            " [=====================================================================================>]  Step: 75ms | Tot: 45s314ms | Loss: 1.391 | Acc: 64.032% (32016/50000) | Cls: 0.686  391/391 \n",
            "[2022-11-10 00:46:40,044] [train] [Epoch 26] [Loss 1.391] [cls 0.686] [Acc 64.032]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s528ms | Loss: 1.611 | Acc: 57.280% (5728/10000)  79/79 \n",
            "[2022-11-10 00:46:42,952] [val] [Epoch 26] [Loss 1.611] [Acc 57.280]\n",
            "Saving..\n",
            "\n",
            "Epoch: 27\n",
            " [=====================================================================================>]  Step: 66ms | Tot: 46s162ms | Loss: 1.365 | Acc: 64.440% (32220/50000) | Cls: 0.685  391/391 \n",
            "[2022-11-10 00:47:29,976] [train] [Epoch 27] [Loss 1.365] [cls 0.685] [Acc 64.440]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s529ms | Loss: 1.664 | Acc: 56.810% (5681/10000)  79/79 \n",
            "[2022-11-10 00:47:32,904] [val] [Epoch 27] [Loss 1.664] [Acc 56.810]\n",
            "\n",
            "Epoch: 28\n",
            " [=====================================================================================>]  Step: 71ms | Tot: 45s61ms | Loss: 1.359 | Acc: 64.406% (32203/50000) | Cls: 0.683  391/391 \n",
            "[2022-11-10 00:48:18,730] [train] [Epoch 28] [Loss 1.359] [cls 0.683] [Acc 64.406]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s477ms | Loss: 1.615 | Acc: 57.270% (5727/10000)  79/79 \n",
            "[2022-11-10 00:48:21,611] [val] [Epoch 28] [Loss 1.615] [Acc 57.270]\n",
            "\n",
            "Epoch: 29\n",
            " [=====================================================================================>]  Step: 72ms | Tot: 44s910ms | Loss: 1.335 | Acc: 65.244% (32622/50000) | Cls: 0.680  391/391 \n",
            "[2022-11-10 00:49:07,203] [train] [Epoch 29] [Loss 1.335] [cls 0.680] [Acc 65.244]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s418ms | Loss: 1.617 | Acc: 57.330% (5733/10000)  79/79 \n",
            "[2022-11-10 00:49:10,031] [val] [Epoch 29] [Loss 1.617] [Acc 57.330]\n",
            "Saving..\n",
            "\n",
            "Epoch: 30\n",
            " [=====================================================================================>]  Step: 69ms | Tot: 44s861ms | Loss: 1.330 | Acc: 65.350% (32675/50000) | Cls: 0.679  391/391 \n",
            "[2022-11-10 00:49:55,663] [train] [Epoch 30] [Loss 1.330] [cls 0.679] [Acc 65.350]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s484ms | Loss: 1.558 | Acc: 58.640% (5864/10000)  79/79 \n",
            "[2022-11-10 00:49:58,495] [val] [Epoch 30] [Loss 1.558] [Acc 58.640]\n",
            "Saving..\n",
            "\n",
            "Epoch: 31\n",
            " [=====================================================================================>]  Step: 69ms | Tot: 45s518ms | Loss: 1.306 | Acc: 66.150% (33075/50000) | Cls: 0.678  391/391 \n",
            "[2022-11-10 00:50:44,804] [train] [Epoch 31] [Loss 1.306] [cls 0.678] [Acc 66.150]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s527ms | Loss: 1.592 | Acc: 57.920% (5792/10000)  79/79 \n",
            "[2022-11-10 00:50:47,635] [val] [Epoch 31] [Loss 1.592] [Acc 57.920]\n",
            "\n",
            "Epoch: 32\n",
            " [=====================================================================================>]  Step: 74ms | Tot: 44s788ms | Loss: 1.296 | Acc: 66.162% (33081/50000) | Cls: 0.674  391/391 \n",
            "[2022-11-10 00:51:33,208] [train] [Epoch 32] [Loss 1.296] [cls 0.674] [Acc 66.162]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s511ms | Loss: 1.577 | Acc: 57.790% (5779/10000)  79/79 \n",
            "[2022-11-10 00:51:36,038] [val] [Epoch 32] [Loss 1.577] [Acc 57.790]\n",
            "\n",
            "Epoch: 33\n",
            " [=====================================================================================>]  Step: 67ms | Tot: 44s441ms | Loss: 1.291 | Acc: 66.114% (33057/50000) | Cls: 0.669  391/391 \n",
            "[2022-11-10 00:52:21,239] [train] [Epoch 33] [Loss 1.291] [cls 0.669] [Acc 66.114]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s446ms | Loss: 1.647 | Acc: 56.810% (5681/10000)  79/79 \n",
            "[2022-11-10 00:52:24,077] [val] [Epoch 33] [Loss 1.647] [Acc 56.810]\n",
            "\n",
            "Epoch: 34\n",
            " [=====================================================================================>]  Step: 71ms | Tot: 45s642ms | Loss: 1.266 | Acc: 66.932% (33466/50000) | Cls: 0.664  391/391 \n",
            "[2022-11-10 00:53:10,440] [train] [Epoch 34] [Loss 1.266] [cls 0.664] [Acc 66.932]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s424ms | Loss: 1.657 | Acc: 55.850% (5585/10000)  79/79 \n",
            "[2022-11-10 00:53:13,276] [val] [Epoch 34] [Loss 1.657] [Acc 55.850]\n",
            "\n",
            "Epoch: 35\n",
            " [=====================================================================================>]  Step: 78ms | Tot: 44s469ms | Loss: 1.258 | Acc: 66.870% (33435/50000) | Cls: 0.668  391/391 \n",
            "[2022-11-10 00:53:58,492] [train] [Epoch 35] [Loss 1.258] [cls 0.668] [Acc 66.870]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s508ms | Loss: 1.595 | Acc: 57.610% (5761/10000)  79/79 \n",
            "[2022-11-10 00:54:01,290] [val] [Epoch 35] [Loss 1.595] [Acc 57.610]\n",
            "\n",
            "Epoch: 36\n",
            " [=====================================================================================>]  Step: 72ms | Tot: 44s318ms | Loss: 1.251 | Acc: 67.236% (33618/50000) | Cls: 0.659  391/391 \n",
            "[2022-11-10 00:54:46,371] [train] [Epoch 36] [Loss 1.251] [cls 0.659] [Acc 67.236]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s451ms | Loss: 1.614 | Acc: 58.230% (5823/10000)  79/79 \n",
            "[2022-11-10 00:54:49,201] [val] [Epoch 36] [Loss 1.614] [Acc 58.230]\n",
            "\n",
            "Epoch: 37\n",
            " [=====================================================================================>]  Step: 76ms | Tot: 44s672ms | Loss: 1.238 | Acc: 67.796% (33898/50000) | Cls: 0.663  391/391 \n",
            "[2022-11-10 00:55:34,625] [train] [Epoch 37] [Loss 1.238] [cls 0.663] [Acc 67.796]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s565ms | Loss: 1.526 | Acc: 59.400% (5940/10000)  79/79 \n",
            "[2022-11-10 00:55:37,537] [val] [Epoch 37] [Loss 1.526] [Acc 59.400]\n",
            "Saving..\n",
            "\n",
            "Epoch: 38\n",
            " [=====================================================================================>]  Step: 72ms | Tot: 45s375ms | Loss: 1.225 | Acc: 68.082% (34041/50000) | Cls: 0.660  391/391 \n",
            "[2022-11-10 00:56:23,747] [train] [Epoch 38] [Loss 1.225] [cls 0.660] [Acc 68.082]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s540ms | Loss: 1.496 | Acc: 60.160% (6016/10000)  79/79 \n",
            "[2022-11-10 00:56:26,632] [val] [Epoch 38] [Loss 1.496] [Acc 60.160]\n",
            "Saving..\n",
            "\n",
            "Epoch: 39\n",
            " [=====================================================================================>]  Step: 72ms | Tot: 44s673ms | Loss: 1.216 | Acc: 68.110% (34055/50000) | Cls: 0.657  391/391 \n",
            "[2022-11-10 00:57:12,178] [train] [Epoch 39] [Loss 1.216] [cls 0.657] [Acc 68.110]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s448ms | Loss: 1.491 | Acc: 59.980% (5998/10000)  79/79 \n",
            "[2022-11-10 00:57:14,996] [val] [Epoch 39] [Loss 1.491] [Acc 59.980]\n",
            "\n",
            "Epoch: 40\n",
            " [=====================================================================================>]  Step: 67ms | Tot: 44s721ms | Loss: 1.207 | Acc: 68.330% (34165/50000) | Cls: 0.654  391/391 \n",
            "[2022-11-10 00:58:00,515] [train] [Epoch 40] [Loss 1.207] [cls 0.654] [Acc 68.330]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s400ms | Loss: 1.504 | Acc: 59.900% (5990/10000)  79/79 \n",
            "[2022-11-10 00:58:03,343] [val] [Epoch 40] [Loss 1.504] [Acc 59.900]\n",
            "\n",
            "Epoch: 41\n",
            " [=====================================================================================>]  Step: 72ms | Tot: 44s336ms | Loss: 1.202 | Acc: 68.578% (34289/50000) | Cls: 0.652  391/391 \n",
            "[2022-11-10 00:58:48,415] [train] [Epoch 41] [Loss 1.202] [cls 0.652] [Acc 68.578]\n",
            " [====================================================================================>.]  Step: 12ms | Tot: 2s520ms | Loss: 1.515 | Acc: 59.600% (5960/10000)  79/79 \n",
            "[2022-11-10 00:58:51,340] [val] [Epoch 41] [Loss 1.515] [Acc 59.600]\n",
            "\n",
            "Epoch: 42\n",
            " [=====================================================================================>]  Step: 73ms | Tot: 44s875ms | Loss: 1.191 | Acc: 68.824% (34412/50000) | Cls: 0.653  391/391 \n",
            "[2022-11-10 00:59:37,302] [train] [Epoch 42] [Loss 1.191] [cls 0.653] [Acc 68.824]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s451ms | Loss: 1.552 | Acc: 58.920% (5892/10000)  79/79 \n",
            "[2022-11-10 00:59:40,151] [val] [Epoch 42] [Loss 1.552] [Acc 58.920]\n",
            "\n",
            "Epoch: 43\n",
            " [=====================================================================================>]  Step: 71ms | Tot: 44s220ms | Loss: 1.176 | Acc: 69.194% (34597/50000) | Cls: 0.647  391/391 \n",
            "[2022-11-10 01:00:25,154] [train] [Epoch 43] [Loss 1.176] [cls 0.647] [Acc 69.194]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s464ms | Loss: 1.499 | Acc: 59.620% (5962/10000)  79/79 \n",
            "[2022-11-10 01:00:27,983] [val] [Epoch 43] [Loss 1.499] [Acc 59.620]\n",
            "\n",
            "Epoch: 44\n",
            " [=====================================================================================>]  Step: 69ms | Tot: 44s228ms | Loss: 1.174 | Acc: 69.278% (34639/50000) | Cls: 0.642  391/391 \n",
            "[2022-11-10 01:01:13,011] [train] [Epoch 44] [Loss 1.174] [cls 0.642] [Acc 69.278]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s419ms | Loss: 1.615 | Acc: 57.620% (5762/10000)  79/79 \n",
            "[2022-11-10 01:01:15,811] [val] [Epoch 44] [Loss 1.615] [Acc 57.620]\n",
            "\n",
            "Epoch: 45\n",
            " [=====================================================================================>]  Step: 71ms | Tot: 46s23ms | Loss: 1.167 | Acc: 69.518% (34759/50000) | Cls: 0.646  391/391 \n",
            "[2022-11-10 01:02:02,651] [train] [Epoch 45] [Loss 1.167] [cls 0.646] [Acc 69.518]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s591ms | Loss: 1.515 | Acc: 59.770% (5977/10000)  79/79 \n",
            "[2022-11-10 01:02:05,571] [val] [Epoch 45] [Loss 1.515] [Acc 59.770]\n",
            "\n",
            "Epoch: 46\n",
            " [=====================================================================================>]  Step: 72ms | Tot: 45s66ms | Loss: 1.161 | Acc: 69.574% (34787/50000) | Cls: 0.644  391/391 \n",
            "[2022-11-10 01:02:51,330] [train] [Epoch 46] [Loss 1.161] [cls 0.644] [Acc 69.574]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s528ms | Loss: 1.531 | Acc: 59.260% (5926/10000)  79/79 \n",
            "[2022-11-10 01:02:54,196] [val] [Epoch 46] [Loss 1.531] [Acc 59.260]\n",
            "\n",
            "Epoch: 47\n",
            " [=====================================================================================>]  Step: 80ms | Tot: 45s241ms | Loss: 1.160 | Acc: 69.712% (34856/50000) | Cls: 0.647  391/391 \n",
            "[2022-11-10 01:03:40,224] [train] [Epoch 47] [Loss 1.160] [cls 0.647] [Acc 69.712]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s507ms | Loss: 1.553 | Acc: 58.380% (5838/10000)  79/79 \n",
            "[2022-11-10 01:03:43,054] [val] [Epoch 47] [Loss 1.553] [Acc 58.380]\n",
            "\n",
            "Epoch: 48\n",
            " [=====================================================================================>]  Step: 72ms | Tot: 45s264ms | Loss: 1.149 | Acc: 69.916% (34958/50000) | Cls: 0.640  391/391 \n",
            "[2022-11-10 01:04:29,003] [train] [Epoch 48] [Loss 1.149] [cls 0.640] [Acc 69.916]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s585ms | Loss: 1.499 | Acc: 60.410% (6041/10000)  79/79 \n",
            "[2022-11-10 01:04:31,943] [val] [Epoch 48] [Loss 1.499] [Acc 60.410]\n",
            "Saving..\n",
            "\n",
            "Epoch: 49\n",
            " [=====================================================================================>]  Step: 73ms | Tot: 46s | Loss: 1.146 | Acc: 69.892% (34946/50000) | Cls: 0.640  391/391 \n",
            "[2022-11-10 01:05:18,781] [train] [Epoch 49] [Loss 1.146] [cls 0.640] [Acc 69.892]\n",
            " [====================================================================================>.]  Step: 10ms | Tot: 2s534ms | Loss: 1.550 | Acc: 59.350% (5935/10000)  79/79 \n",
            "[2022-11-10 01:05:21,629] [val] [Epoch 49] [Loss 1.550] [Acc 59.350]\n",
            "\n",
            "Epoch: 50\n",
            " [=====================================================================================>]  Step: 79ms | Tot: 45s180ms | Loss: 1.143 | Acc: 69.962% (34981/50000) | Cls: 0.635  391/391 \n",
            "[2022-11-10 01:06:07,574] [train] [Epoch 50] [Loss 1.143] [cls 0.635] [Acc 69.962]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s568ms | Loss: 1.520 | Acc: 59.450% (5945/10000)  79/79 \n",
            "[2022-11-10 01:06:10,513] [val] [Epoch 50] [Loss 1.520] [Acc 59.450]\n",
            "\n",
            "Epoch: 51\n",
            " [=====================================================================================>]  Step: 70ms | Tot: 45s317ms | Loss: 1.125 | Acc: 70.416% (35208/50000) | Cls: 0.630  391/391 \n",
            "[2022-11-10 01:06:56,588] [train] [Epoch 51] [Loss 1.125] [cls 0.630] [Acc 70.416]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s557ms | Loss: 1.483 | Acc: 60.070% (6007/10000)  79/79 \n",
            "[2022-11-10 01:06:59,535] [val] [Epoch 51] [Loss 1.483] [Acc 60.070]\n",
            "\n",
            "Epoch: 52\n",
            " [=====================================================================================>]  Step: 71ms | Tot: 45s239ms | Loss: 1.126 | Acc: 70.656% (35328/50000) | Cls: 0.635  391/391 \n",
            "[2022-11-10 01:07:45,479] [train] [Epoch 52] [Loss 1.126] [cls 0.635] [Acc 70.656]\n",
            " [====================================================================================>.]  Step: 12ms | Tot: 2s485ms | Loss: 1.574 | Acc: 59.140% (5914/10000)  79/79 \n",
            "[2022-11-10 01:07:48,356] [val] [Epoch 52] [Loss 1.574] [Acc 59.140]\n",
            "\n",
            "Epoch: 53\n",
            " [=====================================================================================>]  Step: 75ms | Tot: 45s879ms | Loss: 1.109 | Acc: 70.798% (35399/50000) | Cls: 0.635  391/391 \n",
            "[2022-11-10 01:08:35,030] [train] [Epoch 53] [Loss 1.109] [cls 0.635] [Acc 70.798]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s544ms | Loss: 1.553 | Acc: 59.480% (5948/10000)  79/79 \n",
            "[2022-11-10 01:08:37,885] [val] [Epoch 53] [Loss 1.553] [Acc 59.480]\n",
            "\n",
            "Epoch: 54\n",
            " [=====================================================================================>]  Step: 70ms | Tot: 45s5ms | Loss: 1.113 | Acc: 70.576% (35288/50000) | Cls: 0.631  391/391 \n",
            "[2022-11-10 01:09:23,595] [train] [Epoch 54] [Loss 1.113] [cls 0.631] [Acc 70.576]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s518ms | Loss: 1.503 | Acc: 60.540% (6054/10000)  79/79 \n",
            "[2022-11-10 01:09:26,429] [val] [Epoch 54] [Loss 1.503] [Acc 60.540]\n",
            "Saving..\n",
            "\n",
            "Epoch: 55\n",
            " [=====================================================================================>]  Step: 73ms | Tot: 45s130ms | Loss: 1.109 | Acc: 70.958% (35479/50000) | Cls: 0.629  391/391 \n",
            "[2022-11-10 01:10:12,368] [train] [Epoch 55] [Loss 1.109] [cls 0.629] [Acc 70.958]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s568ms | Loss: 1.463 | Acc: 61.460% (6146/10000)  79/79 \n",
            "[2022-11-10 01:10:15,250] [val] [Epoch 55] [Loss 1.463] [Acc 61.460]\n",
            "Saving..\n",
            "\n",
            "Epoch: 56\n",
            " [=====================================================================================>]  Step: 77ms | Tot: 46s161ms | Loss: 1.104 | Acc: 70.750% (35375/50000) | Cls: 0.626  391/391 \n",
            "[2022-11-10 01:11:02,158] [train] [Epoch 56] [Loss 1.104] [cls 0.626] [Acc 70.750]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s479ms | Loss: 1.471 | Acc: 61.440% (6144/10000)  79/79 \n",
            "[2022-11-10 01:11:05,030] [val] [Epoch 56] [Loss 1.471] [Acc 61.440]\n",
            "\n",
            "Epoch: 57\n",
            " [=====================================================================================>]  Step: 74ms | Tot: 45s498ms | Loss: 1.102 | Acc: 71.006% (35503/50000) | Cls: 0.630  391/391 \n",
            "[2022-11-10 01:11:51,310] [train] [Epoch 57] [Loss 1.102] [cls 0.630] [Acc 71.006]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s473ms | Loss: 1.591 | Acc: 58.650% (5865/10000)  79/79 \n",
            "[2022-11-10 01:11:54,176] [val] [Epoch 57] [Loss 1.591] [Acc 58.650]\n",
            "\n",
            "Epoch: 58\n",
            " [=====================================================================================>]  Step: 80ms | Tot: 45s417ms | Loss: 1.092 | Acc: 71.500% (35750/50000) | Cls: 0.625  391/391 \n",
            "[2022-11-10 01:12:40,346] [train] [Epoch 58] [Loss 1.092] [cls 0.625] [Acc 71.500]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s468ms | Loss: 1.552 | Acc: 59.200% (5920/10000)  79/79 \n",
            "[2022-11-10 01:12:43,172] [val] [Epoch 58] [Loss 1.552] [Acc 59.200]\n",
            "\n",
            "Epoch: 59\n",
            " [=====================================================================================>]  Step: 71ms | Tot: 45s197ms | Loss: 1.083 | Acc: 71.498% (35749/50000) | Cls: 0.622  391/391 \n",
            "[2022-11-10 01:13:29,208] [train] [Epoch 59] [Loss 1.083] [cls 0.622] [Acc 71.498]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s432ms | Loss: 1.496 | Acc: 60.480% (6048/10000)  79/79 \n",
            "[2022-11-10 01:13:32,020] [val] [Epoch 59] [Loss 1.496] [Acc 60.480]\n",
            "\n",
            "Epoch: 60\n",
            " [=====================================================================================>]  Step: 72ms | Tot: 46s416ms | Loss: 1.091 | Acc: 71.532% (35766/50000) | Cls: 0.623  391/391 \n",
            "[2022-11-10 01:14:19,187] [train] [Epoch 60] [Loss 1.091] [cls 0.623] [Acc 71.532]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s479ms | Loss: 1.432 | Acc: 62.650% (6265/10000)  79/79 \n",
            "[2022-11-10 01:14:22,083] [val] [Epoch 60] [Loss 1.432] [Acc 62.650]\n",
            "Saving..\n",
            "\n",
            "Epoch: 61\n",
            " [=====================================================================================>]  Step: 74ms | Tot: 45s604ms | Loss: 1.072 | Acc: 71.578% (35789/50000) | Cls: 0.623  391/391 \n",
            "[2022-11-10 01:15:08,510] [train] [Epoch 61] [Loss 1.072] [cls 0.623] [Acc 71.578]\n",
            " [====================================================================================>.]  Step: 10ms | Tot: 2s535ms | Loss: 1.522 | Acc: 59.750% (5975/10000)  79/79 \n",
            "[2022-11-10 01:15:11,452] [val] [Epoch 61] [Loss 1.522] [Acc 59.750]\n",
            "\n",
            "Epoch: 62\n",
            " [=====================================================================================>]  Step: 73ms | Tot: 45s513ms | Loss: 1.078 | Acc: 71.562% (35781/50000) | Cls: 0.619  391/391 \n",
            "[2022-11-10 01:15:57,597] [train] [Epoch 62] [Loss 1.078] [cls 0.619] [Acc 71.562]\n",
            " [====================================================================================>.]  Step: 10ms | Tot: 2s467ms | Loss: 1.479 | Acc: 61.310% (6131/10000)  79/79 \n",
            "[2022-11-10 01:16:00,439] [val] [Epoch 62] [Loss 1.479] [Acc 61.310]\n",
            "\n",
            "Epoch: 63\n",
            " [=====================================================================================>]  Step: 72ms | Tot: 45s359ms | Loss: 1.072 | Acc: 71.850% (35925/50000) | Cls: 0.619  391/391 \n",
            "[2022-11-10 01:16:46,648] [train] [Epoch 63] [Loss 1.072] [cls 0.619] [Acc 71.850]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s523ms | Loss: 1.421 | Acc: 61.780% (6178/10000)  79/79 \n",
            "[2022-11-10 01:16:49,565] [val] [Epoch 63] [Loss 1.421] [Acc 61.780]\n",
            "\n",
            "Epoch: 64\n",
            " [=====================================================================================>]  Step: 72ms | Tot: 46s312ms | Loss: 1.072 | Acc: 71.974% (35987/50000) | Cls: 0.615  391/391 \n",
            "[2022-11-10 01:17:36,698] [train] [Epoch 64] [Loss 1.072] [cls 0.615] [Acc 71.974]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s510ms | Loss: 1.448 | Acc: 61.460% (6146/10000)  79/79 \n",
            "[2022-11-10 01:17:39,617] [val] [Epoch 64] [Loss 1.448] [Acc 61.460]\n",
            "\n",
            "Epoch: 65\n",
            " [=====================================================================================>]  Step: 71ms | Tot: 45s587ms | Loss: 1.057 | Acc: 72.372% (36186/50000) | Cls: 0.619  391/391 \n",
            "[2022-11-10 01:18:25,856] [train] [Epoch 65] [Loss 1.057] [cls 0.619] [Acc 72.372]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s508ms | Loss: 1.451 | Acc: 61.410% (6141/10000)  79/79 \n",
            "[2022-11-10 01:18:28,777] [val] [Epoch 65] [Loss 1.451] [Acc 61.410]\n",
            "\n",
            "Epoch: 66\n",
            " [=====================================================================================>]  Step: 69ms | Tot: 45s878ms | Loss: 1.063 | Acc: 71.930% (35965/50000) | Cls: 0.617  391/391 \n",
            "[2022-11-10 01:19:15,491] [train] [Epoch 66] [Loss 1.063] [cls 0.617] [Acc 71.930]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s552ms | Loss: 1.520 | Acc: 60.140% (6014/10000)  79/79 \n",
            "[2022-11-10 01:19:18,444] [val] [Epoch 66] [Loss 1.520] [Acc 60.140]\n",
            "\n",
            "Epoch: 67\n",
            " [=====================================================================================>]  Step: 75ms | Tot: 45s715ms | Loss: 1.057 | Acc: 72.060% (36030/50000) | Cls: 0.615  391/391 \n",
            "[2022-11-10 01:20:04,963] [train] [Epoch 67] [Loss 1.057] [cls 0.615] [Acc 72.060]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s617ms | Loss: 1.465 | Acc: 60.630% (6063/10000)  79/79 \n",
            "[2022-11-10 01:20:07,959] [val] [Epoch 67] [Loss 1.465] [Acc 60.630]\n",
            "\n",
            "Epoch: 68\n",
            " [=====================================================================================>]  Step: 65ms | Tot: 46s776ms | Loss: 1.050 | Acc: 72.348% (36174/50000) | Cls: 0.612  391/391 \n",
            "[2022-11-10 01:20:55,771] [train] [Epoch 68] [Loss 1.050] [cls 0.612] [Acc 72.348]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s604ms | Loss: 1.462 | Acc: 61.210% (6121/10000)  79/79 \n",
            "[2022-11-10 01:20:58,693] [val] [Epoch 68] [Loss 1.462] [Acc 61.210]\n",
            "\n",
            "Epoch: 69\n",
            " [=====================================================================================>]  Step: 70ms | Tot: 45s882ms | Loss: 1.052 | Acc: 72.236% (36118/50000) | Cls: 0.614  391/391 \n",
            "[2022-11-10 01:21:45,371] [train] [Epoch 69] [Loss 1.052] [cls 0.614] [Acc 72.236]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s550ms | Loss: 1.476 | Acc: 61.220% (6122/10000)  79/79 \n",
            "[2022-11-10 01:21:48,283] [val] [Epoch 69] [Loss 1.476] [Acc 61.220]\n",
            "\n",
            "Epoch: 70\n",
            " [=====================================================================================>]  Step: 73ms | Tot: 46s116ms | Loss: 1.044 | Acc: 72.600% (36300/50000) | Cls: 0.605  391/391 \n",
            "[2022-11-10 01:22:35,198] [train] [Epoch 70] [Loss 1.044] [cls 0.605] [Acc 72.600]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s489ms | Loss: 1.547 | Acc: 59.630% (5963/10000)  79/79 \n",
            "[2022-11-10 01:22:38,107] [val] [Epoch 70] [Loss 1.547] [Acc 59.630]\n",
            "\n",
            "Epoch: 71\n",
            " [=====================================================================================>]  Step: 75ms | Tot: 46s908ms | Loss: 1.040 | Acc: 72.638% (36319/50000) | Cls: 0.607  391/391 \n",
            "[2022-11-10 01:23:25,782] [train] [Epoch 71] [Loss 1.040] [cls 0.607] [Acc 72.638]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s543ms | Loss: 1.465 | Acc: 61.250% (6125/10000)  79/79 \n",
            "[2022-11-10 01:23:28,727] [val] [Epoch 71] [Loss 1.465] [Acc 61.250]\n",
            "\n",
            "Epoch: 72\n",
            " [=====================================================================================>]  Step: 78ms | Tot: 46s288ms | Loss: 1.044 | Acc: 72.716% (36358/50000) | Cls: 0.610  391/391 \n",
            "[2022-11-10 01:24:15,815] [train] [Epoch 72] [Loss 1.044] [cls 0.610] [Acc 72.716]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s593ms | Loss: 1.448 | Acc: 61.930% (6193/10000)  79/79 \n",
            "[2022-11-10 01:24:18,723] [val] [Epoch 72] [Loss 1.448] [Acc 61.930]\n",
            "\n",
            "Epoch: 73\n",
            " [=====================================================================================>]  Step: 82ms | Tot: 46s43ms | Loss: 1.043 | Acc: 72.450% (36225/50000) | Cls: 0.613  391/391 \n",
            "[2022-11-10 01:25:05,559] [train] [Epoch 73] [Loss 1.043] [cls 0.613] [Acc 72.450]\n",
            " [====================================================================================>.]  Step: 12ms | Tot: 2s643ms | Loss: 1.486 | Acc: 61.150% (6115/10000)  79/79 \n",
            "[2022-11-10 01:25:08,548] [val] [Epoch 73] [Loss 1.486] [Acc 61.150]\n",
            "\n",
            "Epoch: 74\n",
            " [=====================================================================================>]  Step: 81ms | Tot: 45s950ms | Loss: 1.037 | Acc: 72.772% (36386/50000) | Cls: 0.605  391/391 \n",
            "[2022-11-10 01:25:55,284] [train] [Epoch 74] [Loss 1.037] [cls 0.605] [Acc 72.772]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s561ms | Loss: 1.474 | Acc: 61.390% (6139/10000)  79/79 \n",
            "[2022-11-10 01:25:58,245] [val] [Epoch 74] [Loss 1.474] [Acc 61.390]\n",
            "\n",
            "Epoch: 75\n",
            " [=====================================================================================>]  Step: 70ms | Tot: 47s17ms | Loss: 1.038 | Acc: 72.804% (36402/50000) | Cls: 0.605  391/391 \n",
            "[2022-11-10 01:26:46,010] [train] [Epoch 75] [Loss 1.038] [cls 0.605] [Acc 72.804]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s611ms | Loss: 1.495 | Acc: 60.730% (6073/10000)  79/79 \n",
            "[2022-11-10 01:26:48,942] [val] [Epoch 75] [Loss 1.495] [Acc 60.730]\n",
            "\n",
            "Epoch: 76\n",
            " [=====================================================================================>]  Step: 71ms | Tot: 45s818ms | Loss: 1.028 | Acc: 73.074% (36537/50000) | Cls: 0.606  391/391 \n",
            "[2022-11-10 01:27:35,556] [train] [Epoch 76] [Loss 1.028] [cls 0.606] [Acc 73.074]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s596ms | Loss: 1.429 | Acc: 61.940% (6194/10000)  79/79 \n",
            "[2022-11-10 01:27:38,482] [val] [Epoch 76] [Loss 1.429] [Acc 61.940]\n",
            "\n",
            "Epoch: 77\n",
            " [=====================================================================================>]  Step: 75ms | Tot: 45s648ms | Loss: 1.029 | Acc: 73.054% (36527/50000) | Cls: 0.602  391/391 \n",
            "[2022-11-10 01:28:24,920] [train] [Epoch 77] [Loss 1.029] [cls 0.602] [Acc 73.054]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s545ms | Loss: 1.491 | Acc: 60.880% (6088/10000)  79/79 \n",
            "[2022-11-10 01:28:27,874] [val] [Epoch 77] [Loss 1.491] [Acc 60.880]\n",
            "\n",
            "Epoch: 78\n",
            " [=====================================================================================>]  Step: 71ms | Tot: 46s269ms | Loss: 1.029 | Acc: 72.898% (36449/50000) | Cls: 0.605  391/391 \n",
            "[2022-11-10 01:29:14,951] [train] [Epoch 78] [Loss 1.029] [cls 0.605] [Acc 72.898]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s569ms | Loss: 1.493 | Acc: 60.390% (6039/10000)  79/79 \n",
            "[2022-11-10 01:29:17,872] [val] [Epoch 78] [Loss 1.493] [Acc 60.390]\n",
            "\n",
            "Epoch: 79\n",
            " [=====================================================================================>]  Step: 72ms | Tot: 46s960ms | Loss: 1.018 | Acc: 73.204% (36602/50000) | Cls: 0.604  391/391 \n",
            "[2022-11-10 01:30:05,681] [train] [Epoch 79] [Loss 1.018] [cls 0.604] [Acc 73.204]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s589ms | Loss: 1.480 | Acc: 61.510% (6151/10000)  79/79 \n",
            "[2022-11-10 01:30:08,586] [val] [Epoch 79] [Loss 1.480] [Acc 61.510]\n",
            "\n",
            "Epoch: 80\n",
            " [=====================================================================================>]  Step: 83ms | Tot: 45s953ms | Loss: 1.016 | Acc: 73.422% (36711/50000) | Cls: 0.603  391/391 \n",
            "[2022-11-10 01:30:55,376] [train] [Epoch 80] [Loss 1.016] [cls 0.603] [Acc 73.422]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s594ms | Loss: 1.522 | Acc: 60.290% (6029/10000)  79/79 \n",
            "[2022-11-10 01:30:58,293] [val] [Epoch 80] [Loss 1.522] [Acc 60.290]\n",
            "\n",
            "Epoch: 81\n",
            " [=====================================================================================>]  Step: 72ms | Tot: 46s88ms | Loss: 1.018 | Acc: 73.320% (36660/50000) | Cls: 0.603  391/391 \n",
            "[2022-11-10 01:31:45,189] [train] [Epoch 81] [Loss 1.018] [cls 0.603] [Acc 73.320]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s623ms | Loss: 1.502 | Acc: 60.580% (6058/10000)  79/79 \n",
            "[2022-11-10 01:31:48,115] [val] [Epoch 81] [Loss 1.502] [Acc 60.580]\n",
            "\n",
            "Epoch: 82\n",
            " [=====================================================================================>]  Step: 71ms | Tot: 46s35ms | Loss: 1.015 | Acc: 73.446% (36723/50000) | Cls: 0.597  391/391 \n",
            "[2022-11-10 01:32:34,905] [train] [Epoch 82] [Loss 1.015] [cls 0.597] [Acc 73.446]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s534ms | Loss: 1.445 | Acc: 61.760% (6176/10000)  79/79 \n",
            "[2022-11-10 01:32:37,834] [val] [Epoch 82] [Loss 1.445] [Acc 61.760]\n",
            "\n",
            "Epoch: 83\n",
            " [=====================================================================================>]  Step: 73ms | Tot: 46s681ms | Loss: 1.017 | Acc: 73.110% (36555/50000) | Cls: 0.603  391/391 \n",
            "[2022-11-10 01:33:25,362] [train] [Epoch 83] [Loss 1.017] [cls 0.603] [Acc 73.110]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s528ms | Loss: 1.458 | Acc: 61.130% (6113/10000)  79/79 \n",
            "[2022-11-10 01:33:28,253] [val] [Epoch 83] [Loss 1.458] [Acc 61.130]\n",
            "\n",
            "Epoch: 84\n",
            " [=====================================================================================>]  Step: 71ms | Tot: 46s313ms | Loss: 1.014 | Acc: 73.362% (36681/50000) | Cls: 0.604  391/391 \n",
            "[2022-11-10 01:34:15,239] [train] [Epoch 84] [Loss 1.014] [cls 0.604] [Acc 73.362]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s548ms | Loss: 1.363 | Acc: 63.600% (6360/10000)  79/79 \n",
            "[2022-11-10 01:34:18,172] [val] [Epoch 84] [Loss 1.363] [Acc 63.600]\n",
            "Saving..\n",
            "\n",
            "Epoch: 85\n",
            " [=====================================================================================>]  Step: 67ms | Tot: 45s961ms | Loss: 0.997 | Acc: 73.822% (36911/50000) | Cls: 0.604  391/391 \n",
            "[2022-11-10 01:35:05,014] [train] [Epoch 85] [Loss 0.997] [cls 0.604] [Acc 73.822]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s583ms | Loss: 1.519 | Acc: 60.510% (6051/10000)  79/79 \n",
            "[2022-11-10 01:35:07,935] [val] [Epoch 85] [Loss 1.519] [Acc 60.510]\n",
            "\n",
            "Epoch: 86\n",
            " [=====================================================================================>]  Step: 76ms | Tot: 46s885ms | Loss: 1.006 | Acc: 73.310% (36655/50000) | Cls: 0.600  391/391 \n",
            "[2022-11-10 01:35:55,574] [train] [Epoch 86] [Loss 1.006] [cls 0.600] [Acc 73.310]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s481ms | Loss: 1.381 | Acc: 63.190% (6319/10000)  79/79 \n",
            "[2022-11-10 01:35:58,450] [val] [Epoch 86] [Loss 1.381] [Acc 63.190]\n",
            "\n",
            "Epoch: 87\n",
            " [=====================================================================================>]  Step: 74ms | Tot: 45s917ms | Loss: 0.992 | Acc: 73.994% (36997/50000) | Cls: 0.594  391/391 \n",
            "[2022-11-10 01:36:45,117] [train] [Epoch 87] [Loss 0.992] [cls 0.594] [Acc 73.994]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s555ms | Loss: 1.448 | Acc: 61.900% (6190/10000)  79/79 \n",
            "[2022-11-10 01:36:48,056] [val] [Epoch 87] [Loss 1.448] [Acc 61.900]\n",
            "\n",
            "Epoch: 88\n",
            " [=====================================================================================>]  Step: 67ms | Tot: 45s677ms | Loss: 1.002 | Acc: 73.504% (36752/50000) | Cls: 0.597  391/391 \n",
            "[2022-11-10 01:37:34,563] [train] [Epoch 88] [Loss 1.002] [cls 0.597] [Acc 73.504]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s637ms | Loss: 1.470 | Acc: 60.900% (6090/10000)  79/79 \n",
            "[2022-11-10 01:37:37,535] [val] [Epoch 88] [Loss 1.470] [Acc 60.900]\n",
            "\n",
            "Epoch: 89\n",
            " [=====================================================================================>]  Step: 71ms | Tot: 45s889ms | Loss: 0.995 | Acc: 73.754% (36877/50000) | Cls: 0.596  391/391 \n",
            "[2022-11-10 01:38:24,128] [train] [Epoch 89] [Loss 0.995] [cls 0.596] [Acc 73.754]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s634ms | Loss: 1.436 | Acc: 62.300% (6230/10000)  79/79 \n",
            "[2022-11-10 01:38:27,089] [val] [Epoch 89] [Loss 1.436] [Acc 62.300]\n",
            "\n",
            "Epoch: 90\n",
            " [=====================================================================================>]  Step: 69ms | Tot: 47s299ms | Loss: 0.997 | Acc: 73.682% (36841/50000) | Cls: 0.593  391/391 \n",
            "[2022-11-10 01:39:15,186] [train] [Epoch 90] [Loss 0.997] [cls 0.593] [Acc 73.682]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s556ms | Loss: 1.514 | Acc: 60.250% (6025/10000)  79/79 \n",
            "[2022-11-10 01:39:18,115] [val] [Epoch 90] [Loss 1.514] [Acc 60.250]\n",
            "\n",
            "Epoch: 91\n",
            " [=====================================================================================>]  Step: 81ms | Tot: 45s878ms | Loss: 0.985 | Acc: 74.180% (37090/50000) | Cls: 0.597  391/391 \n",
            "[2022-11-10 01:40:04,787] [train] [Epoch 91] [Loss 0.985] [cls 0.597] [Acc 74.180]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s545ms | Loss: 1.445 | Acc: 62.170% (6217/10000)  79/79 \n",
            "[2022-11-10 01:40:07,679] [val] [Epoch 91] [Loss 1.445] [Acc 62.170]\n",
            "\n",
            "Epoch: 92\n",
            " [=====================================================================================>]  Step: 70ms | Tot: 45s432ms | Loss: 0.987 | Acc: 74.110% (37055/50000) | Cls: 0.590  391/391 \n",
            "[2022-11-10 01:40:53,948] [train] [Epoch 92] [Loss 0.987] [cls 0.590] [Acc 74.110]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s464ms | Loss: 1.468 | Acc: 61.530% (6153/10000)  79/79 \n",
            "[2022-11-10 01:40:56,799] [val] [Epoch 92] [Loss 1.468] [Acc 61.530]\n",
            "\n",
            "Epoch: 93\n",
            " [=====================================================================================>]  Step: 72ms | Tot: 44s894ms | Loss: 0.993 | Acc: 73.916% (36958/50000) | Cls: 0.595  391/391 \n",
            "[2022-11-10 01:41:42,504] [train] [Epoch 93] [Loss 0.993] [cls 0.595] [Acc 73.916]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s554ms | Loss: 1.397 | Acc: 63.260% (6326/10000)  79/79 \n",
            "[2022-11-10 01:41:45,449] [val] [Epoch 93] [Loss 1.397] [Acc 63.260]\n",
            "\n",
            "Epoch: 94\n",
            " [=====================================================================================>]  Step: 71ms | Tot: 46s952ms | Loss: 0.977 | Acc: 74.368% (37184/50000) | Cls: 0.589  391/391 \n",
            "[2022-11-10 01:42:33,234] [train] [Epoch 94] [Loss 0.977] [cls 0.589] [Acc 74.368]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s573ms | Loss: 1.384 | Acc: 63.840% (6384/10000)  79/79 \n",
            "[2022-11-10 01:42:36,230] [val] [Epoch 94] [Loss 1.384] [Acc 63.840]\n",
            "Saving..\n",
            "\n",
            "Epoch: 95\n",
            " [=====================================================================================>]  Step: 73ms | Tot: 46s19ms | Loss: 0.986 | Acc: 74.208% (37104/50000) | Cls: 0.591  391/391 \n",
            "[2022-11-10 01:43:23,158] [train] [Epoch 95] [Loss 0.986] [cls 0.591] [Acc 74.208]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s523ms | Loss: 1.468 | Acc: 62.080% (6208/10000)  79/79 \n",
            "[2022-11-10 01:43:26,095] [val] [Epoch 95] [Loss 1.468] [Acc 62.080]\n",
            "\n",
            "Epoch: 96\n",
            " [=====================================================================================>]  Step: 75ms | Tot: 45s715ms | Loss: 0.979 | Acc: 74.254% (37127/50000) | Cls: 0.589  391/391 \n",
            "[2022-11-10 01:44:12,544] [train] [Epoch 96] [Loss 0.979] [cls 0.589] [Acc 74.254]\n",
            " [====================================================================================>.]  Step: 12ms | Tot: 2s608ms | Loss: 1.551 | Acc: 60.330% (6033/10000)  79/79 \n",
            "[2022-11-10 01:44:15,544] [val] [Epoch 96] [Loss 1.551] [Acc 60.330]\n",
            "\n",
            "Epoch: 97\n",
            " [=====================================================================================>]  Step: 70ms | Tot: 45s700ms | Loss: 0.986 | Acc: 73.874% (36937/50000) | Cls: 0.592  391/391 \n",
            "[2022-11-10 01:45:01,981] [train] [Epoch 97] [Loss 0.986] [cls 0.592] [Acc 73.874]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s541ms | Loss: 1.429 | Acc: 62.730% (6273/10000)  79/79 \n",
            "[2022-11-10 01:45:04,872] [val] [Epoch 97] [Loss 1.429] [Acc 62.730]\n",
            "\n",
            "Epoch: 98\n",
            " [=====================================================================================>]  Step: 75ms | Tot: 46s162ms | Loss: 0.984 | Acc: 74.216% (37108/50000) | Cls: 0.593  391/391 \n",
            "[2022-11-10 01:45:51,670] [train] [Epoch 98] [Loss 0.984] [cls 0.593] [Acc 74.216]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s561ms | Loss: 1.485 | Acc: 61.270% (6127/10000)  79/79 \n",
            "[2022-11-10 01:45:54,566] [val] [Epoch 98] [Loss 1.485] [Acc 61.270]\n",
            "\n",
            "Epoch: 99\n",
            " [=====================================================================================>]  Step: 72ms | Tot: 45s472ms | Loss: 0.979 | Acc: 74.246% (37123/50000) | Cls: 0.583  391/391 \n",
            "[2022-11-10 01:46:40,737] [train] [Epoch 99] [Loss 0.979] [cls 0.583] [Acc 74.246]\n",
            " [====================================================================================>.]  Step: 10ms | Tot: 2s512ms | Loss: 1.424 | Acc: 62.400% (6240/10000)  79/79 \n",
            "[2022-11-10 01:46:43,638] [val] [Epoch 99] [Loss 1.424] [Acc 62.400]\n",
            "\n",
            "Epoch: 100\n",
            " [=====================================================================================>]  Step: 79ms | Tot: 45s695ms | Loss: 0.974 | Acc: 74.364% (37182/50000) | Cls: 0.586  391/391 \n",
            "[2022-11-10 01:47:29,982] [train] [Epoch 100] [Loss 0.974] [cls 0.586] [Acc 74.364]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s580ms | Loss: 1.417 | Acc: 62.480% (6248/10000)  79/79 \n",
            "[2022-11-10 01:47:32,893] [val] [Epoch 100] [Loss 1.417] [Acc 62.480]\n",
            "\n",
            "Epoch: 101\n",
            " [=====================================================================================>]  Step: 74ms | Tot: 45s451ms | Loss: 0.682 | Acc: 82.678% (41339/50000) | Cls: 0.502  391/391 \n",
            "[2022-11-10 01:48:19,016] [train] [Epoch 101] [Loss 0.682] [cls 0.502] [Acc 82.678]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s509ms | Loss: 1.104 | Acc: 69.760% (6976/10000)  79/79 \n",
            "[2022-11-10 01:48:21,912] [val] [Epoch 101] [Loss 1.104] [Acc 69.760]\n",
            "Saving..\n",
            "\n",
            "Epoch: 102\n",
            " [=====================================================================================>]  Step: 72ms | Tot: 45s864ms | Loss: 0.588 | Acc: 84.828% (42414/50000) | Cls: 0.468  391/391 \n",
            "[2022-11-10 01:49:08,550] [train] [Epoch 102] [Loss 0.588] [cls 0.468] [Acc 84.828]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s492ms | Loss: 1.098 | Acc: 69.740% (6974/10000)  79/79 \n",
            "[2022-11-10 01:49:11,421] [val] [Epoch 102] [Loss 1.098] [Acc 69.740]\n",
            "\n",
            "Epoch: 103\n",
            " [=====================================================================================>]  Step: 74ms | Tot: 45s375ms | Loss: 0.555 | Acc: 85.792% (42896/50000) | Cls: 0.460  391/391 \n",
            "[2022-11-10 01:49:57,499] [train] [Epoch 103] [Loss 0.555] [cls 0.460] [Acc 85.792]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s560ms | Loss: 1.096 | Acc: 69.740% (6974/10000)  79/79 \n",
            "[2022-11-10 01:50:00,375] [val] [Epoch 103] [Loss 1.096] [Acc 69.740]\n",
            "\n",
            "Epoch: 104\n",
            " [=====================================================================================>]  Step: 75ms | Tot: 45s318ms | Loss: 0.531 | Acc: 86.368% (43184/50000) | Cls: 0.450  391/391 \n",
            "[2022-11-10 01:50:46,475] [train] [Epoch 104] [Loss 0.531] [cls 0.450] [Acc 86.368]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s530ms | Loss: 1.107 | Acc: 69.620% (6962/10000)  79/79 \n",
            "[2022-11-10 01:50:49,400] [val] [Epoch 104] [Loss 1.107] [Acc 69.620]\n",
            "\n",
            "Epoch: 105\n",
            " [=====================================================================================>]  Step: 70ms | Tot: 45s798ms | Loss: 0.509 | Acc: 87.014% (43507/50000) | Cls: 0.439  391/391 \n",
            "[2022-11-10 01:51:35,963] [train] [Epoch 105] [Loss 0.509] [cls 0.439] [Acc 87.014]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s580ms | Loss: 1.103 | Acc: 69.930% (6993/10000)  79/79 \n",
            "[2022-11-10 01:51:38,926] [val] [Epoch 105] [Loss 1.103] [Acc 69.930]\n",
            "Saving..\n",
            "\n",
            "Epoch: 106\n",
            " [=====================================================================================>]  Step: 74ms | Tot: 46s143ms | Loss: 0.495 | Acc: 87.498% (43749/50000) | Cls: 0.436  391/391 \n",
            "[2022-11-10 01:52:25,970] [train] [Epoch 106] [Loss 0.495] [cls 0.436] [Acc 87.498]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s457ms | Loss: 1.104 | Acc: 70.300% (7030/10000)  79/79 \n",
            "[2022-11-10 01:52:28,818] [val] [Epoch 106] [Loss 1.104] [Acc 70.300]\n",
            "Saving..\n",
            "\n",
            "Epoch: 107\n",
            " [=====================================================================================>]  Step: 79ms | Tot: 45s577ms | Loss: 0.481 | Acc: 87.874% (43937/50000) | Cls: 0.431  391/391 \n",
            "[2022-11-10 01:53:15,231] [train] [Epoch 107] [Loss 0.481] [cls 0.431] [Acc 87.874]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s596ms | Loss: 1.111 | Acc: 70.000% (7000/10000)  79/79 \n",
            "[2022-11-10 01:53:18,141] [val] [Epoch 107] [Loss 1.111] [Acc 70.000]\n",
            "\n",
            "Epoch: 108\n",
            " [=====================================================================================>]  Step: 72ms | Tot: 45s615ms | Loss: 0.470 | Acc: 88.036% (44018/50000) | Cls: 0.425  391/391 \n",
            "[2022-11-10 01:54:04,563] [train] [Epoch 108] [Loss 0.470] [cls 0.425] [Acc 88.036]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s545ms | Loss: 1.116 | Acc: 69.950% (6995/10000)  79/79 \n",
            "[2022-11-10 01:54:07,474] [val] [Epoch 108] [Loss 1.116] [Acc 69.950]\n",
            "\n",
            "Epoch: 109\n",
            " [=====================================================================================>]  Step: 75ms | Tot: 45s854ms | Loss: 0.463 | Acc: 88.136% (44068/50000) | Cls: 0.424  391/391 \n",
            "[2022-11-10 01:54:54,057] [train] [Epoch 109] [Loss 0.463] [cls 0.424] [Acc 88.136]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s533ms | Loss: 1.119 | Acc: 70.020% (7002/10000)  79/79 \n",
            "[2022-11-10 01:54:57,007] [val] [Epoch 109] [Loss 1.119] [Acc 70.020]\n",
            "\n",
            "Epoch: 110\n",
            " [=====================================================================================>]  Step: 75ms | Tot: 46s291ms | Loss: 0.449 | Acc: 88.652% (44326/50000) | Cls: 0.419  391/391 \n",
            "[2022-11-10 01:55:44,127] [train] [Epoch 110] [Loss 0.449] [cls 0.419] [Acc 88.652]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s507ms | Loss: 1.116 | Acc: 69.920% (6992/10000)  79/79 \n",
            "[2022-11-10 01:55:47,006] [val] [Epoch 110] [Loss 1.116] [Acc 69.920]\n",
            "\n",
            "Epoch: 111\n",
            " [=====================================================================================>]  Step: 73ms | Tot: 45s360ms | Loss: 0.436 | Acc: 89.020% (44510/50000) | Cls: 0.416  391/391 \n",
            "[2022-11-10 01:56:33,142] [train] [Epoch 111] [Loss 0.436] [cls 0.416] [Acc 89.020]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s543ms | Loss: 1.118 | Acc: 70.080% (7008/10000)  79/79 \n",
            "[2022-11-10 01:56:36,070] [val] [Epoch 111] [Loss 1.118] [Acc 70.080]\n",
            "\n",
            "Epoch: 112\n",
            " [=====================================================================================>]  Step: 74ms | Tot: 45s703ms | Loss: 0.433 | Acc: 88.984% (44492/50000) | Cls: 0.411  391/391 \n",
            "[2022-11-10 01:57:22,590] [train] [Epoch 112] [Loss 0.433] [cls 0.411] [Acc 88.984]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s448ms | Loss: 1.122 | Acc: 69.810% (6981/10000)  79/79 \n",
            "[2022-11-10 01:57:25,454] [val] [Epoch 112] [Loss 1.122] [Acc 69.810]\n",
            "\n",
            "Epoch: 113\n",
            " [=====================================================================================>]  Step: 74ms | Tot: 45s625ms | Loss: 0.424 | Acc: 89.350% (44675/50000) | Cls: 0.409  391/391 \n",
            "[2022-11-10 01:58:11,928] [train] [Epoch 113] [Loss 0.424] [cls 0.409] [Acc 89.350]\n",
            " [====================================================================================>.]  Step: 10ms | Tot: 2s559ms | Loss: 1.122 | Acc: 70.160% (7016/10000)  79/79 \n",
            "[2022-11-10 01:58:14,823] [val] [Epoch 113] [Loss 1.122] [Acc 70.160]\n",
            "\n",
            "Epoch: 114\n",
            " [=====================================================================================>]  Step: 73ms | Tot: 45s527ms | Loss: 0.416 | Acc: 89.470% (44735/50000) | Cls: 0.406  391/391 \n",
            "[2022-11-10 01:59:01,134] [train] [Epoch 114] [Loss 0.416] [cls 0.406] [Acc 89.470]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s498ms | Loss: 1.136 | Acc: 69.680% (6968/10000)  79/79 \n",
            "[2022-11-10 01:59:04,040] [val] [Epoch 114] [Loss 1.136] [Acc 69.680]\n",
            "\n",
            "Epoch: 115\n",
            " [=====================================================================================>]  Step: 74ms | Tot: 44s725ms | Loss: 0.405 | Acc: 89.916% (44958/50000) | Cls: 0.405  391/391 \n",
            "[2022-11-10 01:59:49,613] [train] [Epoch 115] [Loss 0.405] [cls 0.405] [Acc 89.916]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s506ms | Loss: 1.135 | Acc: 69.560% (6956/10000)  79/79 \n",
            "[2022-11-10 01:59:52,433] [val] [Epoch 115] [Loss 1.135] [Acc 69.560]\n",
            "\n",
            "Epoch: 116\n",
            " [=====================================================================================>]  Step: 72ms | Tot: 44s650ms | Loss: 0.400 | Acc: 89.896% (44948/50000) | Cls: 0.399  391/391 \n",
            "[2022-11-10 02:00:37,865] [train] [Epoch 116] [Loss 0.400] [cls 0.399] [Acc 89.896]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s432ms | Loss: 1.134 | Acc: 69.810% (6981/10000)  79/79 \n",
            "[2022-11-10 02:00:40,697] [val] [Epoch 116] [Loss 1.134] [Acc 69.810]\n",
            "\n",
            "Epoch: 117\n",
            " [=====================================================================================>]  Step: 73ms | Tot: 44s674ms | Loss: 0.391 | Acc: 90.180% (45090/50000) | Cls: 0.395  391/391 \n",
            "[2022-11-10 02:01:26,132] [train] [Epoch 117] [Loss 0.391] [cls 0.395] [Acc 90.180]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s472ms | Loss: 1.132 | Acc: 69.940% (6994/10000)  79/79 \n",
            "[2022-11-10 02:01:28,928] [val] [Epoch 117] [Loss 1.132] [Acc 69.940]\n",
            "\n",
            "Epoch: 118\n",
            " [=====================================================================================>]  Step: 72ms | Tot: 46s5ms | Loss: 0.386 | Acc: 90.420% (45210/50000) | Cls: 0.390  391/391 \n",
            "[2022-11-10 02:02:15,700] [train] [Epoch 118] [Loss 0.386] [cls 0.390] [Acc 90.420]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s492ms | Loss: 1.142 | Acc: 70.220% (7022/10000)  79/79 \n",
            "[2022-11-10 02:02:18,605] [val] [Epoch 118] [Loss 1.142] [Acc 70.220]\n",
            "\n",
            "Epoch: 119\n",
            " [=====================================================================================>]  Step: 74ms | Tot: 45s264ms | Loss: 0.383 | Acc: 90.428% (45214/50000) | Cls: 0.390  391/391 \n",
            "[2022-11-10 02:03:04,636] [train] [Epoch 119] [Loss 0.383] [cls 0.390] [Acc 90.428]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s509ms | Loss: 1.145 | Acc: 69.970% (6997/10000)  79/79 \n",
            "[2022-11-10 02:03:07,561] [val] [Epoch 119] [Loss 1.145] [Acc 69.970]\n",
            "\n",
            "Epoch: 120\n",
            " [=====================================================================================>]  Step: 78ms | Tot: 45s384ms | Loss: 0.373 | Acc: 90.712% (45356/50000) | Cls: 0.388  391/391 \n",
            "[2022-11-10 02:03:53,734] [train] [Epoch 120] [Loss 0.373] [cls 0.388] [Acc 90.712]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s488ms | Loss: 1.143 | Acc: 70.150% (7015/10000)  79/79 \n",
            "[2022-11-10 02:03:56,610] [val] [Epoch 120] [Loss 1.143] [Acc 70.150]\n",
            "\n",
            "Epoch: 121\n",
            " [=====================================================================================>]  Step: 80ms | Tot: 45s232ms | Loss: 0.373 | Acc: 90.586% (45293/50000) | Cls: 0.389  391/391 \n",
            "[2022-11-10 02:04:42,678] [train] [Epoch 121] [Loss 0.373] [cls 0.389] [Acc 90.586]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s554ms | Loss: 1.153 | Acc: 69.980% (6998/10000)  79/79 \n",
            "[2022-11-10 02:04:45,625] [val] [Epoch 121] [Loss 1.153] [Acc 69.980]\n",
            "\n",
            "Epoch: 122\n",
            " [=====================================================================================>]  Step: 79ms | Tot: 46s536ms | Loss: 0.362 | Acc: 90.874% (45437/50000) | Cls: 0.386  391/391 \n",
            "[2022-11-10 02:05:32,958] [train] [Epoch 122] [Loss 0.362] [cls 0.386] [Acc 90.874]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s522ms | Loss: 1.154 | Acc: 69.650% (6965/10000)  79/79 \n",
            "[2022-11-10 02:05:35,832] [val] [Epoch 122] [Loss 1.154] [Acc 69.650]\n",
            "\n",
            "Epoch: 123\n",
            " [=====================================================================================>]  Step: 72ms | Tot: 45s697ms | Loss: 0.357 | Acc: 91.096% (45548/50000) | Cls: 0.380  391/391 \n",
            "[2022-11-10 02:06:22,229] [train] [Epoch 123] [Loss 0.357] [cls 0.380] [Acc 91.096]\n",
            " [====================================================================================>.]  Step: 10ms | Tot: 2s518ms | Loss: 1.156 | Acc: 69.800% (6980/10000)  79/79 \n",
            "[2022-11-10 02:06:25,078] [val] [Epoch 123] [Loss 1.156] [Acc 69.800]\n",
            "\n",
            "Epoch: 124\n",
            " [=====================================================================================>]  Step: 73ms | Tot: 45s430ms | Loss: 0.354 | Acc: 91.078% (45539/50000) | Cls: 0.379  391/391 \n",
            "[2022-11-10 02:07:11,254] [train] [Epoch 124] [Loss 0.354] [cls 0.379] [Acc 91.078]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s517ms | Loss: 1.163 | Acc: 69.670% (6967/10000)  79/79 \n",
            "[2022-11-10 02:07:14,160] [val] [Epoch 124] [Loss 1.163] [Acc 69.670]\n",
            "\n",
            "Epoch: 125\n",
            " [=====================================================================================>]  Step: 73ms | Tot: 45s495ms | Loss: 0.352 | Acc: 91.192% (45596/50000) | Cls: 0.374  391/391 \n",
            "[2022-11-10 02:08:00,450] [train] [Epoch 125] [Loss 0.352] [cls 0.374] [Acc 91.192]\n",
            " [====================================================================================>.]  Step: 12ms | Tot: 2s479ms | Loss: 1.160 | Acc: 69.660% (6966/10000)  79/79 \n",
            "[2022-11-10 02:08:03,329] [val] [Epoch 125] [Loss 1.160] [Acc 69.660]\n",
            "\n",
            "Epoch: 126\n",
            " [=====================================================================================>]  Step: 67ms | Tot: 46s271ms | Loss: 0.341 | Acc: 91.624% (45812/50000) | Cls: 0.378  391/391 \n",
            "[2022-11-10 02:08:50,422] [train] [Epoch 126] [Loss 0.341] [cls 0.378] [Acc 91.624]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s514ms | Loss: 1.160 | Acc: 69.720% (6972/10000)  79/79 \n",
            "[2022-11-10 02:08:53,284] [val] [Epoch 126] [Loss 1.160] [Acc 69.720]\n",
            "\n",
            "Epoch: 127\n",
            " [=====================================================================================>]  Step: 77ms | Tot: 45s301ms | Loss: 0.346 | Acc: 91.364% (45682/50000) | Cls: 0.376  391/391 \n",
            "[2022-11-10 02:09:39,375] [train] [Epoch 127] [Loss 0.346] [cls 0.376] [Acc 91.364]\n",
            " [====================================================================================>.]  Step: 11ms | Tot: 2s545ms | Loss: 1.161 | Acc: 69.780% (6978/10000)  79/79 \n",
            "[2022-11-10 02:09:42,243] [val] [Epoch 127] [Loss 1.161] [Acc 69.780]\n",
            "\n",
            "Epoch: 128\n",
            " [=====================================================================================>]  Step: 74ms | Tot: 45s603ms | Loss: 0.339 | Acc: 91.622% (45811/50000) | Cls: 0.370  391/391 \n",
            "[2022-11-10 02:10:28,681] [train] [Epoch 128] [Loss 0.339] [cls 0.370] [Acc 91.622]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s591ms | Loss: 1.170 | Acc: 69.710% (6971/10000)  79/79 \n",
            "[2022-11-10 02:10:31,591] [val] [Epoch 128] [Loss 1.170] [Acc 69.710]\n",
            "\n",
            "Epoch: 129\n",
            " [=====================================================================================>]  Step: 82ms | Tot: 45s483ms | Loss: 0.335 | Acc: 91.610% (45805/50000) | Cls: 0.372  391/391 \n",
            "[2022-11-10 02:11:17,882] [train] [Epoch 129] [Loss 0.335] [cls 0.372] [Acc 91.610]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s618ms | Loss: 1.171 | Acc: 70.080% (7008/10000)  79/79 \n",
            "[2022-11-10 02:11:20,810] [val] [Epoch 129] [Loss 1.171] [Acc 70.080]\n",
            "\n",
            "Epoch: 130\n",
            " [=====================================================================================>]  Step: 80ms | Tot: 45s961ms | Loss: 0.329 | Acc: 92.034% (46017/50000) | Cls: 0.371  391/391 \n",
            "[2022-11-10 02:12:07,563] [train] [Epoch 130] [Loss 0.329] [cls 0.371] [Acc 92.034]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s650ms | Loss: 1.184 | Acc: 69.560% (6956/10000)  79/79 \n",
            "[2022-11-10 02:12:10,537] [val] [Epoch 130] [Loss 1.184] [Acc 69.560]\n",
            "\n",
            "Epoch: 131\n",
            " [=====================================================================================>]  Step: 73ms | Tot: 45s384ms | Loss: 0.322 | Acc: 92.082% (46041/50000) | Cls: 0.365  391/391 \n",
            "[2022-11-10 02:12:56,543] [train] [Epoch 131] [Loss 0.322] [cls 0.365] [Acc 92.082]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s549ms | Loss: 1.184 | Acc: 69.280% (6928/10000)  79/79 \n",
            "[2022-11-10 02:12:59,423] [val] [Epoch 131] [Loss 1.184] [Acc 69.280]\n",
            "\n",
            "Epoch: 132\n",
            " [=====================================================================================>]  Step: 87ms | Tot: 45s591ms | Loss: 0.320 | Acc: 92.054% (46027/50000) | Cls: 0.369  391/391 \n",
            "[2022-11-10 02:13:45,768] [train] [Epoch 132] [Loss 0.320] [cls 0.369] [Acc 92.054]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s616ms | Loss: 1.203 | Acc: 69.440% (6944/10000)  79/79 \n",
            "[2022-11-10 02:13:48,695] [val] [Epoch 132] [Loss 1.203] [Acc 69.440]\n",
            "\n",
            "Epoch: 133\n",
            " [=====================================================================================>]  Step: 76ms | Tot: 45s655ms | Loss: 0.318 | Acc: 92.250% (46125/50000) | Cls: 0.365  391/391 \n",
            "[2022-11-10 02:14:35,176] [train] [Epoch 133] [Loss 0.318] [cls 0.365] [Acc 92.250]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s493ms | Loss: 1.196 | Acc: 69.470% (6947/10000)  79/79 \n",
            "[2022-11-10 02:14:38,068] [val] [Epoch 133] [Loss 1.196] [Acc 69.470]\n",
            "\n",
            "Epoch: 134\n",
            " [=====================================================================================>]  Step: 71ms | Tot: 46s38ms | Loss: 0.314 | Acc: 92.184% (46092/50000) | Cls: 0.367  391/391 \n",
            "[2022-11-10 02:15:24,913] [train] [Epoch 134] [Loss 0.314] [cls 0.367] [Acc 92.184]\n",
            " [====================================================================================>.]  Step: 13ms | Tot: 2s511ms | Loss: 1.197 | Acc: 69.640% (6964/10000)  79/79 \n",
            "[2022-11-10 02:15:27,768] [val] [Epoch 134] [Loss 1.197] [Acc 69.640]\n",
            "\n",
            "Epoch: 135\n",
            " [=====================================================================================>]  Step: 72ms | Tot: 45s125ms | Loss: 0.312 | Acc: 92.320% (46160/50000) | Cls: 0.362  391/391 \n",
            "[2022-11-10 02:16:13,696] [train] [Epoch 135] [Loss 0.312] [cls 0.362] [Acc 92.320]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s580ms | Loss: 1.202 | Acc: 69.480% (6948/10000)  79/79 \n",
            "[2022-11-10 02:16:16,600] [val] [Epoch 135] [Loss 1.202] [Acc 69.480]\n",
            "\n",
            "Epoch: 136\n",
            " [=====================================================================================>]  Step: 71ms | Tot: 45s5ms | Loss: 0.313 | Acc: 92.346% (46173/50000) | Cls: 0.358  391/391 \n",
            "[2022-11-10 02:17:02,399] [train] [Epoch 136] [Loss 0.313] [cls 0.358] [Acc 92.346]\n",
            " [====================================================================================>.]  Step: 11ms | Tot: 2s553ms | Loss: 1.197 | Acc: 69.650% (6965/10000)  79/79 \n",
            "[2022-11-10 02:17:05,296] [val] [Epoch 136] [Loss 1.197] [Acc 69.650]\n",
            "\n",
            "Epoch: 137\n",
            " [=====================================================================================>]  Step: 71ms | Tot: 45s281ms | Loss: 0.306 | Acc: 92.472% (46236/50000) | Cls: 0.353  391/391 \n",
            "[2022-11-10 02:17:51,380] [train] [Epoch 137] [Loss 0.306] [cls 0.353] [Acc 92.472]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s562ms | Loss: 1.206 | Acc: 69.100% (6910/10000)  79/79 \n",
            "[2022-11-10 02:17:54,303] [val] [Epoch 137] [Loss 1.206] [Acc 69.100]\n",
            "\n",
            "Epoch: 138\n",
            " [=====================================================================================>]  Step: 73ms | Tot: 45s934ms | Loss: 0.300 | Acc: 92.736% (46368/50000) | Cls: 0.356  391/391 \n",
            "[2022-11-10 02:18:41,024] [train] [Epoch 138] [Loss 0.300] [cls 0.356] [Acc 92.736]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s432ms | Loss: 1.182 | Acc: 69.810% (6981/10000)  79/79 \n",
            "[2022-11-10 02:18:43,848] [val] [Epoch 138] [Loss 1.182] [Acc 69.810]\n",
            "\n",
            "Epoch: 139\n",
            " [=====================================================================================>]  Step: 71ms | Tot: 45s525ms | Loss: 0.301 | Acc: 92.540% (46270/50000) | Cls: 0.352  391/391 \n",
            "[2022-11-10 02:19:30,210] [train] [Epoch 139] [Loss 0.301] [cls 0.352] [Acc 92.540]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s513ms | Loss: 1.212 | Acc: 69.420% (6942/10000)  79/79 \n",
            "[2022-11-10 02:19:33,051] [val] [Epoch 139] [Loss 1.212] [Acc 69.420]\n",
            "\n",
            "Epoch: 140\n",
            " [=====================================================================================>]  Step: 76ms | Tot: 45s184ms | Loss: 0.301 | Acc: 92.470% (46235/50000) | Cls: 0.358  391/391 \n",
            "[2022-11-10 02:20:19,026] [train] [Epoch 140] [Loss 0.301] [cls 0.358] [Acc 92.470]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s552ms | Loss: 1.203 | Acc: 69.640% (6964/10000)  79/79 \n",
            "[2022-11-10 02:20:21,900] [val] [Epoch 140] [Loss 1.203] [Acc 69.640]\n",
            "\n",
            "Epoch: 141\n",
            " [=====================================================================================>]  Step: 76ms | Tot: 45s278ms | Loss: 0.294 | Acc: 92.836% (46418/50000) | Cls: 0.354  391/391 \n",
            "[2022-11-10 02:21:07,938] [train] [Epoch 141] [Loss 0.294] [cls 0.354] [Acc 92.836]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s594ms | Loss: 1.220 | Acc: 69.110% (6911/10000)  79/79 \n",
            "[2022-11-10 02:21:10,855] [val] [Epoch 141] [Loss 1.220] [Acc 69.110]\n",
            "\n",
            "Epoch: 142\n",
            " [=====================================================================================>]  Step: 69ms | Tot: 46s124ms | Loss: 0.294 | Acc: 92.880% (46440/50000) | Cls: 0.353  391/391 \n",
            "[2022-11-10 02:21:57,786] [train] [Epoch 142] [Loss 0.294] [cls 0.353] [Acc 92.880]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s531ms | Loss: 1.229 | Acc: 69.030% (6903/10000)  79/79 \n",
            "[2022-11-10 02:22:00,635] [val] [Epoch 142] [Loss 1.229] [Acc 69.030]\n",
            "\n",
            "Epoch: 143\n",
            " [=====================================================================================>]  Step: 78ms | Tot: 45s257ms | Loss: 0.293 | Acc: 93.028% (46514/50000) | Cls: 0.351  391/391 \n",
            "[2022-11-10 02:22:46,691] [train] [Epoch 143] [Loss 0.293] [cls 0.351] [Acc 93.028]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s486ms | Loss: 1.230 | Acc: 69.110% (6911/10000)  79/79 \n",
            "[2022-11-10 02:22:49,558] [val] [Epoch 143] [Loss 1.230] [Acc 69.110]\n",
            "\n",
            "Epoch: 144\n",
            " [=====================================================================================>]  Step: 71ms | Tot: 45s340ms | Loss: 0.288 | Acc: 93.028% (46514/50000) | Cls: 0.347  391/391 \n",
            "[2022-11-10 02:23:35,669] [train] [Epoch 144] [Loss 0.288] [cls 0.347] [Acc 93.028]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s487ms | Loss: 1.213 | Acc: 69.600% (6960/10000)  79/79 \n",
            "[2022-11-10 02:23:38,549] [val] [Epoch 144] [Loss 1.213] [Acc 69.600]\n",
            "\n",
            "Epoch: 145\n",
            " [=====================================================================================>]  Step: 77ms | Tot: 45s958ms | Loss: 0.285 | Acc: 93.062% (46531/50000) | Cls: 0.345  391/391 \n",
            "[2022-11-10 02:24:25,121] [train] [Epoch 145] [Loss 0.285] [cls 0.345] [Acc 93.062]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s560ms | Loss: 1.227 | Acc: 69.110% (6911/10000)  79/79 \n",
            "[2022-11-10 02:24:28,002] [val] [Epoch 145] [Loss 1.227] [Acc 69.110]\n",
            "\n",
            "Epoch: 146\n",
            " [=====================================================================================>]  Step: 68ms | Tot: 46s150ms | Loss: 0.284 | Acc: 93.098% (46549/50000) | Cls: 0.350  391/391 \n",
            "[2022-11-10 02:25:14,913] [train] [Epoch 146] [Loss 0.284] [cls 0.350] [Acc 93.098]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s550ms | Loss: 1.196 | Acc: 69.560% (6956/10000)  79/79 \n",
            "[2022-11-10 02:25:17,845] [val] [Epoch 146] [Loss 1.196] [Acc 69.560]\n",
            "\n",
            "Epoch: 147\n",
            " [=====================================================================================>]  Step: 77ms | Tot: 45s265ms | Loss: 0.283 | Acc: 93.150% (46575/50000) | Cls: 0.344  391/391 \n",
            "[2022-11-10 02:26:03,837] [train] [Epoch 147] [Loss 0.283] [cls 0.344] [Acc 93.150]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s544ms | Loss: 1.212 | Acc: 69.300% (6930/10000)  79/79 \n",
            "[2022-11-10 02:26:06,712] [val] [Epoch 147] [Loss 1.212] [Acc 69.300]\n",
            "\n",
            "Epoch: 148\n",
            " [=====================================================================================>]  Step: 70ms | Tot: 45s692ms | Loss: 0.278 | Acc: 93.264% (46632/50000) | Cls: 0.347  391/391 \n",
            "[2022-11-10 02:26:53,204] [train] [Epoch 148] [Loss 0.278] [cls 0.347] [Acc 93.264]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s550ms | Loss: 1.236 | Acc: 69.030% (6903/10000)  79/79 \n",
            "[2022-11-10 02:26:56,141] [val] [Epoch 148] [Loss 1.236] [Acc 69.030]\n",
            "\n",
            "Epoch: 149\n",
            " [=====================================================================================>]  Step: 75ms | Tot: 45s419ms | Loss: 0.279 | Acc: 93.400% (46700/50000) | Cls: 0.343  391/391 \n",
            "[2022-11-10 02:27:42,327] [train] [Epoch 149] [Loss 0.279] [cls 0.343] [Acc 93.400]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s434ms | Loss: 1.243 | Acc: 68.760% (6876/10000)  79/79 \n",
            "[2022-11-10 02:27:45,173] [val] [Epoch 149] [Loss 1.243] [Acc 68.760]\n",
            "\n",
            "Epoch: 150\n",
            " [=====================================================================================>]  Step: 74ms | Tot: 45s722ms | Loss: 0.283 | Acc: 93.076% (46538/50000) | Cls: 0.343  391/391 \n",
            "[2022-11-10 02:28:31,726] [train] [Epoch 150] [Loss 0.283] [cls 0.343] [Acc 93.076]\n",
            " [====================================================================================>.]  Step: 10ms | Tot: 2s486ms | Loss: 1.239 | Acc: 68.890% (6889/10000)  79/79 \n",
            "[2022-11-10 02:28:34,609] [val] [Epoch 150] [Loss 1.239] [Acc 68.890]\n",
            "\n",
            "Epoch: 151\n",
            " [=====================================================================================>]  Step: 80ms | Tot: 44s958ms | Loss: 0.236 | Acc: 94.652% (47326/50000) | Cls: 0.319  391/391 \n",
            "[2022-11-10 02:29:20,346] [train] [Epoch 151] [Loss 0.236] [cls 0.319] [Acc 94.652]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s530ms | Loss: 1.203 | Acc: 69.590% (6959/10000)  79/79 \n",
            "[2022-11-10 02:29:23,208] [val] [Epoch 151] [Loss 1.203] [Acc 69.590]\n",
            "\n",
            "Epoch: 152\n",
            " [=====================================================================================>]  Step: 74ms | Tot: 44s927ms | Loss: 0.223 | Acc: 95.184% (47592/50000) | Cls: 0.307  391/391 \n",
            "[2022-11-10 02:30:08,919] [train] [Epoch 152] [Loss 0.223] [cls 0.307] [Acc 95.184]\n",
            " [====================================================================================>.]  Step: 11ms | Tot: 2s441ms | Loss: 1.198 | Acc: 69.880% (6988/10000)  79/79 \n",
            "[2022-11-10 02:30:11,734] [val] [Epoch 152] [Loss 1.198] [Acc 69.880]\n",
            "\n",
            "Epoch: 153\n",
            " [=====================================================================================>]  Step: 70ms | Tot: 45s449ms | Loss: 0.220 | Acc: 95.032% (47516/50000) | Cls: 0.304  391/391 \n",
            "[2022-11-10 02:30:57,926] [train] [Epoch 153] [Loss 0.220] [cls 0.304] [Acc 95.032]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s460ms | Loss: 1.199 | Acc: 69.750% (6975/10000)  79/79 \n",
            "[2022-11-10 02:31:00,801] [val] [Epoch 153] [Loss 1.199] [Acc 69.750]\n",
            "\n",
            "Epoch: 154\n",
            " [=====================================================================================>]  Step: 77ms | Tot: 45s733ms | Loss: 0.213 | Acc: 95.306% (47653/50000) | Cls: 0.300  391/391 \n",
            "[2022-11-10 02:31:47,340] [train] [Epoch 154] [Loss 0.213] [cls 0.300] [Acc 95.306]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s566ms | Loss: 1.197 | Acc: 69.930% (6993/10000)  79/79 \n",
            "[2022-11-10 02:31:50,234] [val] [Epoch 154] [Loss 1.197] [Acc 69.930]\n",
            "\n",
            "Epoch: 155\n",
            " [=====================================================================================>]  Step: 70ms | Tot: 45s360ms | Loss: 0.210 | Acc: 95.436% (47718/50000) | Cls: 0.298  391/391 \n",
            "[2022-11-10 02:32:36,252] [train] [Epoch 155] [Loss 0.210] [cls 0.298] [Acc 95.436]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s446ms | Loss: 1.206 | Acc: 69.910% (6991/10000)  79/79 \n",
            "[2022-11-10 02:32:39,094] [val] [Epoch 155] [Loss 1.206] [Acc 69.910]\n",
            "\n",
            "Epoch: 156\n",
            " [=====================================================================================>]  Step: 77ms | Tot: 45s104ms | Loss: 0.210 | Acc: 95.476% (47738/50000) | Cls: 0.299  391/391 \n",
            "[2022-11-10 02:33:24,863] [train] [Epoch 156] [Loss 0.210] [cls 0.299] [Acc 95.476]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s567ms | Loss: 1.194 | Acc: 70.080% (7008/10000)  79/79 \n",
            "[2022-11-10 02:33:27,743] [val] [Epoch 156] [Loss 1.194] [Acc 70.080]\n",
            "\n",
            "Epoch: 157\n",
            " [=====================================================================================>]  Step: 65ms | Tot: 45s295ms | Loss: 0.206 | Acc: 95.592% (47796/50000) | Cls: 0.294  391/391 \n",
            "[2022-11-10 02:34:13,710] [train] [Epoch 157] [Loss 0.206] [cls 0.294] [Acc 95.592]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s555ms | Loss: 1.201 | Acc: 69.930% (6993/10000)  79/79 \n",
            "[2022-11-10 02:34:16,598] [val] [Epoch 157] [Loss 1.201] [Acc 69.930]\n",
            "\n",
            "Epoch: 158\n",
            " [=====================================================================================>]  Step: 74ms | Tot: 45s933ms | Loss: 0.205 | Acc: 95.654% (47827/50000) | Cls: 0.292  391/391 \n",
            "[2022-11-10 02:35:03,285] [train] [Epoch 158] [Loss 0.205] [cls 0.292] [Acc 95.654]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s457ms | Loss: 1.200 | Acc: 70.340% (7034/10000)  79/79 \n",
            "[2022-11-10 02:35:06,119] [val] [Epoch 158] [Loss 1.200] [Acc 70.340]\n",
            "Saving..\n",
            "\n",
            "Epoch: 159\n",
            " [=====================================================================================>]  Step: 70ms | Tot: 45s161ms | Loss: 0.200 | Acc: 95.748% (47874/50000) | Cls: 0.289  391/391 \n",
            "[2022-11-10 02:35:52,058] [train] [Epoch 159] [Loss 0.200] [cls 0.289] [Acc 95.748]\n",
            " [====================================================================================>.]  Step: 11ms | Tot: 2s536ms | Loss: 1.202 | Acc: 69.910% (6991/10000)  79/79 \n",
            "[2022-11-10 02:35:54,938] [val] [Epoch 159] [Loss 1.202] [Acc 69.910]\n",
            "\n",
            "Epoch: 160\n",
            " [=====================================================================================>]  Step: 74ms | Tot: 45s84ms | Loss: 0.201 | Acc: 95.650% (47825/50000) | Cls: 0.292  391/391 \n",
            "[2022-11-10 02:36:40,868] [train] [Epoch 160] [Loss 0.201] [cls 0.292] [Acc 95.650]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s491ms | Loss: 1.205 | Acc: 70.000% (7000/10000)  79/79 \n",
            "[2022-11-10 02:36:43,774] [val] [Epoch 160] [Loss 1.205] [Acc 70.000]\n",
            "\n",
            "Epoch: 161\n",
            " [=====================================================================================>]  Step: 73ms | Tot: 45s263ms | Loss: 0.198 | Acc: 95.760% (47880/50000) | Cls: 0.292  391/391 \n",
            "[2022-11-10 02:37:29,858] [train] [Epoch 161] [Loss 0.198] [cls 0.292] [Acc 95.760]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s586ms | Loss: 1.203 | Acc: 69.980% (6998/10000)  79/79 \n",
            "[2022-11-10 02:37:32,798] [val] [Epoch 161] [Loss 1.203] [Acc 69.980]\n",
            "\n",
            "Epoch: 162\n",
            " [=====================================================================================>]  Step: 72ms | Tot: 45s8ms | Loss: 0.198 | Acc: 95.884% (47942/50000) | Cls: 0.288  391/391 \n",
            "[2022-11-10 02:38:18,588] [train] [Epoch 162] [Loss 0.198] [cls 0.288] [Acc 95.884]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s536ms | Loss: 1.208 | Acc: 70.220% (7022/10000)  79/79 \n",
            "[2022-11-10 02:38:21,429] [val] [Epoch 162] [Loss 1.208] [Acc 70.220]\n",
            "\n",
            "Epoch: 163\n",
            " [=====================================================================================>]  Step: 72ms | Tot: 45s889ms | Loss: 0.197 | Acc: 95.804% (47902/50000) | Cls: 0.289  391/391 \n",
            "[2022-11-10 02:39:08,083] [train] [Epoch 163] [Loss 0.197] [cls 0.289] [Acc 95.804]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s477ms | Loss: 1.210 | Acc: 69.680% (6968/10000)  79/79 \n",
            "[2022-11-10 02:39:10,956] [val] [Epoch 163] [Loss 1.210] [Acc 69.680]\n",
            "\n",
            "Epoch: 164\n",
            " [=====================================================================================>]  Step: 75ms | Tot: 45s113ms | Loss: 0.195 | Acc: 95.918% (47959/50000) | Cls: 0.286  391/391 \n",
            "[2022-11-10 02:39:56,784] [train] [Epoch 164] [Loss 0.195] [cls 0.286] [Acc 95.918]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s575ms | Loss: 1.204 | Acc: 70.100% (7010/10000)  79/79 \n",
            "[2022-11-10 02:39:59,709] [val] [Epoch 164] [Loss 1.204] [Acc 70.100]\n",
            "\n",
            "Epoch: 165\n",
            " [=====================================================================================>]  Step: 71ms | Tot: 45s454ms | Loss: 0.192 | Acc: 95.974% (47987/50000) | Cls: 0.286  391/391 \n",
            "[2022-11-10 02:40:45,934] [train] [Epoch 165] [Loss 0.192] [cls 0.286] [Acc 95.974]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s467ms | Loss: 1.206 | Acc: 69.940% (6994/10000)  79/79 \n",
            "[2022-11-10 02:40:48,797] [val] [Epoch 165] [Loss 1.206] [Acc 69.940]\n",
            "\n",
            "Epoch: 166\n",
            " [=====================================================================================>]  Step: 71ms | Tot: 45s648ms | Loss: 0.193 | Acc: 95.852% (47926/50000) | Cls: 0.287  391/391 \n",
            "[2022-11-10 02:41:35,174] [train] [Epoch 166] [Loss 0.193] [cls 0.287] [Acc 95.852]\n",
            " [====================================================================================>.]  Step: 12ms | Tot: 2s455ms | Loss: 1.211 | Acc: 69.850% (6985/10000)  79/79 \n",
            "[2022-11-10 02:41:38,036] [val] [Epoch 166] [Loss 1.211] [Acc 69.850]\n",
            "\n",
            "Epoch: 167\n",
            " [=====================================================================================>]  Step: 70ms | Tot: 46s790ms | Loss: 0.191 | Acc: 95.838% (47919/50000) | Cls: 0.284  391/391 \n",
            "[2022-11-10 02:42:25,591] [train] [Epoch 167] [Loss 0.191] [cls 0.284] [Acc 95.838]\n",
            " [====================================================================================>.]  Step: 10ms | Tot: 2s629ms | Loss: 1.212 | Acc: 70.060% (7006/10000)  79/79 \n",
            "[2022-11-10 02:42:28,563] [val] [Epoch 167] [Loss 1.212] [Acc 70.060]\n",
            "\n",
            "Epoch: 168\n",
            " [=====================================================================================>]  Step: 86ms | Tot: 45s543ms | Loss: 0.189 | Acc: 96.078% (48039/50000) | Cls: 0.284  391/391 \n",
            "[2022-11-10 02:43:14,914] [train] [Epoch 168] [Loss 0.189] [cls 0.284] [Acc 96.078]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s504ms | Loss: 1.216 | Acc: 69.960% (6996/10000)  79/79 \n",
            "[2022-11-10 02:43:17,798] [val] [Epoch 168] [Loss 1.216] [Acc 69.960]\n",
            "\n",
            "Epoch: 169\n",
            " [=====================================================================================>]  Step: 74ms | Tot: 45s537ms | Loss: 0.186 | Acc: 96.138% (48069/50000) | Cls: 0.283  391/391 \n",
            "[2022-11-10 02:44:04,142] [train] [Epoch 169] [Loss 0.186] [cls 0.283] [Acc 96.138]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s454ms | Loss: 1.215 | Acc: 69.860% (6986/10000)  79/79 \n",
            "[2022-11-10 02:44:06,996] [val] [Epoch 169] [Loss 1.215] [Acc 69.860]\n",
            "\n",
            "Epoch: 170\n",
            " [=====================================================================================>]  Step: 89ms | Tot: 45s1ms | Loss: 0.187 | Acc: 96.098% (48049/50000) | Cls: 0.281  391/391 \n",
            "[2022-11-10 02:44:52,816] [train] [Epoch 170] [Loss 0.187] [cls 0.281] [Acc 96.098]\n",
            " [====================================================================================>.]  Step: 12ms | Tot: 2s532ms | Loss: 1.210 | Acc: 70.270% (7027/10000)  79/79 \n",
            "[2022-11-10 02:44:55,711] [val] [Epoch 170] [Loss 1.210] [Acc 70.270]\n",
            "\n",
            "Epoch: 171\n",
            " [=====================================================================================>]  Step: 84ms | Tot: 45s614ms | Loss: 0.187 | Acc: 96.080% (48040/50000) | Cls: 0.283  391/391 \n",
            "[2022-11-10 02:45:42,166] [train] [Epoch 171] [Loss 0.187] [cls 0.283] [Acc 96.080]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s517ms | Loss: 1.212 | Acc: 70.020% (7002/10000)  79/79 \n",
            "[2022-11-10 02:45:44,983] [val] [Epoch 171] [Loss 1.212] [Acc 70.020]\n",
            "\n",
            "Epoch: 172\n",
            " [=====================================================================================>]  Step: 75ms | Tot: 45s16ms | Loss: 0.185 | Acc: 96.104% (48052/50000) | Cls: 0.279  391/391 \n",
            "[2022-11-10 02:46:30,706] [train] [Epoch 172] [Loss 0.185] [cls 0.279] [Acc 96.104]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s413ms | Loss: 1.219 | Acc: 70.060% (7006/10000)  79/79 \n",
            "[2022-11-10 02:46:33,513] [val] [Epoch 172] [Loss 1.219] [Acc 70.060]\n",
            "\n",
            "Epoch: 173\n",
            " [=====================================================================================>]  Step: 80ms | Tot: 44s880ms | Loss: 0.185 | Acc: 96.082% (48041/50000) | Cls: 0.282  391/391 \n",
            "[2022-11-10 02:47:19,112] [train] [Epoch 173] [Loss 0.185] [cls 0.282] [Acc 96.082]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s511ms | Loss: 1.218 | Acc: 69.900% (6990/10000)  79/79 \n",
            "[2022-11-10 02:47:21,940] [val] [Epoch 173] [Loss 1.218] [Acc 69.900]\n",
            "\n",
            "Epoch: 174\n",
            " [=====================================================================================>]  Step: 80ms | Tot: 44s964ms | Loss: 0.184 | Acc: 96.216% (48108/50000) | Cls: 0.282  391/391 \n",
            "[2022-11-10 02:48:07,659] [train] [Epoch 174] [Loss 0.184] [cls 0.282] [Acc 96.216]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s485ms | Loss: 1.219 | Acc: 69.940% (6994/10000)  79/79 \n",
            "[2022-11-10 02:48:10,513] [val] [Epoch 174] [Loss 1.219] [Acc 69.940]\n",
            "\n",
            "Epoch: 175\n",
            " [=====================================================================================>]  Step: 77ms | Tot: 46s9ms | Loss: 0.184 | Acc: 96.152% (48076/50000) | Cls: 0.278  391/391 \n",
            "[2022-11-10 02:48:57,256] [train] [Epoch 175] [Loss 0.184] [cls 0.278] [Acc 96.152]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s570ms | Loss: 1.213 | Acc: 69.860% (6986/10000)  79/79 \n",
            "[2022-11-10 02:49:00,164] [val] [Epoch 175] [Loss 1.213] [Acc 69.860]\n",
            "\n",
            "Epoch: 176\n",
            " [=====================================================================================>]  Step: 73ms | Tot: 45s490ms | Loss: 0.182 | Acc: 96.240% (48120/50000) | Cls: 0.281  391/391 \n",
            "[2022-11-10 02:49:46,435] [train] [Epoch 176] [Loss 0.182] [cls 0.281] [Acc 96.240]\n",
            " [====================================================================================>.]  Step: 12ms | Tot: 2s624ms | Loss: 1.212 | Acc: 70.040% (7004/10000)  79/79 \n",
            "[2022-11-10 02:49:49,372] [val] [Epoch 176] [Loss 1.212] [Acc 70.040]\n",
            "\n",
            "Epoch: 177\n",
            " [=====================================================================================>]  Step: 73ms | Tot: 44s948ms | Loss: 0.181 | Acc: 96.340% (48170/50000) | Cls: 0.277  391/391 \n",
            "[2022-11-10 02:50:35,119] [train] [Epoch 177] [Loss 0.181] [cls 0.277] [Acc 96.340]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s435ms | Loss: 1.223 | Acc: 69.900% (6990/10000)  79/79 \n",
            "[2022-11-10 02:50:37,947] [val] [Epoch 177] [Loss 1.223] [Acc 69.900]\n",
            "\n",
            "Epoch: 178\n",
            " [=====================================================================================>]  Step: 70ms | Tot: 45s213ms | Loss: 0.181 | Acc: 96.356% (48178/50000) | Cls: 0.279  391/391 \n",
            "[2022-11-10 02:51:23,962] [train] [Epoch 178] [Loss 0.181] [cls 0.279] [Acc 96.356]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s524ms | Loss: 1.224 | Acc: 69.960% (6996/10000)  79/79 \n",
            "[2022-11-10 02:51:26,881] [val] [Epoch 178] [Loss 1.224] [Acc 69.960]\n",
            "\n",
            "Epoch: 179\n",
            " [=====================================================================================>]  Step: 74ms | Tot: 46s238ms | Loss: 0.179 | Acc: 96.304% (48152/50000) | Cls: 0.279  391/391 \n",
            "[2022-11-10 02:52:13,901] [train] [Epoch 179] [Loss 0.179] [cls 0.279] [Acc 96.304]\n",
            " [====================================================================================>.]  Step: 11ms | Tot: 2s611ms | Loss: 1.223 | Acc: 69.960% (6996/10000)  79/79 \n",
            "[2022-11-10 02:52:16,826] [val] [Epoch 179] [Loss 1.223] [Acc 69.960]\n",
            "\n",
            "Epoch: 180\n",
            " [=====================================================================================>]  Step: 73ms | Tot: 45s266ms | Loss: 0.181 | Acc: 96.342% (48171/50000) | Cls: 0.277  391/391 \n",
            "[2022-11-10 02:53:02,872] [train] [Epoch 180] [Loss 0.181] [cls 0.277] [Acc 96.342]\n",
            " [====================================================================================>.]  Step: 12ms | Tot: 2s430ms | Loss: 1.221 | Acc: 70.010% (7001/10000)  79/79 \n",
            "[2022-11-10 02:53:05,696] [val] [Epoch 180] [Loss 1.221] [Acc 70.010]\n",
            "\n",
            "Epoch: 181\n",
            " [=====================================================================================>]  Step: 72ms | Tot: 45s253ms | Loss: 0.180 | Acc: 96.336% (48168/50000) | Cls: 0.277  391/391 \n",
            "[2022-11-10 02:53:51,678] [train] [Epoch 181] [Loss 0.180] [cls 0.277] [Acc 96.336]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s478ms | Loss: 1.227 | Acc: 69.810% (6981/10000)  79/79 \n",
            "[2022-11-10 02:53:54,525] [val] [Epoch 181] [Loss 1.227] [Acc 69.810]\n",
            "\n",
            "Epoch: 182\n",
            " [=====================================================================================>]  Step: 71ms | Tot: 45s250ms | Loss: 0.181 | Acc: 96.244% (48122/50000) | Cls: 0.279  391/391 \n",
            "[2022-11-10 02:54:40,442] [train] [Epoch 182] [Loss 0.181] [cls 0.279] [Acc 96.244]\n",
            " [====================================================================================>.]  Step: 11ms | Tot: 2s568ms | Loss: 1.221 | Acc: 70.060% (7006/10000)  79/79 \n",
            "[2022-11-10 02:54:43,302] [val] [Epoch 182] [Loss 1.221] [Acc 70.060]\n",
            "\n",
            "Epoch: 183\n",
            " [=====================================================================================>]  Step: 72ms | Tot: 46s95ms | Loss: 0.177 | Acc: 96.378% (48189/50000) | Cls: 0.279  391/391 \n",
            "[2022-11-10 02:55:30,064] [train] [Epoch 183] [Loss 0.177] [cls 0.279] [Acc 96.378]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s568ms | Loss: 1.221 | Acc: 69.950% (6995/10000)  79/79 \n",
            "[2022-11-10 02:55:32,978] [val] [Epoch 183] [Loss 1.221] [Acc 69.950]\n",
            "\n",
            "Epoch: 184\n",
            " [=====================================================================================>]  Step: 75ms | Tot: 47s531ms | Loss: 0.175 | Acc: 96.420% (48210/50000) | Cls: 0.277  391/391 \n",
            "[2022-11-10 02:56:21,348] [train] [Epoch 184] [Loss 0.175] [cls 0.277] [Acc 96.420]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s581ms | Loss: 1.227 | Acc: 69.810% (6981/10000)  79/79 \n",
            "[2022-11-10 02:56:24,230] [val] [Epoch 184] [Loss 1.227] [Acc 69.810]\n",
            "\n",
            "Epoch: 185\n",
            " [=====================================================================================>]  Step: 72ms | Tot: 46s49ms | Loss: 0.174 | Acc: 96.504% (48252/50000) | Cls: 0.277  391/391 \n",
            "[2022-11-10 02:57:10,997] [train] [Epoch 185] [Loss 0.174] [cls 0.277] [Acc 96.504]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s487ms | Loss: 1.229 | Acc: 70.070% (7007/10000)  79/79 \n",
            "[2022-11-10 02:57:13,881] [val] [Epoch 185] [Loss 1.229] [Acc 70.070]\n",
            "\n",
            "Epoch: 186\n",
            " [=====================================================================================>]  Step: 76ms | Tot: 45s481ms | Loss: 0.177 | Acc: 96.378% (48189/50000) | Cls: 0.275  391/391 \n",
            "[2022-11-10 02:58:00,156] [train] [Epoch 186] [Loss 0.177] [cls 0.275] [Acc 96.378]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s551ms | Loss: 1.232 | Acc: 69.670% (6967/10000)  79/79 \n",
            "[2022-11-10 02:58:03,074] [val] [Epoch 186] [Loss 1.232] [Acc 69.670]\n",
            "\n",
            "Epoch: 187\n",
            " [=====================================================================================>]  Step: 72ms | Tot: 47s84ms | Loss: 0.173 | Acc: 96.424% (48212/50000) | Cls: 0.274  391/391 \n",
            "[2022-11-10 02:58:50,988] [train] [Epoch 187] [Loss 0.173] [cls 0.274] [Acc 96.424]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s615ms | Loss: 1.229 | Acc: 69.820% (6982/10000)  79/79 \n",
            "[2022-11-10 02:58:53,991] [val] [Epoch 187] [Loss 1.229] [Acc 69.820]\n",
            "\n",
            "Epoch: 188\n",
            " [=====================================================================================>]  Step: 62ms | Tot: 50s877ms | Loss: 0.176 | Acc: 96.380% (48190/50000) | Cls: 0.274  391/391 \n",
            "[2022-11-10 02:59:45,703] [train] [Epoch 188] [Loss 0.176] [cls 0.274] [Acc 96.380]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 3s6ms | Loss: 1.229 | Acc: 69.810% (6981/10000)  79/79 \n",
            "[2022-11-10 02:59:49,091] [val] [Epoch 188] [Loss 1.229] [Acc 69.810]\n",
            "\n",
            "Epoch: 189\n",
            " [=====================================================================================>]  Step: 72ms | Tot: 48s313ms | Loss: 0.174 | Acc: 96.340% (48170/50000) | Cls: 0.277  391/391 \n",
            "[2022-11-10 03:00:38,345] [train] [Epoch 189] [Loss 0.174] [cls 0.277] [Acc 96.340]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s577ms | Loss: 1.232 | Acc: 69.730% (6973/10000)  79/79 \n",
            "[2022-11-10 03:00:41,328] [val] [Epoch 189] [Loss 1.232] [Acc 69.730]\n",
            "\n",
            "Epoch: 190\n",
            " [=====================================================================================>]  Step: 74ms | Tot: 46s694ms | Loss: 0.172 | Acc: 96.568% (48284/50000) | Cls: 0.276  391/391 \n",
            "[2022-11-10 03:01:28,856] [train] [Epoch 190] [Loss 0.172] [cls 0.276] [Acc 96.568]\n",
            " [====================================================================================>.]  Step: 13ms | Tot: 2s635ms | Loss: 1.233 | Acc: 69.710% (6971/10000)  79/79 \n",
            "[2022-11-10 03:01:31,837] [val] [Epoch 190] [Loss 1.233] [Acc 69.710]\n",
            "\n",
            "Epoch: 191\n",
            " [=====================================================================================>]  Step: 72ms | Tot: 48s125ms | Loss: 0.172 | Acc: 96.484% (48242/50000) | Cls: 0.275  391/391 \n",
            "[2022-11-10 03:02:20,757] [train] [Epoch 191] [Loss 0.172] [cls 0.275] [Acc 96.484]\n",
            " [====================================================================================>.]  Step: 13ms | Tot: 2s528ms | Loss: 1.231 | Acc: 69.810% (6981/10000)  79/79 \n",
            "[2022-11-10 03:02:23,643] [val] [Epoch 191] [Loss 1.231] [Acc 69.810]\n",
            "\n",
            "Epoch: 192\n",
            " [=====================================================================================>]  Step: 81ms | Tot: 47s12ms | Loss: 0.171 | Acc: 96.446% (48223/50000) | Cls: 0.274  391/391 \n",
            "[2022-11-10 03:03:11,394] [train] [Epoch 192] [Loss 0.171] [cls 0.274] [Acc 96.446]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s661ms | Loss: 1.231 | Acc: 69.770% (6977/10000)  79/79 \n",
            "[2022-11-10 03:03:14,406] [val] [Epoch 192] [Loss 1.231] [Acc 69.770]\n",
            "\n",
            "Epoch: 193\n",
            " [=====================================================================================>]  Step: 79ms | Tot: 47s421ms | Loss: 0.172 | Acc: 96.438% (48219/50000) | Cls: 0.276  391/391 \n",
            "[2022-11-10 03:04:02,672] [train] [Epoch 193] [Loss 0.172] [cls 0.276] [Acc 96.438]\n",
            " [====================================================================================>.]  Step: 11ms | Tot: 2s720ms | Loss: 1.236 | Acc: 69.750% (6975/10000)  79/79 \n",
            "[2022-11-10 03:04:05,753] [val] [Epoch 193] [Loss 1.236] [Acc 69.750]\n",
            "\n",
            "Epoch: 194\n",
            " [=====================================================================================>]  Step: 75ms | Tot: 47s594ms | Loss: 0.173 | Acc: 96.370% (48185/50000) | Cls: 0.273  391/391 \n",
            "[2022-11-10 03:04:54,146] [train] [Epoch 194] [Loss 0.173] [cls 0.273] [Acc 96.370]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s648ms | Loss: 1.232 | Acc: 69.760% (6976/10000)  79/79 \n",
            "[2022-11-10 03:04:57,224] [val] [Epoch 194] [Loss 1.232] [Acc 69.760]\n",
            "\n",
            "Epoch: 195\n",
            " [=====================================================================================>]  Step: 70ms | Tot: 48s343ms | Loss: 0.171 | Acc: 96.602% (48301/50000) | Cls: 0.271  391/391 \n",
            "[2022-11-10 03:05:46,303] [train] [Epoch 195] [Loss 0.171] [cls 0.271] [Acc 96.602]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s591ms | Loss: 1.230 | Acc: 69.830% (6983/10000)  79/79 \n",
            "[2022-11-10 03:05:49,306] [val] [Epoch 195] [Loss 1.230] [Acc 69.830]\n",
            "\n",
            "Epoch: 196\n",
            " [=====================================================================================>]  Step: 73ms | Tot: 45s940ms | Loss: 0.170 | Acc: 96.592% (48296/50000) | Cls: 0.271  391/391 \n",
            "[2022-11-10 03:06:36,034] [train] [Epoch 196] [Loss 0.170] [cls 0.271] [Acc 96.592]\n",
            " [====================================================================================>.]  Step: 11ms | Tot: 2s461ms | Loss: 1.235 | Acc: 70.010% (7001/10000)  79/79 \n",
            "[2022-11-10 03:06:38,925] [val] [Epoch 196] [Loss 1.235] [Acc 70.010]\n",
            "\n",
            "Epoch: 197\n",
            " [=====================================================================================>]  Step: 73ms | Tot: 46s433ms | Loss: 0.169 | Acc: 96.582% (48291/50000) | Cls: 0.273  391/391 \n",
            "[2022-11-10 03:07:26,137] [train] [Epoch 197] [Loss 0.169] [cls 0.273] [Acc 96.582]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s526ms | Loss: 1.241 | Acc: 69.880% (6988/10000)  79/79 \n",
            "[2022-11-10 03:07:29,077] [val] [Epoch 197] [Loss 1.241] [Acc 69.880]\n",
            "\n",
            "Epoch: 198\n",
            " [=====================================================================================>]  Step: 72ms | Tot: 46s200ms | Loss: 0.167 | Acc: 96.678% (48339/50000) | Cls: 0.270  391/391 \n",
            "[2022-11-10 03:08:16,118] [train] [Epoch 198] [Loss 0.167] [cls 0.270] [Acc 96.678]\n",
            " [====================================================================================>.]  Step: 10ms | Tot: 2s550ms | Loss: 1.240 | Acc: 69.480% (6948/10000)  79/79 \n",
            "[2022-11-10 03:08:19,057] [val] [Epoch 198] [Loss 1.240] [Acc 69.480]\n",
            "\n",
            "Epoch: 199\n",
            " [=====================================================================================>]  Step: 70ms | Tot: 47s154ms | Loss: 0.167 | Acc: 96.668% (48334/50000) | Cls: 0.268  391/391 \n",
            "[2022-11-10 03:09:07,000] [train] [Epoch 199] [Loss 0.167] [cls 0.268] [Acc 96.668]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s518ms | Loss: 1.243 | Acc: 69.680% (6968/10000)  79/79 \n",
            "[2022-11-10 03:09:09,927] [val] [Epoch 199] [Loss 1.243] [Acc 69.680]\n",
            "Best Accuracy : 70.33999633789062\n",
            "[2022-11-10 03:09:09,927] [best] [Acc 70.340]\n"
          ]
        }
      ],
      "source": [
        "!python Learning-With-Retrospection/CS-KD_techinque/cs-kd/train.py --sgpu 0 --lr 0.1 --epoch 200 --model resnet56 --name cifar100_resnet56 --decay 1e-4 --dataset cifar100 --dataroot ~/data/ -cls --lamda 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoQMXOOzbBPX"
      },
      "source": [
        "# VGG16-BN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fIgjp4gbHjj"
      },
      "source": [
        "## CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unCILSK39RC4",
        "outputId": "57338521-2d3d-47cf-c0d9-8614cbfca2b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==> Preparing dataset: cifar10\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Number of train dataset:  50000\n",
            "Number of validation dataset:  10000\n",
            "==> Building model: CIFAR10_VGG16\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\" to /root/.cache/torch/hub/checkpoints/vgg16_bn-6c64b313.pth\n",
            "100% 528M/528M [00:07<00:00, 72.1MB/s]\n",
            "1\n",
            "Using CUDA..\n",
            "\"./results/cifar10/CIFAR10_VGG16/cifar10_vgg16\" exists. Overwrite [Y/n]? Y\n",
            "[2022-11-03 15:43:20,366] [main] Learning-With-Retrospection/CS-KD_techinque/cs-kd/train.py --sgpu 0 --lr 0.1 --epoch 200 --model CIFAR10_VGG16 --name cifar10_vgg16 --decay 1e-4 --dataset cifar10 --dataroot /root/data/ -cls --lamda 1\n",
            "[2022-11-03 15:43:20,367] [main] Namespace(batch_size=128, cls=True, dataroot='/root/data/', dataset='cifar10', decay=0.0001, epoch=200, lamda=1.0, lr=0.1, model='CIFAR10_VGG16', name='cifar10_vgg16', ngpu=1, resume=False, saveroot='./results', sgpu=0, temp=4.0)\n",
            "\n",
            "Epoch: 0\n",
            " [=====================================================================================>]  Step: 734ms | Tot: 49s144ms | Loss: 2.076 | Acc: 19.608% (9804/50000) | Cls: 0.136  391/391 \n",
            "[2022-11-03 15:44:13,524] [train] [Epoch 0] [Loss 2.076] [cls 0.136] [Acc 19.608]\n",
            " [====================================================================================>.]  Step: 114ms | Tot: 2s617ms | Loss: 1.873 | Acc: 27.660% (2766/10000)  79/79 \n",
            "[2022-11-03 15:44:16,494] [val] [Epoch 0] [Loss 1.873] [Acc 27.660]\n",
            "Saving..\n",
            "\n",
            "Epoch: 1\n",
            " [=====================================================================================>]  Step: 122ms | Tot: 50s789ms | Loss: 1.714 | Acc: 35.262% (17631/50000) | Cls: 0.271  391/391 \n",
            "[2022-11-03 15:45:12,835] [train] [Epoch 1] [Loss 1.714] [cls 0.271] [Acc 35.262]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s540ms | Loss: 1.697 | Acc: 37.490% (3749/10000)  79/79 \n",
            "[2022-11-03 15:45:15,821] [val] [Epoch 1] [Loss 1.697] [Acc 37.490]\n",
            "Saving..\n",
            "\n",
            "Epoch: 2\n",
            " [=====================================================================================>]  Step: 123ms | Tot: 50s227ms | Loss: 1.441 | Acc: 46.870% (23435/50000) | Cls: 0.351  391/391 \n",
            "[2022-11-03 15:46:11,361] [train] [Epoch 2] [Loss 1.441] [cls 0.351] [Acc 46.870]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s527ms | Loss: 1.445 | Acc: 48.950% (4895/10000)  79/79 \n",
            "[2022-11-03 15:46:14,329] [val] [Epoch 2] [Loss 1.445] [Acc 48.950]\n",
            "Saving..\n",
            "\n",
            "Epoch: 3\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 50s553ms | Loss: 1.312 | Acc: 54.200% (27100/50000) | Cls: 0.371  391/391 \n",
            "[2022-11-03 15:47:09,979] [train] [Epoch 3] [Loss 1.312] [cls 0.371] [Acc 54.200]\n",
            " [====================================================================================>.]  Step: 10ms | Tot: 2s515ms | Loss: 1.226 | Acc: 58.510% (5851/10000)  79/79 \n",
            "[2022-11-03 15:47:12,959] [val] [Epoch 3] [Loss 1.226] [Acc 58.510]\n",
            "Saving..\n",
            "\n",
            "Epoch: 4\n",
            " [=====================================================================================>]  Step: 127ms | Tot: 50s825ms | Loss: 1.200 | Acc: 60.404% (30202/50000) | Cls: 0.394  391/391 \n",
            "[2022-11-03 15:48:08,990] [train] [Epoch 4] [Loss 1.200] [cls 0.394] [Acc 60.404]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s610ms | Loss: 1.195 | Acc: 60.350% (6035/10000)  79/79 \n",
            "[2022-11-03 15:48:12,008] [val] [Epoch 4] [Loss 1.195] [Acc 60.350]\n",
            "Saving..\n",
            "\n",
            "Epoch: 5\n",
            " [=====================================================================================>]  Step: 126ms | Tot: 50s771ms | Loss: 1.084 | Acc: 67.962% (33981/50000) | Cls: 0.423  391/391 \n",
            "[2022-11-03 15:49:08,159] [train] [Epoch 5] [Loss 1.084] [cls 0.423] [Acc 67.962]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s510ms | Loss: 1.176 | Acc: 63.940% (6394/10000)  79/79 \n",
            "[2022-11-03 15:49:11,089] [val] [Epoch 5] [Loss 1.176] [Acc 63.940]\n",
            "Saving..\n",
            "\n",
            "Epoch: 6\n",
            " [=====================================================================================>]  Step: 126ms | Tot: 50s835ms | Loss: 1.014 | Acc: 71.268% (35634/50000) | Cls: 0.425  391/391 \n",
            "[2022-11-03 15:50:07,230] [train] [Epoch 6] [Loss 1.014] [cls 0.425] [Acc 71.268]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s519ms | Loss: 0.970 | Acc: 73.270% (7327/10000)  79/79 \n",
            "[2022-11-03 15:50:10,212] [val] [Epoch 6] [Loss 0.970] [Acc 73.270]\n",
            "Saving..\n",
            "\n",
            "Epoch: 7\n",
            " [=====================================================================================>]  Step: 127ms | Tot: 51s771ms | Loss: 0.924 | Acc: 74.690% (37345/50000) | Cls: 0.428  391/391 \n",
            "[2022-11-03 15:51:07,439] [train] [Epoch 7] [Loss 0.924] [cls 0.428] [Acc 74.690]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s543ms | Loss: 0.823 | Acc: 77.090% (7709/10000)  79/79 \n",
            "[2022-11-03 15:51:10,396] [val] [Epoch 7] [Loss 0.823] [Acc 77.090]\n",
            "Saving..\n",
            "\n",
            "Epoch: 8\n",
            " [=====================================================================================>]  Step: 124ms | Tot: 50s808ms | Loss: 0.897 | Acc: 75.786% (37893/50000) | Cls: 0.437  391/391 \n",
            "[2022-11-03 15:52:06,540] [train] [Epoch 8] [Loss 0.897] [cls 0.437] [Acc 75.786]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s509ms | Loss: 0.998 | Acc: 72.660% (7266/10000)  79/79 \n",
            "[2022-11-03 15:52:09,515] [val] [Epoch 8] [Loss 0.998] [Acc 72.660]\n",
            "\n",
            "Epoch: 9\n",
            " [=====================================================================================>]  Step: 124ms | Tot: 51s184ms | Loss: 0.865 | Acc: 76.994% (38497/50000) | Cls: 0.434  391/391 \n",
            "[2022-11-03 15:53:01,327] [train] [Epoch 9] [Loss 0.865] [cls 0.434] [Acc 76.994]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s581ms | Loss: 0.812 | Acc: 77.890% (7789/10000)  79/79 \n",
            "[2022-11-03 15:53:04,328] [val] [Epoch 9] [Loss 0.812] [Acc 77.890]\n",
            "Saving..\n",
            "\n",
            "Epoch: 10\n",
            " [=====================================================================================>]  Step: 128ms | Tot: 51s14ms | Loss: 0.833 | Acc: 78.332% (39166/50000) | Cls: 0.432  391/391 \n",
            "[2022-11-03 15:54:00,776] [train] [Epoch 10] [Loss 0.833] [cls 0.432] [Acc 78.332]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s585ms | Loss: 0.913 | Acc: 74.170% (7417/10000)  79/79 \n",
            "[2022-11-03 15:54:03,797] [val] [Epoch 10] [Loss 0.913] [Acc 74.170]\n",
            "\n",
            "Epoch: 11\n",
            " [=====================================================================================>]  Step: 122ms | Tot: 51s88ms | Loss: 0.825 | Acc: 78.726% (39363/50000) | Cls: 0.433  391/391 \n",
            "[2022-11-03 15:54:55,763] [train] [Epoch 11] [Loss 0.825] [cls 0.433] [Acc 78.726]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s554ms | Loss: 0.855 | Acc: 78.130% (7813/10000)  79/79 \n",
            "[2022-11-03 15:54:58,733] [val] [Epoch 11] [Loss 0.855] [Acc 78.130]\n",
            "Saving..\n",
            "\n",
            "Epoch: 12\n",
            " [=====================================================================================>]  Step: 126ms | Tot: 51s23ms | Loss: 0.796 | Acc: 79.474% (39737/50000) | Cls: 0.435  391/391 \n",
            "[2022-11-03 15:55:55,054] [train] [Epoch 12] [Loss 0.796] [cls 0.435] [Acc 79.474]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s537ms | Loss: 0.766 | Acc: 81.080% (8108/10000)  79/79 \n",
            "[2022-11-03 15:55:58,063] [val] [Epoch 12] [Loss 0.766] [Acc 81.080]\n",
            "Saving..\n",
            "\n",
            "Epoch: 13\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 50s815ms | Loss: 0.773 | Acc: 80.508% (40254/50000) | Cls: 0.437  391/391 \n",
            "[2022-11-03 15:56:54,492] [train] [Epoch 13] [Loss 0.773] [cls 0.437] [Acc 80.508]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s591ms | Loss: 0.816 | Acc: 79.230% (7923/10000)  79/79 \n",
            "[2022-11-03 15:56:57,492] [val] [Epoch 13] [Loss 0.816] [Acc 79.230]\n",
            "\n",
            "Epoch: 14\n",
            " [=====================================================================================>]  Step: 127ms | Tot: 51s894ms | Loss: 0.781 | Acc: 80.230% (40115/50000) | Cls: 0.438  391/391 \n",
            "[2022-11-03 15:57:50,253] [train] [Epoch 14] [Loss 0.781] [cls 0.438] [Acc 80.230]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s741ms | Loss: 0.692 | Acc: 81.330% (8133/10000)  79/79 \n",
            "[2022-11-03 15:57:53,405] [val] [Epoch 14] [Loss 0.692] [Acc 81.330]\n",
            "Saving..\n",
            "\n",
            "Epoch: 15\n",
            " [=====================================================================================>]  Step: 129ms | Tot: 50s987ms | Loss: 0.739 | Acc: 81.356% (40678/50000) | Cls: 0.428  391/391 \n",
            "[2022-11-03 15:58:49,870] [train] [Epoch 15] [Loss 0.739] [cls 0.428] [Acc 81.356]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s564ms | Loss: 0.831 | Acc: 79.630% (7963/10000)  79/79 \n",
            "[2022-11-03 15:58:52,889] [val] [Epoch 15] [Loss 0.831] [Acc 79.630]\n",
            "\n",
            "Epoch: 16\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 51s174ms | Loss: 0.716 | Acc: 82.150% (41075/50000) | Cls: 0.424  391/391 \n",
            "[2022-11-03 15:59:44,850] [train] [Epoch 16] [Loss 0.716] [cls 0.424] [Acc 82.150]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s551ms | Loss: 0.847 | Acc: 78.260% (7826/10000)  79/79 \n",
            "[2022-11-03 15:59:47,856] [val] [Epoch 16] [Loss 0.847] [Acc 78.260]\n",
            "\n",
            "Epoch: 17\n",
            " [=====================================================================================>]  Step: 127ms | Tot: 51s230ms | Loss: 0.699 | Acc: 82.512% (41256/50000) | Cls: 0.431  391/391 \n",
            "[2022-11-03 16:00:39,780] [train] [Epoch 17] [Loss 0.699] [cls 0.431] [Acc 82.512]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s588ms | Loss: 0.723 | Acc: 82.450% (8245/10000)  79/79 \n",
            "[2022-11-03 16:00:42,781] [val] [Epoch 17] [Loss 0.723] [Acc 82.450]\n",
            "Saving..\n",
            "\n",
            "Epoch: 18\n",
            " [=====================================================================================>]  Step: 127ms | Tot: 51s92ms | Loss: 0.690 | Acc: 82.890% (41445/50000) | Cls: 0.428  391/391 \n",
            "[2022-11-03 16:01:39,345] [train] [Epoch 18] [Loss 0.690] [cls 0.428] [Acc 82.890]\n",
            " [====================================================================================>.]  Step: 10ms | Tot: 2s583ms | Loss: 0.795 | Acc: 81.170% (8117/10000)  79/79 \n",
            "[2022-11-03 16:01:42,340] [val] [Epoch 18] [Loss 0.795] [Acc 81.170]\n",
            "\n",
            "Epoch: 19\n",
            " [=====================================================================================>]  Step: 124ms | Tot: 51s195ms | Loss: 0.707 | Acc: 82.552% (41276/50000) | Cls: 0.434  391/391 \n",
            "[2022-11-03 16:02:34,227] [train] [Epoch 19] [Loss 0.707] [cls 0.434] [Acc 82.552]\n",
            " [====================================================================================>.]  Step: 10ms | Tot: 2s551ms | Loss: 0.740 | Acc: 81.800% (8180/10000)  79/79 \n",
            "[2022-11-03 16:02:37,248] [val] [Epoch 19] [Loss 0.740] [Acc 81.800]\n",
            "\n",
            "Epoch: 20\n",
            " [=====================================================================================>]  Step: 128ms | Tot: 51s125ms | Loss: 0.682 | Acc: 83.356% (41678/50000) | Cls: 0.426  391/391 \n",
            "[2022-11-03 16:03:29,209] [train] [Epoch 20] [Loss 0.682] [cls 0.426] [Acc 83.356]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 3s731ms | Loss: 0.685 | Acc: 81.800% (8180/10000)  79/79 \n",
            "[2022-11-03 16:03:33,596] [val] [Epoch 20] [Loss 0.685] [Acc 81.800]\n",
            "\n",
            "Epoch: 21\n",
            " [=====================================================================================>]  Step: 126ms | Tot: 51s76ms | Loss: 0.683 | Acc: 83.030% (41515/50000) | Cls: 0.430  391/391 \n",
            "[2022-11-03 16:04:25,753] [train] [Epoch 21] [Loss 0.683] [cls 0.430] [Acc 83.030]\n",
            " [====================================================================================>.]  Step: 10ms | Tot: 2s534ms | Loss: 0.840 | Acc: 78.290% (7829/10000)  79/79 \n",
            "[2022-11-03 16:04:28,740] [val] [Epoch 21] [Loss 0.840] [Acc 78.290]\n",
            "\n",
            "Epoch: 22\n",
            " [=====================================================================================>]  Step: 130ms | Tot: 51s90ms | Loss: 0.686 | Acc: 83.440% (41720/50000) | Cls: 0.431  391/391 \n",
            "[2022-11-03 16:05:20,638] [train] [Epoch 22] [Loss 0.686] [cls 0.431] [Acc 83.440]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s598ms | Loss: 0.750 | Acc: 82.670% (8267/10000)  79/79 \n",
            "[2022-11-03 16:05:23,636] [val] [Epoch 22] [Loss 0.750] [Acc 82.670]\n",
            "Saving..\n",
            "\n",
            "Epoch: 23\n",
            " [=====================================================================================>]  Step: 126ms | Tot: 51s91ms | Loss: 0.664 | Acc: 84.082% (42041/50000) | Cls: 0.429  391/391 \n",
            "[2022-11-03 16:06:20,247] [train] [Epoch 23] [Loss 0.664] [cls 0.429] [Acc 84.082]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s527ms | Loss: 0.804 | Acc: 78.810% (7881/10000)  79/79 \n",
            "[2022-11-03 16:06:23,242] [val] [Epoch 23] [Loss 0.804] [Acc 78.810]\n",
            "\n",
            "Epoch: 24\n",
            " [=====================================================================================>]  Step: 127ms | Tot: 51s79ms | Loss: 0.666 | Acc: 83.832% (41916/50000) | Cls: 0.428  391/391 \n",
            "[2022-11-03 16:07:15,088] [train] [Epoch 24] [Loss 0.666] [cls 0.428] [Acc 83.832]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s564ms | Loss: 0.917 | Acc: 75.980% (7598/10000)  79/79 \n",
            "[2022-11-03 16:07:18,049] [val] [Epoch 24] [Loss 0.917] [Acc 75.980]\n",
            "\n",
            "Epoch: 25\n",
            " [=====================================================================================>]  Step: 127ms | Tot: 51s194ms | Loss: 0.665 | Acc: 83.994% (41997/50000) | Cls: 0.427  391/391 \n",
            "[2022-11-03 16:08:10,019] [train] [Epoch 25] [Loss 0.665] [cls 0.427] [Acc 83.994]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s523ms | Loss: 0.718 | Acc: 83.330% (8333/10000)  79/79 \n",
            "[2022-11-03 16:08:12,987] [val] [Epoch 25] [Loss 0.718] [Acc 83.330]\n",
            "Saving..\n",
            "\n",
            "Epoch: 26\n",
            " [=====================================================================================>]  Step: 126ms | Tot: 51s81ms | Loss: 0.644 | Acc: 84.504% (42252/50000) | Cls: 0.423  391/391 \n",
            "[2022-11-03 16:09:09,639] [train] [Epoch 26] [Loss 0.644] [cls 0.423] [Acc 84.504]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s492ms | Loss: 0.739 | Acc: 82.630% (8263/10000)  79/79 \n",
            "[2022-11-03 16:09:12,649] [val] [Epoch 26] [Loss 0.739] [Acc 82.630]\n",
            "\n",
            "Epoch: 27\n",
            " [=====================================================================================>]  Step: 124ms | Tot: 51s592ms | Loss: 0.645 | Acc: 84.424% (42212/50000) | Cls: 0.429  391/391 \n",
            "[2022-11-03 16:10:05,061] [train] [Epoch 27] [Loss 0.645] [cls 0.429] [Acc 84.424]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s540ms | Loss: 0.795 | Acc: 80.700% (8070/10000)  79/79 \n",
            "[2022-11-03 16:10:08,076] [val] [Epoch 27] [Loss 0.795] [Acc 80.700]\n",
            "\n",
            "Epoch: 28\n",
            " [=====================================================================================>]  Step: 127ms | Tot: 51s228ms | Loss: 0.662 | Acc: 84.176% (42088/50000) | Cls: 0.425  391/391 \n",
            "[2022-11-03 16:11:00,120] [train] [Epoch 28] [Loss 0.662] [cls 0.425] [Acc 84.176]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s643ms | Loss: 0.817 | Acc: 80.530% (8053/10000)  79/79 \n",
            "[2022-11-03 16:11:03,172] [val] [Epoch 28] [Loss 0.817] [Acc 80.530]\n",
            "\n",
            "Epoch: 29\n",
            " [=====================================================================================>]  Step: 124ms | Tot: 51s123ms | Loss: 0.664 | Acc: 84.138% (42069/50000) | Cls: 0.431  391/391 \n",
            "[2022-11-03 16:11:55,072] [train] [Epoch 29] [Loss 0.664] [cls 0.431] [Acc 84.138]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s511ms | Loss: 0.825 | Acc: 81.360% (8136/10000)  79/79 \n",
            "[2022-11-03 16:11:58,050] [val] [Epoch 29] [Loss 0.825] [Acc 81.360]\n",
            "\n",
            "Epoch: 30\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 51s334ms | Loss: 0.675 | Acc: 84.074% (42037/50000) | Cls: 0.433  391/391 \n",
            "[2022-11-03 16:12:50,153] [train] [Epoch 30] [Loss 0.675] [cls 0.433] [Acc 84.074]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s528ms | Loss: 0.768 | Acc: 81.350% (8135/10000)  79/79 \n",
            "[2022-11-03 16:12:53,106] [val] [Epoch 30] [Loss 0.768] [Acc 81.350]\n",
            "\n",
            "Epoch: 31\n",
            " [=====================================================================================>]  Step: 126ms | Tot: 51s84ms | Loss: 0.647 | Acc: 84.578% (42289/50000) | Cls: 0.423  391/391 \n",
            "[2022-11-03 16:13:44,979] [train] [Epoch 31] [Loss 0.647] [cls 0.423] [Acc 84.578]\n",
            " [====================================================================================>.]  Step: 10ms | Tot: 2s541ms | Loss: 0.680 | Acc: 84.310% (8431/10000)  79/79 \n",
            "[2022-11-03 16:13:47,959] [val] [Epoch 31] [Loss 0.680] [Acc 84.310]\n",
            "Saving..\n",
            "\n",
            "Epoch: 32\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 51s137ms | Loss: 0.622 | Acc: 85.334% (42667/50000) | Cls: 0.428  391/391 \n",
            "[2022-11-03 16:14:44,649] [train] [Epoch 32] [Loss 0.622] [cls 0.428] [Acc 85.334]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s515ms | Loss: 0.698 | Acc: 83.160% (8316/10000)  79/79 \n",
            "[2022-11-03 16:14:47,611] [val] [Epoch 32] [Loss 0.698] [Acc 83.160]\n",
            "\n",
            "Epoch: 33\n",
            " [=====================================================================================>]  Step: 128ms | Tot: 51s32ms | Loss: 0.612 | Acc: 85.406% (42703/50000) | Cls: 0.420  391/391 \n",
            "[2022-11-03 16:15:39,421] [train] [Epoch 33] [Loss 0.612] [cls 0.420] [Acc 85.406]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s534ms | Loss: 0.662 | Acc: 83.870% (8387/10000)  79/79 \n",
            "[2022-11-03 16:15:42,415] [val] [Epoch 33] [Loss 0.662] [Acc 83.870]\n",
            "\n",
            "Epoch: 34\n",
            " [=====================================================================================>]  Step: 127ms | Tot: 51s689ms | Loss: 0.626 | Acc: 85.154% (42577/50000) | Cls: 0.421  391/391 \n",
            "[2022-11-03 16:16:34,868] [train] [Epoch 34] [Loss 0.626] [cls 0.421] [Acc 85.154]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s581ms | Loss: 0.673 | Acc: 84.010% (8401/10000)  79/79 \n",
            "[2022-11-03 16:16:37,847] [val] [Epoch 34] [Loss 0.673] [Acc 84.010]\n",
            "\n",
            "Epoch: 35\n",
            " [=====================================================================================>]  Step: 122ms | Tot: 51s358ms | Loss: 0.606 | Acc: 85.748% (42874/50000) | Cls: 0.418  391/391 \n",
            "[2022-11-03 16:17:29,945] [train] [Epoch 35] [Loss 0.606] [cls 0.418] [Acc 85.748]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s502ms | Loss: 0.676 | Acc: 84.530% (8453/10000)  79/79 \n",
            "[2022-11-03 16:17:32,925] [val] [Epoch 35] [Loss 0.676] [Acc 84.530]\n",
            "Saving..\n",
            "\n",
            "Epoch: 36\n",
            " [=====================================================================================>]  Step: 127ms | Tot: 51s129ms | Loss: 0.588 | Acc: 86.212% (43106/50000) | Cls: 0.407  391/391 \n",
            "[2022-11-03 16:18:29,645] [train] [Epoch 36] [Loss 0.588] [cls 0.407] [Acc 86.212]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s532ms | Loss: 0.717 | Acc: 81.520% (8152/10000)  79/79 \n",
            "[2022-11-03 16:18:32,663] [val] [Epoch 36] [Loss 0.717] [Acc 81.520]\n",
            "\n",
            "Epoch: 37\n",
            " [=====================================================================================>]  Step: 130ms | Tot: 51s181ms | Loss: 0.593 | Acc: 86.072% (43036/50000) | Cls: 0.414  391/391 \n",
            "[2022-11-03 16:19:24,620] [train] [Epoch 37] [Loss 0.593] [cls 0.414] [Acc 86.072]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s563ms | Loss: 0.667 | Acc: 83.760% (8376/10000)  79/79 \n",
            "[2022-11-03 16:19:27,599] [val] [Epoch 37] [Loss 0.667] [Acc 83.760]\n",
            "\n",
            "Epoch: 38\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 51s252ms | Loss: 0.609 | Acc: 85.752% (42876/50000) | Cls: 0.427  391/391 \n",
            "[2022-11-03 16:20:19,618] [train] [Epoch 38] [Loss 0.609] [cls 0.427] [Acc 85.752]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s505ms | Loss: 0.766 | Acc: 81.390% (8139/10000)  79/79 \n",
            "[2022-11-03 16:20:22,577] [val] [Epoch 38] [Loss 0.766] [Acc 81.390]\n",
            "\n",
            "Epoch: 39\n",
            " [=====================================================================================>]  Step: 128ms | Tot: 51s270ms | Loss: 0.606 | Acc: 85.876% (42938/50000) | Cls: 0.414  391/391 \n",
            "[2022-11-03 16:21:14,668] [train] [Epoch 39] [Loss 0.606] [cls 0.414] [Acc 85.876]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s638ms | Loss: 0.595 | Acc: 85.470% (8547/10000)  79/79 \n",
            "[2022-11-03 16:21:17,708] [val] [Epoch 39] [Loss 0.595] [Acc 85.470]\n",
            "Saving..\n",
            "\n",
            "Epoch: 40\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 51s437ms | Loss: 0.607 | Acc: 85.668% (42834/50000) | Cls: 0.422  391/391 \n",
            "[2022-11-03 16:22:14,657] [train] [Epoch 40] [Loss 0.607] [cls 0.422] [Acc 85.668]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s592ms | Loss: 0.776 | Acc: 80.720% (8072/10000)  79/79 \n",
            "[2022-11-03 16:22:17,670] [val] [Epoch 40] [Loss 0.776] [Acc 80.720]\n",
            "\n",
            "Epoch: 41\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 51s160ms | Loss: 0.598 | Acc: 86.040% (43020/50000) | Cls: 0.420  391/391 \n",
            "[2022-11-03 16:23:09,648] [train] [Epoch 41] [Loss 0.598] [cls 0.420] [Acc 86.040]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s588ms | Loss: 0.661 | Acc: 83.930% (8393/10000)  79/79 \n",
            "[2022-11-03 16:23:12,684] [val] [Epoch 41] [Loss 0.661] [Acc 83.930]\n",
            "\n",
            "Epoch: 42\n",
            " [=====================================================================================>]  Step: 127ms | Tot: 51s206ms | Loss: 0.611 | Acc: 85.922% (42961/50000) | Cls: 0.428  391/391 \n",
            "[2022-11-03 16:24:04,681] [train] [Epoch 42] [Loss 0.611] [cls 0.428] [Acc 85.922]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s603ms | Loss: 0.822 | Acc: 83.000% (8300/10000)  79/79 \n",
            "[2022-11-03 16:24:07,716] [val] [Epoch 42] [Loss 0.822] [Acc 83.000]\n",
            "\n",
            "Epoch: 43\n",
            " [=====================================================================================>]  Step: 126ms | Tot: 51s189ms | Loss: 0.595 | Acc: 86.208% (43104/50000) | Cls: 0.418  391/391 \n",
            "[2022-11-03 16:24:59,657] [train] [Epoch 43] [Loss 0.595] [cls 0.418] [Acc 86.208]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s525ms | Loss: 0.714 | Acc: 82.900% (8290/10000)  79/79 \n",
            "[2022-11-03 16:25:02,641] [val] [Epoch 43] [Loss 0.714] [Acc 82.900]\n",
            "\n",
            "Epoch: 44\n",
            "Traceback (most recent call last):\n",
            "  File \"Learning-With-Retrospection/CS-KD_techinque/cs-kd/train.py\", line 229, in <module>\n",
            "    train_loss, train_acc, train_cls_loss = train(epoch)\n",
            "  File \"Learning-With-Retrospection/CS-KD_techinque/cs-kd/train.py\", line 140, in train\n",
            "    train_cls_loss += cls_loss.item()\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!python Learning-With-Retrospection/CS-KD_techinque/cs-kd/train.py --sgpu 0 --lr 0.1 --epoch 200 --model CIFAR10_VGG16 --name cifar10_vgg16 --decay 1e-4 --dataset cifar10 --dataroot ~/data/ -cls --lamda 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCZKwgtUbZS9",
        "outputId": "66c74fba-e244-42f3-fa8f-b452ff39887e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==> Preparing dataset: cifar10\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /root/data/cifar-10-python.tar.gz\n",
            "100% 170498071/170498071 [00:13<00:00, 12397138.09it/s]\n",
            "Extracting /root/data/cifar-10-python.tar.gz to /root/data/\n",
            "Files already downloaded and verified\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Number of train dataset:  50000\n",
            "Number of validation dataset:  10000\n",
            "==> Building model: CIFAR10_VGG16\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\" to /root/.cache/torch/hub/checkpoints/vgg16_bn-6c64b313.pth\n",
            "100% 528M/528M [00:06<00:00, 83.9MB/s]\n",
            "1\n",
            "Using CUDA..\n",
            "\"./results/cifar10/CIFAR10_VGG16/cifar10_vgg16\" exists. Overwrite [Y/n]? Y\n",
            "[2022-11-03 16:59:25,570] [main] Learning-With-Retrospection/CS-KD_techinque/cs-kd/train.py --resume --sgpu 0 --lr 0.1 --epoch 200 --model CIFAR10_VGG16 --name cifar10_vgg16 --decay 1e-4 --dataset cifar10 --dataroot /root/data/ -cls --lamda 1\n",
            "[2022-11-03 16:59:25,571] [main] Namespace(batch_size=128, cls=True, dataroot='/root/data/', dataset='cifar10', decay=0.0001, epoch=200, lamda=1.0, lr=0.1, model='CIFAR10_VGG16', name='cifar10_vgg16', ngpu=1, resume=True, saveroot='./results', sgpu=0, temp=4.0)\n",
            "==> Resuming from checkpoint..\n",
            "\n",
            "Epoch: 40\n",
            " [=====================================================================================>]  Step: 809ms | Tot: 50s814ms | Loss: 0.608 | Acc: 85.586% (42793/50000) | Cls: 0.422  391/391 \n",
            "[2022-11-03 17:00:27,543] [train] [Epoch 40] [Loss 0.608] [cls 0.422] [Acc 85.586]\n",
            " [====================================================================================>.]  Step: 120ms | Tot: 2s626ms | Loss: 0.670 | Acc: 84.120% (8412/10000)  79/79 \n",
            "[2022-11-03 17:00:30,565] [val] [Epoch 40] [Loss 0.670] [Acc 84.120]\n",
            "Saving..\n",
            "\n",
            "Epoch: 41\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 51s468ms | Loss: 0.603 | Acc: 85.946% (42973/50000) | Cls: 0.419  391/391 \n",
            "[2022-11-03 17:01:27,358] [train] [Epoch 41] [Loss 0.603] [cls 0.419] [Acc 85.946]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s588ms | Loss: 0.733 | Acc: 82.280% (8228/10000)  79/79 \n",
            "[2022-11-03 17:01:30,378] [val] [Epoch 41] [Loss 0.733] [Acc 82.280]\n",
            "\n",
            "Epoch: 42\n",
            " [=====================================================================================>]  Step: 128ms | Tot: 51s310ms | Loss: 0.596 | Acc: 86.062% (43031/50000) | Cls: 0.422  391/391 \n",
            "[2022-11-03 17:02:22,477] [train] [Epoch 42] [Loss 0.596] [cls 0.422] [Acc 86.062]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s617ms | Loss: 0.673 | Acc: 84.250% (8425/10000)  79/79 \n",
            "[2022-11-03 17:02:25,506] [val] [Epoch 42] [Loss 0.673] [Acc 84.250]\n",
            "Saving..\n",
            "\n",
            "Epoch: 43\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 51s391ms | Loss: 0.605 | Acc: 85.800% (42900/50000) | Cls: 0.422  391/391 \n",
            "[2022-11-03 17:03:22,205] [train] [Epoch 43] [Loss 0.605] [cls 0.422] [Acc 85.800]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s630ms | Loss: 0.683 | Acc: 84.520% (8452/10000)  79/79 \n",
            "[2022-11-03 17:03:25,228] [val] [Epoch 43] [Loss 0.683] [Acc 84.520]\n",
            "Saving..\n",
            "\n",
            "Epoch: 44\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 51s313ms | Loss: 0.611 | Acc: 85.860% (42930/50000) | Cls: 0.426  391/391 \n",
            "[2022-11-03 17:04:21,945] [train] [Epoch 44] [Loss 0.611] [cls 0.426] [Acc 85.860]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s546ms | Loss: 0.834 | Acc: 82.020% (8202/10000)  79/79 \n",
            "[2022-11-03 17:04:24,973] [val] [Epoch 44] [Loss 0.834] [Acc 82.020]\n",
            "\n",
            "Epoch: 45\n",
            " [=====================================================================================>]  Step: 126ms | Tot: 52s321ms | Loss: 0.604 | Acc: 85.986% (42993/50000) | Cls: 0.419  391/391 \n",
            "[2022-11-03 17:05:18,133] [train] [Epoch 45] [Loss 0.604] [cls 0.419] [Acc 85.986]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 3s903ms | Loss: 0.667 | Acc: 83.350% (8335/10000)  79/79 \n",
            "[2022-11-03 17:05:22,828] [val] [Epoch 45] [Loss 0.667] [Acc 83.350]\n",
            "\n",
            "Epoch: 46\n",
            " [=====================================================================================>]  Step: 124ms | Tot: 51s191ms | Loss: 0.599 | Acc: 86.092% (43046/50000) | Cls: 0.423  391/391 \n",
            "[2022-11-03 17:06:14,741] [train] [Epoch 46] [Loss 0.599] [cls 0.423] [Acc 86.092]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s498ms | Loss: 0.697 | Acc: 84.080% (8408/10000)  79/79 \n",
            "[2022-11-03 17:06:17,669] [val] [Epoch 46] [Loss 0.697] [Acc 84.080]\n",
            "\n",
            "Epoch: 47\n",
            " [=====================================================================================>]  Step: 124ms | Tot: 51s291ms | Loss: 0.599 | Acc: 86.212% (43106/50000) | Cls: 0.421  391/391 \n",
            "[2022-11-03 17:07:09,639] [train] [Epoch 47] [Loss 0.599] [cls 0.421] [Acc 86.212]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s544ms | Loss: 0.671 | Acc: 84.970% (8497/10000)  79/79 \n",
            "[2022-11-03 17:07:12,597] [val] [Epoch 47] [Loss 0.671] [Acc 84.970]\n",
            "Saving..\n",
            "\n",
            "Epoch: 48\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 51s368ms | Loss: 0.626 | Acc: 85.652% (42826/50000) | Cls: 0.433  391/391 \n",
            "[2022-11-03 17:08:09,113] [train] [Epoch 48] [Loss 0.626] [cls 0.433] [Acc 85.652]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s539ms | Loss: 0.793 | Acc: 81.140% (8114/10000)  79/79 \n",
            "[2022-11-03 17:08:12,057] [val] [Epoch 48] [Loss 0.793] [Acc 81.140]\n",
            "\n",
            "Epoch: 49\n",
            " [=====================================================================================>]  Step: 124ms | Tot: 51s127ms | Loss: 0.624 | Acc: 85.760% (42880/50000) | Cls: 0.431  391/391 \n",
            "[2022-11-03 17:09:03,919] [train] [Epoch 49] [Loss 0.624] [cls 0.431] [Acc 85.760]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s459ms | Loss: 0.824 | Acc: 80.370% (8037/10000)  79/79 \n",
            "[2022-11-03 17:09:06,851] [val] [Epoch 49] [Loss 0.824] [Acc 80.370]\n",
            "\n",
            "Epoch: 50\n",
            " [=====================================================================================>]  Step: 129ms | Tot: 51s752ms | Loss: 0.635 | Acc: 85.486% (42743/50000) | Cls: 0.434  391/391 \n",
            "[2022-11-03 17:09:59,395] [train] [Epoch 50] [Loss 0.635] [cls 0.434] [Acc 85.486]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s542ms | Loss: 0.756 | Acc: 82.470% (8247/10000)  79/79 \n",
            "[2022-11-03 17:10:02,391] [val] [Epoch 50] [Loss 0.756] [Acc 82.470]\n",
            "\n",
            "Epoch: 51\n",
            " [=====================================================================================>]  Step: 128ms | Tot: 51s73ms | Loss: 0.646 | Acc: 85.234% (42617/50000) | Cls: 0.439  391/391 \n",
            "[2022-11-03 17:10:54,245] [train] [Epoch 51] [Loss 0.646] [cls 0.439] [Acc 85.234]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s534ms | Loss: 0.818 | Acc: 80.730% (8073/10000)  79/79 \n",
            "[2022-11-03 17:10:57,227] [val] [Epoch 51] [Loss 0.818] [Acc 80.730]\n",
            "\n",
            "Epoch: 52\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 52s502ms | Loss: 0.650 | Acc: 85.160% (42580/50000) | Cls: 0.435  391/391 \n",
            "[2022-11-03 17:11:50,421] [train] [Epoch 52] [Loss 0.650] [cls 0.435] [Acc 85.160]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s509ms | Loss: 0.818 | Acc: 82.030% (8203/10000)  79/79 \n",
            "[2022-11-03 17:11:53,395] [val] [Epoch 52] [Loss 0.818] [Acc 82.030]\n",
            "\n",
            "Epoch: 53\n",
            " [=====================================================================================>]  Step: 128ms | Tot: 51s285ms | Loss: 0.632 | Acc: 85.524% (42762/50000) | Cls: 0.433  391/391 \n",
            "[2022-11-03 17:12:45,380] [train] [Epoch 53] [Loss 0.632] [cls 0.433] [Acc 85.524]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s567ms | Loss: 0.814 | Acc: 80.810% (8081/10000)  79/79 \n",
            "[2022-11-03 17:12:48,344] [val] [Epoch 53] [Loss 0.814] [Acc 80.810]\n",
            "\n",
            "Epoch: 54\n",
            " [=====================================================================================>]  Step: 126ms | Tot: 51s831ms | Loss: 0.671 | Acc: 84.772% (42386/50000) | Cls: 0.441  391/391 \n",
            "[2022-11-03 17:13:40,939] [train] [Epoch 54] [Loss 0.671] [cls 0.441] [Acc 84.772]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s555ms | Loss: 0.741 | Acc: 82.500% (8250/10000)  79/79 \n",
            "[2022-11-03 17:13:43,944] [val] [Epoch 54] [Loss 0.741] [Acc 82.500]\n",
            "\n",
            "Epoch: 55\n",
            " [=====================================================================================>]  Step: 127ms | Tot: 51s256ms | Loss: 0.628 | Acc: 85.554% (42777/50000) | Cls: 0.432  391/391 \n",
            "[2022-11-03 17:14:35,911] [train] [Epoch 55] [Loss 0.628] [cls 0.432] [Acc 85.554]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s626ms | Loss: 0.775 | Acc: 82.920% (8292/10000)  79/79 \n",
            "[2022-11-03 17:14:38,943] [val] [Epoch 55] [Loss 0.775] [Acc 82.920]\n",
            "\n",
            "Epoch: 56\n",
            " [=====================================================================================>]  Step: 126ms | Tot: 51s393ms | Loss: 0.669 | Acc: 84.558% (42279/50000) | Cls: 0.443  391/391 \n",
            "[2022-11-03 17:15:30,937] [train] [Epoch 56] [Loss 0.669] [cls 0.443] [Acc 84.558]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s539ms | Loss: 0.735 | Acc: 83.100% (8310/10000)  79/79 \n",
            "[2022-11-03 17:15:33,893] [val] [Epoch 56] [Loss 0.735] [Acc 83.100]\n",
            "\n",
            "Epoch: 57\n",
            " [=====================================================================================>]  Step: 128ms | Tot: 51s289ms | Loss: 0.604 | Acc: 86.148% (43074/50000) | Cls: 0.422  391/391 \n",
            "[2022-11-03 17:16:25,859] [train] [Epoch 57] [Loss 0.604] [cls 0.422] [Acc 86.148]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s520ms | Loss: 0.733 | Acc: 84.320% (8432/10000)  79/79 \n",
            "[2022-11-03 17:16:28,785] [val] [Epoch 57] [Loss 0.733] [Acc 84.320]\n",
            "\n",
            "Epoch: 58\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 52s458ms | Loss: 0.599 | Acc: 86.320% (43160/50000) | Cls: 0.427  391/391 \n",
            "[2022-11-03 17:17:22,008] [train] [Epoch 58] [Loss 0.599] [cls 0.427] [Acc 86.320]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s716ms | Loss: 0.703 | Acc: 83.260% (8326/10000)  79/79 \n",
            "[2022-11-03 17:17:25,195] [val] [Epoch 58] [Loss 0.703] [Acc 83.260]\n",
            "\n",
            "Epoch: 59\n",
            " [=====================================================================================>]  Step: 124ms | Tot: 51s541ms | Loss: 0.572 | Acc: 87.030% (43515/50000) | Cls: 0.416  391/391 \n",
            "[2022-11-03 17:18:17,884] [train] [Epoch 59] [Loss 0.572] [cls 0.416] [Acc 87.030]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s515ms | Loss: 0.672 | Acc: 84.390% (8439/10000)  79/79 \n",
            "[2022-11-03 17:18:20,807] [val] [Epoch 59] [Loss 0.672] [Acc 84.390]\n",
            "\n",
            "Epoch: 60\n",
            " [=====================================================================================>]  Step: 124ms | Tot: 51s407ms | Loss: 0.557 | Acc: 87.194% (43597/50000) | Cls: 0.410  391/391 \n",
            "[2022-11-03 17:19:12,939] [train] [Epoch 60] [Loss 0.557] [cls 0.410] [Acc 87.194]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s519ms | Loss: 0.670 | Acc: 83.560% (8356/10000)  79/79 \n",
            "[2022-11-03 17:19:15,870] [val] [Epoch 60] [Loss 0.670] [Acc 83.560]\n",
            "\n",
            "Epoch: 61\n",
            " [=====================================================================================>]  Step: 129ms | Tot: 51s367ms | Loss: 0.550 | Acc: 87.412% (43706/50000) | Cls: 0.407  391/391 \n",
            "[2022-11-03 17:20:07,985] [train] [Epoch 61] [Loss 0.550] [cls 0.407] [Acc 87.412]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s490ms | Loss: 0.596 | Acc: 85.270% (8527/10000)  79/79 \n",
            "[2022-11-03 17:20:10,913] [val] [Epoch 61] [Loss 0.596] [Acc 85.270]\n",
            "Saving..\n",
            "\n",
            "Epoch: 62\n",
            " [=====================================================================================>]  Step: 124ms | Tot: 51s335ms | Loss: 0.532 | Acc: 87.672% (43836/50000) | Cls: 0.407  391/391 \n",
            "[2022-11-03 17:21:07,417] [train] [Epoch 62] [Loss 0.532] [cls 0.407] [Acc 87.672]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s456ms | Loss: 0.569 | Acc: 86.830% (8683/10000)  79/79 \n",
            "[2022-11-03 17:21:10,353] [val] [Epoch 62] [Loss 0.569] [Acc 86.830]\n",
            "Saving..\n",
            "\n",
            "Epoch: 63\n",
            " [=====================================================================================>]  Step: 128ms | Tot: 51s420ms | Loss: 0.541 | Acc: 87.674% (43837/50000) | Cls: 0.405  391/391 \n",
            "[2022-11-03 17:22:07,015] [train] [Epoch 63] [Loss 0.541] [cls 0.405] [Acc 87.674]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s589ms | Loss: 0.643 | Acc: 85.130% (8513/10000)  79/79 \n",
            "[2022-11-03 17:22:09,982] [val] [Epoch 63] [Loss 0.643] [Acc 85.130]\n",
            "\n",
            "Epoch: 64\n",
            " [=====================================================================================>]  Step: 123ms | Tot: 51s225ms | Loss: 0.575 | Acc: 86.908% (43454/50000) | Cls: 0.428  391/391 \n",
            "[2022-11-03 17:23:01,937] [train] [Epoch 64] [Loss 0.575] [cls 0.428] [Acc 86.908]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s515ms | Loss: 0.649 | Acc: 83.300% (8330/10000)  79/79 \n",
            "[2022-11-03 17:23:04,927] [val] [Epoch 64] [Loss 0.649] [Acc 83.300]\n",
            "\n",
            "Epoch: 65\n",
            " [=====================================================================================>]  Step: 126ms | Tot: 51s443ms | Loss: 0.568 | Acc: 86.892% (43446/50000) | Cls: 0.413  391/391 \n",
            "[2022-11-03 17:23:57,102] [train] [Epoch 65] [Loss 0.568] [cls 0.413] [Acc 86.892]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s578ms | Loss: 0.628 | Acc: 85.480% (8548/10000)  79/79 \n",
            "[2022-11-03 17:24:00,075] [val] [Epoch 65] [Loss 0.628] [Acc 85.480]\n",
            "\n",
            "Epoch: 66\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 53s501ms | Loss: 0.553 | Acc: 87.192% (43596/50000) | Cls: 0.409  391/391 \n",
            "[2022-11-03 17:24:54,339] [train] [Epoch 66] [Loss 0.553] [cls 0.409] [Acc 87.192]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s480ms | Loss: 0.706 | Acc: 83.600% (8360/10000)  79/79 \n",
            "[2022-11-03 17:24:57,230] [val] [Epoch 66] [Loss 0.706] [Acc 83.600]\n",
            "\n",
            "Epoch: 67\n",
            " [=====================================================================================>]  Step: 127ms | Tot: 51s308ms | Loss: 0.572 | Acc: 86.960% (43480/50000) | Cls: 0.414  391/391 \n",
            "[2022-11-03 17:25:49,269] [train] [Epoch 67] [Loss 0.572] [cls 0.414] [Acc 86.960]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s497ms | Loss: 0.604 | Acc: 86.300% (8630/10000)  79/79 \n",
            "[2022-11-03 17:25:52,217] [val] [Epoch 67] [Loss 0.604] [Acc 86.300]\n",
            "\n",
            "Epoch: 68\n",
            " [=====================================================================================>]  Step: 124ms | Tot: 51s329ms | Loss: 0.547 | Acc: 87.548% (43774/50000) | Cls: 0.404  391/391 \n",
            "[2022-11-03 17:26:44,259] [train] [Epoch 68] [Loss 0.547] [cls 0.404] [Acc 87.548]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s510ms | Loss: 0.587 | Acc: 85.350% (8535/10000)  79/79 \n",
            "[2022-11-03 17:26:47,180] [val] [Epoch 68] [Loss 0.587] [Acc 85.350]\n",
            "\n",
            "Epoch: 69\n",
            " [=====================================================================================>]  Step: 128ms | Tot: 51s301ms | Loss: 0.535 | Acc: 87.646% (43823/50000) | Cls: 0.397  391/391 \n",
            "[2022-11-03 17:27:39,256] [train] [Epoch 69] [Loss 0.535] [cls 0.397] [Acc 87.646]\n",
            " [====================================================================================>.]  Step: 10ms | Tot: 2s525ms | Loss: 0.638 | Acc: 84.800% (8480/10000)  79/79 \n",
            "[2022-11-03 17:27:42,167] [val] [Epoch 69] [Loss 0.638] [Acc 84.800]\n",
            "\n",
            "Epoch: 70\n",
            " [=====================================================================================>]  Step: 127ms | Tot: 51s332ms | Loss: 0.570 | Acc: 86.908% (43454/50000) | Cls: 0.413  391/391 \n",
            "[2022-11-03 17:28:34,231] [train] [Epoch 70] [Loss 0.570] [cls 0.413] [Acc 86.908]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s543ms | Loss: 0.645 | Acc: 84.160% (8416/10000)  79/79 \n",
            "[2022-11-03 17:28:37,201] [val] [Epoch 70] [Loss 0.645] [Acc 84.160]\n",
            "\n",
            "Epoch: 71\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 51s410ms | Loss: 0.557 | Acc: 87.274% (43637/50000) | Cls: 0.415  391/391 \n",
            "[2022-11-03 17:29:29,345] [train] [Epoch 71] [Loss 0.557] [cls 0.415] [Acc 87.274]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s529ms | Loss: 0.615 | Acc: 85.660% (8566/10000)  79/79 \n",
            "[2022-11-03 17:29:32,267] [val] [Epoch 71] [Loss 0.615] [Acc 85.660]\n",
            "\n",
            "Epoch: 72\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 51s243ms | Loss: 0.551 | Acc: 87.526% (43763/50000) | Cls: 0.412  391/391 \n",
            "[2022-11-03 17:30:24,235] [train] [Epoch 72] [Loss 0.551] [cls 0.412] [Acc 87.526]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s437ms | Loss: 0.672 | Acc: 83.160% (8316/10000)  79/79 \n",
            "[2022-11-03 17:30:27,093] [val] [Epoch 72] [Loss 0.672] [Acc 83.160]\n",
            "\n",
            "Epoch: 73\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 51s397ms | Loss: 0.587 | Acc: 86.394% (43197/50000) | Cls: 0.421  391/391 \n",
            "[2022-11-03 17:31:19,211] [train] [Epoch 73] [Loss 0.587] [cls 0.421] [Acc 86.394]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s438ms | Loss: 0.676 | Acc: 84.930% (8493/10000)  79/79 \n",
            "[2022-11-03 17:31:22,135] [val] [Epoch 73] [Loss 0.676] [Acc 84.930]\n",
            "\n",
            "Epoch: 74\n",
            " [=====================================================================================>]  Step: 128ms | Tot: 53s307ms | Loss: 0.591 | Acc: 86.600% (43300/50000) | Cls: 0.415  391/391 \n",
            "[2022-11-03 17:32:16,127] [train] [Epoch 74] [Loss 0.591] [cls 0.415] [Acc 86.600]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s502ms | Loss: 0.700 | Acc: 82.050% (8205/10000)  79/79 \n",
            "[2022-11-03 17:32:19,041] [val] [Epoch 74] [Loss 0.700] [Acc 82.050]\n",
            "\n",
            "Epoch: 75\n",
            " [=====================================================================================>]  Step: 123ms | Tot: 51s217ms | Loss: 0.539 | Acc: 87.714% (43857/50000) | Cls: 0.403  391/391 \n",
            "[2022-11-03 17:33:11,045] [train] [Epoch 75] [Loss 0.539] [cls 0.403] [Acc 87.714]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s545ms | Loss: 0.611 | Acc: 85.660% (8566/10000)  79/79 \n",
            "[2022-11-03 17:33:14,030] [val] [Epoch 75] [Loss 0.611] [Acc 85.660]\n",
            "\n",
            "Epoch: 76\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 51s170ms | Loss: 0.554 | Acc: 87.234% (43617/50000) | Cls: 0.409  391/391 \n",
            "[2022-11-03 17:34:05,963] [train] [Epoch 76] [Loss 0.554] [cls 0.409] [Acc 87.234]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s453ms | Loss: 0.644 | Acc: 83.890% (8389/10000)  79/79 \n",
            "[2022-11-03 17:34:08,909] [val] [Epoch 76] [Loss 0.644] [Acc 83.890]\n",
            "\n",
            "Epoch: 77\n",
            " [=====================================================================================>]  Step: 128ms | Tot: 51s253ms | Loss: 0.540 | Acc: 87.608% (43804/50000) | Cls: 0.407  391/391 \n",
            "[2022-11-03 17:35:00,867] [train] [Epoch 77] [Loss 0.540] [cls 0.407] [Acc 87.608]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s526ms | Loss: 0.579 | Acc: 85.970% (8597/10000)  79/79 \n",
            "[2022-11-03 17:35:03,804] [val] [Epoch 77] [Loss 0.579] [Acc 85.970]\n",
            "\n",
            "Epoch: 78\n",
            " [=====================================================================================>]  Step: 123ms | Tot: 51s287ms | Loss: 0.549 | Acc: 87.392% (43696/50000) | Cls: 0.405  391/391 \n",
            "[2022-11-03 17:35:55,867] [train] [Epoch 78] [Loss 0.549] [cls 0.405] [Acc 87.392]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s458ms | Loss: 0.689 | Acc: 83.020% (8302/10000)  79/79 \n",
            "[2022-11-03 17:35:58,750] [val] [Epoch 78] [Loss 0.689] [Acc 83.020]\n",
            "\n",
            "Epoch: 79\n",
            " [=====================================================================================>]  Step: 128ms | Tot: 51s673ms | Loss: 0.547 | Acc: 87.652% (43826/50000) | Cls: 0.401  391/391 \n",
            "[2022-11-03 17:36:51,227] [train] [Epoch 79] [Loss 0.547] [cls 0.401] [Acc 87.652]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s494ms | Loss: 0.570 | Acc: 86.270% (8627/10000)  79/79 \n",
            "[2022-11-03 17:36:54,134] [val] [Epoch 79] [Loss 0.570] [Acc 86.270]\n",
            "\n",
            "Epoch: 80\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 51s654ms | Loss: 0.538 | Acc: 87.740% (43870/50000) | Cls: 0.402  391/391 \n",
            "[2022-11-03 17:37:46,685] [train] [Epoch 80] [Loss 0.538] [cls 0.402] [Acc 87.740]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 3s486ms | Loss: 0.588 | Acc: 86.190% (8619/10000)  79/79 \n",
            "[2022-11-03 17:37:50,799] [val] [Epoch 80] [Loss 0.588] [Acc 86.190]\n",
            "\n",
            "Epoch: 81\n",
            " [=====================================================================================>]  Step: 127ms | Tot: 51s272ms | Loss: 0.542 | Acc: 87.604% (43802/50000) | Cls: 0.406  391/391 \n",
            "[2022-11-03 17:38:42,735] [train] [Epoch 81] [Loss 0.542] [cls 0.406] [Acc 87.604]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s510ms | Loss: 0.641 | Acc: 85.390% (8539/10000)  79/79 \n",
            "[2022-11-03 17:38:45,620] [val] [Epoch 81] [Loss 0.641] [Acc 85.390]\n",
            "\n",
            "Epoch: 82\n",
            " [=====================================================================================>]  Step: 127ms | Tot: 51s265ms | Loss: 0.549 | Acc: 87.472% (43736/50000) | Cls: 0.414  391/391 \n",
            "[2022-11-03 17:39:37,653] [train] [Epoch 82] [Loss 0.549] [cls 0.414] [Acc 87.472]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s496ms | Loss: 0.599 | Acc: 85.710% (8571/10000)  79/79 \n",
            "[2022-11-03 17:39:40,546] [val] [Epoch 82] [Loss 0.599] [Acc 85.710]\n",
            "\n",
            "Epoch: 83\n",
            " [=====================================================================================>]  Step: 128ms | Tot: 51s778ms | Loss: 0.617 | Acc: 85.370% (42685/50000) | Cls: 0.429  391/391 \n",
            "[2022-11-03 17:40:33,087] [train] [Epoch 83] [Loss 0.617] [cls 0.429] [Acc 85.370]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s511ms | Loss: 0.696 | Acc: 83.760% (8376/10000)  79/79 \n",
            "[2022-11-03 17:40:36,002] [val] [Epoch 83] [Loss 0.696] [Acc 83.760]\n",
            "\n",
            "Epoch: 84\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 51s296ms | Loss: 0.580 | Acc: 86.796% (43398/50000) | Cls: 0.414  391/391 \n",
            "[2022-11-03 17:41:27,939] [train] [Epoch 84] [Loss 0.580] [cls 0.414] [Acc 86.796]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s488ms | Loss: 0.657 | Acc: 84.890% (8489/10000)  79/79 \n",
            "[2022-11-03 17:41:30,848] [val] [Epoch 84] [Loss 0.657] [Acc 84.890]\n",
            "\n",
            "Epoch: 85\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 51s236ms | Loss: 0.575 | Acc: 86.934% (43467/50000) | Cls: 0.410  391/391 \n",
            "[2022-11-03 17:42:22,870] [train] [Epoch 85] [Loss 0.575] [cls 0.410] [Acc 86.934]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s500ms | Loss: 0.563 | Acc: 86.990% (8699/10000)  79/79 \n",
            "[2022-11-03 17:42:25,819] [val] [Epoch 85] [Loss 0.563] [Acc 86.990]\n",
            "Saving..\n",
            "\n",
            "Epoch: 86\n",
            " [=====================================================================================>]  Step: 131ms | Tot: 52s431ms | Loss: 0.541 | Acc: 87.522% (43761/50000) | Cls: 0.405  391/391 \n",
            "[2022-11-03 17:43:23,494] [train] [Epoch 86] [Loss 0.541] [cls 0.405] [Acc 87.522]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s541ms | Loss: 0.698 | Acc: 84.040% (8404/10000)  79/79 \n",
            "[2022-11-03 17:43:26,429] [val] [Epoch 86] [Loss 0.698] [Acc 84.040]\n",
            "\n",
            "Epoch: 87\n",
            " [=====================================================================================>]  Step: 129ms | Tot: 52s326ms | Loss: 0.555 | Acc: 87.302% (43651/50000) | Cls: 0.408  391/391 \n",
            "[2022-11-03 17:44:19,320] [train] [Epoch 87] [Loss 0.555] [cls 0.408] [Acc 87.302]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s504ms | Loss: 0.668 | Acc: 84.070% (8407/10000)  79/79 \n",
            "[2022-11-03 17:44:22,217] [val] [Epoch 87] [Loss 0.668] [Acc 84.070]\n",
            "\n",
            "Epoch: 88\n",
            " [=====================================================================================>]  Step: 126ms | Tot: 51s264ms | Loss: 0.571 | Acc: 86.974% (43487/50000) | Cls: 0.411  391/391 \n",
            "[2022-11-03 17:45:14,272] [train] [Epoch 88] [Loss 0.571] [cls 0.411] [Acc 86.974]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s571ms | Loss: 0.629 | Acc: 84.700% (8470/10000)  79/79 \n",
            "[2022-11-03 17:45:17,231] [val] [Epoch 88] [Loss 0.629] [Acc 84.700]\n",
            "\n",
            "Epoch: 89\n",
            " [=====================================================================================>]  Step: 128ms | Tot: 51s207ms | Loss: 0.531 | Acc: 87.798% (43899/50000) | Cls: 0.404  391/391 \n",
            "[2022-11-03 17:46:09,170] [train] [Epoch 89] [Loss 0.531] [cls 0.404] [Acc 87.798]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s505ms | Loss: 0.614 | Acc: 85.000% (8500/10000)  79/79 \n",
            "[2022-11-03 17:46:12,054] [val] [Epoch 89] [Loss 0.614] [Acc 85.000]\n",
            "\n",
            "Epoch: 90\n",
            " [=====================================================================================>]  Step: 129ms | Tot: 51s224ms | Loss: 0.587 | Acc: 86.448% (43224/50000) | Cls: 0.421  391/391 \n",
            "[2022-11-03 17:47:04,044] [train] [Epoch 90] [Loss 0.587] [cls 0.421] [Acc 86.448]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s441ms | Loss: 0.717 | Acc: 81.840% (8184/10000)  79/79 \n",
            "[2022-11-03 17:47:06,936] [val] [Epoch 90] [Loss 0.717] [Acc 81.840]\n",
            "\n",
            "Epoch: 91\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 51s817ms | Loss: 0.568 | Acc: 87.142% (43571/50000) | Cls: 0.415  391/391 \n",
            "[2022-11-03 17:47:59,386] [train] [Epoch 91] [Loss 0.568] [cls 0.415] [Acc 87.142]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s476ms | Loss: 0.700 | Acc: 83.500% (8350/10000)  79/79 \n",
            "[2022-11-03 17:48:02,256] [val] [Epoch 91] [Loss 0.700] [Acc 83.500]\n",
            "\n",
            "Epoch: 92\n",
            " [=====================================================================================>]  Step: 128ms | Tot: 51s574ms | Loss: 0.553 | Acc: 87.428% (43714/50000) | Cls: 0.409  391/391 \n",
            "[2022-11-03 17:48:54,575] [train] [Epoch 92] [Loss 0.553] [cls 0.409] [Acc 87.428]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 3s95ms | Loss: 0.664 | Acc: 83.560% (8356/10000)  79/79 \n",
            "[2022-11-03 17:48:58,194] [val] [Epoch 92] [Loss 0.664] [Acc 83.560]\n",
            "\n",
            "Epoch: 93\n",
            " [=====================================================================================>]  Step: 127ms | Tot: 51s966ms | Loss: 0.543 | Acc: 87.512% (43756/50000) | Cls: 0.405  391/391 \n",
            "[2022-11-03 17:49:51,339] [train] [Epoch 93] [Loss 0.543] [cls 0.405] [Acc 87.512]\n",
            " [====================================================================================>.]  Step: 10ms | Tot: 2s537ms | Loss: 0.586 | Acc: 85.950% (8595/10000)  79/79 \n",
            "[2022-11-03 17:49:54,257] [val] [Epoch 93] [Loss 0.586] [Acc 85.950]\n",
            "\n",
            "Epoch: 94\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 51s236ms | Loss: 0.554 | Acc: 87.438% (43719/50000) | Cls: 0.411  391/391 \n",
            "[2022-11-03 17:50:46,216] [train] [Epoch 94] [Loss 0.554] [cls 0.411] [Acc 87.438]\n",
            " [====================================================================================>.]  Step: 10ms | Tot: 2s451ms | Loss: 0.622 | Acc: 86.120% (8612/10000)  79/79 \n",
            "[2022-11-03 17:50:49,115] [val] [Epoch 94] [Loss 0.622] [Acc 86.120]\n",
            "\n",
            "Epoch: 95\n",
            " [=====================================================================================>]  Step: 126ms | Tot: 51s606ms | Loss: 0.534 | Acc: 87.892% (43946/50000) | Cls: 0.400  391/391 \n",
            "[2022-11-03 17:51:41,448] [train] [Epoch 95] [Loss 0.534] [cls 0.400] [Acc 87.892]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s479ms | Loss: 0.601 | Acc: 85.110% (8511/10000)  79/79 \n",
            "[2022-11-03 17:51:44,310] [val] [Epoch 95] [Loss 0.601] [Acc 85.110]\n",
            "\n",
            "Epoch: 96\n",
            " [=====================================================================================>]  Step: 123ms | Tot: 51s581ms | Loss: 0.583 | Acc: 86.856% (43428/50000) | Cls: 0.418  391/391 \n",
            "[2022-11-03 17:52:36,653] [train] [Epoch 96] [Loss 0.583] [cls 0.418] [Acc 86.856]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s500ms | Loss: 0.672 | Acc: 83.600% (8360/10000)  79/79 \n",
            "[2022-11-03 17:52:39,592] [val] [Epoch 96] [Loss 0.672] [Acc 83.600]\n",
            "\n",
            "Epoch: 97\n",
            " [=====================================================================================>]  Step: 129ms | Tot: 51s147ms | Loss: 0.546 | Acc: 87.524% (43762/50000) | Cls: 0.404  391/391 \n",
            "[2022-11-03 17:53:31,496] [train] [Epoch 97] [Loss 0.546] [cls 0.404] [Acc 87.524]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s545ms | Loss: 0.606 | Acc: 86.680% (8668/10000)  79/79 \n",
            "[2022-11-03 17:53:34,435] [val] [Epoch 97] [Loss 0.606] [Acc 86.680]\n",
            "\n",
            "Epoch: 98\n",
            " [=====================================================================================>]  Step: 124ms | Tot: 52s514ms | Loss: 0.597 | Acc: 86.342% (43171/50000) | Cls: 0.426  391/391 \n",
            "[2022-11-03 17:54:27,714] [train] [Epoch 98] [Loss 0.597] [cls 0.426] [Acc 86.342]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s519ms | Loss: 0.590 | Acc: 86.890% (8689/10000)  79/79 \n",
            "[2022-11-03 17:54:30,612] [val] [Epoch 98] [Loss 0.590] [Acc 86.890]\n",
            "\n",
            "Epoch: 99\n",
            " [=====================================================================================>]  Step: 129ms | Tot: 51s804ms | Loss: 0.545 | Acc: 87.556% (43778/50000) | Cls: 0.407  391/391 \n",
            "[2022-11-03 17:55:23,163] [train] [Epoch 99] [Loss 0.545] [cls 0.407] [Acc 87.556]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s456ms | Loss: 0.640 | Acc: 85.690% (8569/10000)  79/79 \n",
            "[2022-11-03 17:55:26,080] [val] [Epoch 99] [Loss 0.640] [Acc 85.690]\n",
            "\n",
            "Epoch: 100\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 51s768ms | Loss: 0.531 | Acc: 88.032% (44016/50000) | Cls: 0.405  391/391 \n",
            "[2022-11-03 17:56:18,611] [train] [Epoch 100] [Loss 0.531] [cls 0.405] [Acc 88.032]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s434ms | Loss: 0.695 | Acc: 85.000% (8500/10000)  79/79 \n",
            "[2022-11-03 17:56:21,523] [val] [Epoch 100] [Loss 0.695] [Acc 85.000]\n",
            "\n",
            "Epoch: 101\n",
            " [=====================================================================================>]  Step: 126ms | Tot: 51s238ms | Loss: 0.365 | Acc: 92.100% (46050/50000) | Cls: 0.323  391/391 \n",
            "[2022-11-03 17:57:13,444] [train] [Epoch 101] [Loss 0.365] [cls 0.323] [Acc 92.100]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s480ms | Loss: 0.435 | Acc: 90.300% (9030/10000)  79/79 \n",
            "[2022-11-03 17:57:16,400] [val] [Epoch 101] [Loss 0.435] [Acc 90.300]\n",
            "Saving..\n",
            "\n",
            "Epoch: 102\n",
            " [=====================================================================================>]  Step: 128ms | Tot: 51s392ms | Loss: 0.303 | Acc: 93.278% (46639/50000) | Cls: 0.291  391/391 \n",
            "[2022-11-03 17:58:13,051] [train] [Epoch 102] [Loss 0.303] [cls 0.291] [Acc 93.278]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s471ms | Loss: 0.397 | Acc: 90.540% (9054/10000)  79/79 \n",
            "[2022-11-03 17:58:15,982] [val] [Epoch 102] [Loss 0.397] [Acc 90.540]\n",
            "Saving..\n",
            "\n",
            "Epoch: 103\n",
            " [=====================================================================================>]  Step: 128ms | Tot: 51s802ms | Loss: 0.281 | Acc: 93.754% (46877/50000) | Cls: 0.280  391/391 \n",
            "[2022-11-03 17:59:13,011] [train] [Epoch 103] [Loss 0.281] [cls 0.280] [Acc 93.754]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s474ms | Loss: 0.381 | Acc: 90.690% (9069/10000)  79/79 \n",
            "[2022-11-03 17:59:15,932] [val] [Epoch 103] [Loss 0.381] [Acc 90.690]\n",
            "Saving..\n",
            "\n",
            "Epoch: 104\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 52s215ms | Loss: 0.262 | Acc: 94.170% (47085/50000) | Cls: 0.271  391/391 \n",
            "[2022-11-03 18:00:14,328] [train] [Epoch 104] [Loss 0.262] [cls 0.271] [Acc 94.170]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s528ms | Loss: 0.369 | Acc: 90.930% (9093/10000)  79/79 \n",
            "[2022-11-03 18:00:17,249] [val] [Epoch 104] [Loss 0.369] [Acc 90.930]\n",
            "Saving..\n",
            "\n",
            "Epoch: 105\n",
            " [=====================================================================================>]  Step: 127ms | Tot: 51s467ms | Loss: 0.245 | Acc: 94.592% (47296/50000) | Cls: 0.263  391/391 \n",
            "[2022-11-03 18:01:13,926] [train] [Epoch 105] [Loss 0.245] [cls 0.263] [Acc 94.592]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s545ms | Loss: 0.357 | Acc: 90.980% (9098/10000)  79/79 \n",
            "[2022-11-03 18:01:16,945] [val] [Epoch 105] [Loss 0.357] [Acc 90.980]\n",
            "Saving..\n",
            "\n",
            "Epoch: 106\n",
            " [=====================================================================================>]  Step: 129ms | Tot: 51s366ms | Loss: 0.241 | Acc: 94.666% (47333/50000) | Cls: 0.260  391/391 \n",
            "[2022-11-03 18:02:13,680] [train] [Epoch 106] [Loss 0.241] [cls 0.260] [Acc 94.666]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s595ms | Loss: 0.358 | Acc: 90.900% (9090/10000)  79/79 \n",
            "[2022-11-03 18:02:16,662] [val] [Epoch 106] [Loss 0.358] [Acc 90.900]\n",
            "\n",
            "Epoch: 107\n",
            " [=====================================================================================>]  Step: 127ms | Tot: 51s654ms | Loss: 0.230 | Acc: 94.968% (47484/50000) | Cls: 0.252  391/391 \n",
            "[2022-11-03 18:03:09,017] [train] [Epoch 107] [Loss 0.230] [cls 0.252] [Acc 94.968]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s429ms | Loss: 0.352 | Acc: 91.150% (9115/10000)  79/79 \n",
            "[2022-11-03 18:03:11,878] [val] [Epoch 107] [Loss 0.352] [Acc 91.150]\n",
            "Saving..\n",
            "\n",
            "Epoch: 108\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 51s828ms | Loss: 0.223 | Acc: 94.988% (47494/50000) | Cls: 0.250  391/391 \n",
            "[2022-11-03 18:04:09,027] [train] [Epoch 108] [Loss 0.223] [cls 0.250] [Acc 94.988]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s435ms | Loss: 0.340 | Acc: 91.450% (9145/10000)  79/79 \n",
            "[2022-11-03 18:04:11,918] [val] [Epoch 108] [Loss 0.340] [Acc 91.450]\n",
            "Saving..\n",
            "\n",
            "Epoch: 109\n",
            " [=====================================================================================>]  Step: 127ms | Tot: 52s513ms | Loss: 0.212 | Acc: 95.390% (47695/50000) | Cls: 0.238  391/391 \n",
            "[2022-11-03 18:05:09,702] [train] [Epoch 109] [Loss 0.212] [cls 0.238] [Acc 95.390]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s545ms | Loss: 0.338 | Acc: 91.460% (9146/10000)  79/79 \n",
            "[2022-11-03 18:05:12,633] [val] [Epoch 109] [Loss 0.338] [Acc 91.460]\n",
            "Saving..\n",
            "\n",
            "Epoch: 110\n",
            " [=====================================================================================>]  Step: 129ms | Tot: 51s317ms | Loss: 0.209 | Acc: 95.506% (47753/50000) | Cls: 0.238  391/391 \n",
            "[2022-11-03 18:06:09,217] [train] [Epoch 110] [Loss 0.209] [cls 0.238] [Acc 95.506]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s479ms | Loss: 0.337 | Acc: 91.640% (9164/10000)  79/79 \n",
            "[2022-11-03 18:06:12,099] [val] [Epoch 110] [Loss 0.337] [Acc 91.640]\n",
            "Saving..\n",
            "\n",
            "Epoch: 111\n",
            " [=====================================================================================>]  Step: 122ms | Tot: 51s797ms | Loss: 0.207 | Acc: 95.486% (47743/50000) | Cls: 0.233  391/391 \n",
            "[2022-11-03 18:07:09,120] [train] [Epoch 111] [Loss 0.207] [cls 0.233] [Acc 95.486]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s488ms | Loss: 0.333 | Acc: 91.720% (9172/10000)  79/79 \n",
            "[2022-11-03 18:07:12,052] [val] [Epoch 111] [Loss 0.333] [Acc 91.720]\n",
            "Saving..\n",
            "\n",
            "Epoch: 112\n",
            " [=====================================================================================>]  Step: 124ms | Tot: 51s843ms | Loss: 0.194 | Acc: 95.756% (47878/50000) | Cls: 0.227  391/391 \n",
            "[2022-11-03 18:08:09,304] [train] [Epoch 112] [Loss 0.194] [cls 0.227] [Acc 95.756]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s494ms | Loss: 0.325 | Acc: 91.850% (9185/10000)  79/79 \n",
            "[2022-11-03 18:08:12,247] [val] [Epoch 112] [Loss 0.325] [Acc 91.850]\n",
            "Saving..\n",
            "\n",
            "Epoch: 113\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 51s411ms | Loss: 0.193 | Acc: 95.748% (47874/50000) | Cls: 0.224  391/391 \n",
            "[2022-11-03 18:09:08,799] [train] [Epoch 113] [Loss 0.193] [cls 0.224] [Acc 95.748]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s489ms | Loss: 0.327 | Acc: 91.640% (9164/10000)  79/79 \n",
            "[2022-11-03 18:09:11,725] [val] [Epoch 113] [Loss 0.327] [Acc 91.640]\n",
            "\n",
            "Epoch: 114\n",
            " [=====================================================================================>]  Step: 127ms | Tot: 51s690ms | Loss: 0.182 | Acc: 96.114% (48057/50000) | Cls: 0.220  391/391 \n",
            "[2022-11-03 18:10:04,274] [train] [Epoch 114] [Loss 0.182] [cls 0.220] [Acc 96.114]\n",
            " [====================================================================================>.]  Step: 11ms | Tot: 3s680ms | Loss: 0.325 | Acc: 91.800% (9180/10000)  79/79 \n",
            "[2022-11-03 18:10:08,702] [val] [Epoch 114] [Loss 0.325] [Acc 91.800]\n",
            "\n",
            "Epoch: 115\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 51s483ms | Loss: 0.182 | Acc: 96.086% (48043/50000) | Cls: 0.218  391/391 \n",
            "[2022-11-03 18:11:01,191] [train] [Epoch 115] [Loss 0.182] [cls 0.218] [Acc 96.086]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s603ms | Loss: 0.321 | Acc: 91.910% (9191/10000)  79/79 \n",
            "[2022-11-03 18:11:04,216] [val] [Epoch 115] [Loss 0.321] [Acc 91.910]\n",
            "Saving..\n",
            "\n",
            "Epoch: 116\n",
            " [=====================================================================================>]  Step: 124ms | Tot: 51s557ms | Loss: 0.176 | Acc: 96.316% (48158/50000) | Cls: 0.214  391/391 \n",
            "[2022-11-03 18:12:01,792] [train] [Epoch 116] [Loss 0.176] [cls 0.214] [Acc 96.316]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s548ms | Loss: 0.326 | Acc: 91.870% (9187/10000)  79/79 \n",
            "[2022-11-03 18:12:04,858] [val] [Epoch 116] [Loss 0.326] [Acc 91.870]\n",
            "\n",
            "Epoch: 117\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 51s507ms | Loss: 0.170 | Acc: 96.396% (48198/50000) | Cls: 0.209  391/391 \n",
            "[2022-11-03 18:12:57,151] [train] [Epoch 117] [Loss 0.170] [cls 0.209] [Acc 96.396]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s553ms | Loss: 0.315 | Acc: 92.100% (9210/10000)  79/79 \n",
            "[2022-11-03 18:13:00,146] [val] [Epoch 117] [Loss 0.315] [Acc 92.100]\n",
            "Saving..\n",
            "\n",
            "Epoch: 118\n",
            " [=====================================================================================>]  Step: 123ms | Tot: 51s624ms | Loss: 0.167 | Acc: 96.492% (48246/50000) | Cls: 0.208  391/391 \n",
            "[2022-11-03 18:13:57,353] [train] [Epoch 118] [Loss 0.167] [cls 0.208] [Acc 96.492]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s621ms | Loss: 0.326 | Acc: 91.700% (9170/10000)  79/79 \n",
            "[2022-11-03 18:14:00,431] [val] [Epoch 118] [Loss 0.326] [Acc 91.700]\n",
            "\n",
            "Epoch: 119\n",
            " [=====================================================================================>]  Step: 126ms | Tot: 52s275ms | Loss: 0.164 | Acc: 96.498% (48249/50000) | Cls: 0.204  391/391 \n",
            "[2022-11-03 18:14:53,507] [train] [Epoch 119] [Loss 0.164] [cls 0.204] [Acc 96.498]\n",
            " [====================================================================================>.]  Step: 10ms | Tot: 2s678ms | Loss: 0.330 | Acc: 91.740% (9174/10000)  79/79 \n",
            "[2022-11-03 18:14:56,606] [val] [Epoch 119] [Loss 0.330] [Acc 91.740]\n",
            "\n",
            "Epoch: 120\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 54s7ms | Loss: 0.160 | Acc: 96.674% (48337/50000) | Cls: 0.200  391/391 \n",
            "[2022-11-03 18:15:51,433] [train] [Epoch 120] [Loss 0.160] [cls 0.200] [Acc 96.674]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s662ms | Loss: 0.329 | Acc: 91.650% (9165/10000)  79/79 \n",
            "[2022-11-03 18:15:54,581] [val] [Epoch 120] [Loss 0.329] [Acc 91.650]\n",
            "\n",
            "Epoch: 121\n",
            " [=====================================================================================>]  Step: 138ms | Tot: 51s537ms | Loss: 0.158 | Acc: 96.746% (48373/50000) | Cls: 0.196  391/391 \n",
            "[2022-11-03 18:16:46,934] [train] [Epoch 121] [Loss 0.158] [cls 0.196] [Acc 96.746]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s671ms | Loss: 0.320 | Acc: 91.760% (9176/10000)  79/79 \n",
            "[2022-11-03 18:16:50,035] [val] [Epoch 121] [Loss 0.320] [Acc 91.760]\n",
            "\n",
            "Epoch: 122\n",
            " [=====================================================================================>]  Step: 129ms | Tot: 51s571ms | Loss: 0.151 | Acc: 96.822% (48411/50000) | Cls: 0.192  391/391 \n",
            "[2022-11-03 18:17:42,393] [train] [Epoch 122] [Loss 0.151] [cls 0.192] [Acc 96.822]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s639ms | Loss: 0.324 | Acc: 91.840% (9184/10000)  79/79 \n",
            "[2022-11-03 18:17:45,530] [val] [Epoch 122] [Loss 0.324] [Acc 91.840]\n",
            "\n",
            "Epoch: 123\n",
            " [=====================================================================================>]  Step: 127ms | Tot: 52s333ms | Loss: 0.148 | Acc: 96.902% (48451/50000) | Cls: 0.192  391/391 \n",
            "[2022-11-03 18:18:38,680] [train] [Epoch 123] [Loss 0.148] [cls 0.192] [Acc 96.902]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s567ms | Loss: 0.320 | Acc: 91.710% (9171/10000)  79/79 \n",
            "[2022-11-03 18:18:41,706] [val] [Epoch 123] [Loss 0.320] [Acc 91.710]\n",
            "\n",
            "Epoch: 124\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 52s201ms | Loss: 0.145 | Acc: 97.114% (48557/50000) | Cls: 0.188  391/391 \n",
            "[2022-11-03 18:19:34,708] [train] [Epoch 124] [Loss 0.145] [cls 0.188] [Acc 97.114]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s662ms | Loss: 0.319 | Acc: 91.860% (9186/10000)  79/79 \n",
            "[2022-11-03 18:19:37,821] [val] [Epoch 124] [Loss 0.319] [Acc 91.860]\n",
            "\n",
            "Epoch: 125\n",
            " [=====================================================================================>]  Step: 128ms | Tot: 51s608ms | Loss: 0.142 | Acc: 97.178% (48589/50000) | Cls: 0.186  391/391 \n",
            "[2022-11-03 18:20:30,153] [train] [Epoch 125] [Loss 0.142] [cls 0.186] [Acc 97.178]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s624ms | Loss: 0.318 | Acc: 91.950% (9195/10000)  79/79 \n",
            "[2022-11-03 18:20:33,255] [val] [Epoch 125] [Loss 0.318] [Acc 91.950]\n",
            "\n",
            "Epoch: 126\n",
            " [=====================================================================================>]  Step: 129ms | Tot: 53s447ms | Loss: 0.142 | Acc: 97.028% (48514/50000) | Cls: 0.187  391/391 \n",
            "[2022-11-03 18:21:27,581] [train] [Epoch 126] [Loss 0.142] [cls 0.187] [Acc 97.028]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s684ms | Loss: 0.316 | Acc: 92.020% (9202/10000)  79/79 \n",
            "[2022-11-03 18:21:30,698] [val] [Epoch 126] [Loss 0.316] [Acc 92.020]\n",
            "\n",
            "Epoch: 127\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 52s354ms | Loss: 0.134 | Acc: 97.280% (48640/50000) | Cls: 0.182  391/391 \n",
            "[2022-11-03 18:22:23,895] [train] [Epoch 127] [Loss 0.134] [cls 0.182] [Acc 97.280]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s639ms | Loss: 0.308 | Acc: 91.990% (9199/10000)  79/79 \n",
            "[2022-11-03 18:22:27,073] [val] [Epoch 127] [Loss 0.308] [Acc 91.990]\n",
            "\n",
            "Epoch: 128\n",
            " [=====================================================================================>]  Step: 124ms | Tot: 52s510ms | Loss: 0.131 | Acc: 97.324% (48662/50000) | Cls: 0.179  391/391 \n",
            "[2022-11-03 18:23:20,337] [train] [Epoch 128] [Loss 0.131] [cls 0.179] [Acc 97.324]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s713ms | Loss: 0.330 | Acc: 91.630% (9163/10000)  79/79 \n",
            "[2022-11-03 18:23:23,495] [val] [Epoch 128] [Loss 0.330] [Acc 91.630]\n",
            "\n",
            "Epoch: 129\n",
            " [=====================================================================================>]  Step: 130ms | Tot: 51s567ms | Loss: 0.131 | Acc: 97.398% (48699/50000) | Cls: 0.178  391/391 \n",
            "[2022-11-03 18:24:15,886] [train] [Epoch 129] [Loss 0.131] [cls 0.178] [Acc 97.398]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s728ms | Loss: 0.319 | Acc: 91.870% (9187/10000)  79/79 \n",
            "[2022-11-03 18:24:19,074] [val] [Epoch 129] [Loss 0.319] [Acc 91.870]\n",
            "\n",
            "Epoch: 130\n",
            " [=====================================================================================>]  Step: 126ms | Tot: 51s642ms | Loss: 0.128 | Acc: 97.474% (48737/50000) | Cls: 0.175  391/391 \n",
            "[2022-11-03 18:25:11,507] [train] [Epoch 130] [Loss 0.128] [cls 0.175] [Acc 97.474]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s676ms | Loss: 0.320 | Acc: 92.170% (9217/10000)  79/79 \n",
            "[2022-11-03 18:25:14,674] [val] [Epoch 130] [Loss 0.320] [Acc 92.170]\n",
            "Saving..\n",
            "\n",
            "Epoch: 131\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 52s396ms | Loss: 0.125 | Acc: 97.488% (48744/50000) | Cls: 0.173  391/391 \n",
            "[2022-11-03 18:26:12,530] [train] [Epoch 131] [Loss 0.125] [cls 0.173] [Acc 97.488]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s735ms | Loss: 0.317 | Acc: 91.800% (9180/10000)  79/79 \n",
            "[2022-11-03 18:26:15,669] [val] [Epoch 131] [Loss 0.317] [Acc 91.800]\n",
            "\n",
            "Epoch: 132\n",
            " [=====================================================================================>]  Step: 129ms | Tot: 54s17ms | Loss: 0.124 | Acc: 97.534% (48767/50000) | Cls: 0.168  391/391 \n",
            "[2022-11-03 18:27:10,379] [train] [Epoch 132] [Loss 0.124] [cls 0.168] [Acc 97.534]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s654ms | Loss: 0.332 | Acc: 91.850% (9185/10000)  79/79 \n",
            "[2022-11-03 18:27:13,450] [val] [Epoch 132] [Loss 0.332] [Acc 91.850]\n",
            "\n",
            "Epoch: 133\n",
            " [=====================================================================================>]  Step: 123ms | Tot: 51s586ms | Loss: 0.123 | Acc: 97.528% (48764/50000) | Cls: 0.175  391/391 \n",
            "[2022-11-03 18:28:05,880] [train] [Epoch 133] [Loss 0.123] [cls 0.175] [Acc 97.528]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s588ms | Loss: 0.318 | Acc: 91.950% (9195/10000)  79/79 \n",
            "[2022-11-03 18:28:09,002] [val] [Epoch 133] [Loss 0.318] [Acc 91.950]\n",
            "\n",
            "Epoch: 134\n",
            " [=====================================================================================>]  Step: 130ms | Tot: 51s618ms | Loss: 0.115 | Acc: 97.708% (48854/50000) | Cls: 0.164  391/391 \n",
            "[2022-11-03 18:29:01,362] [train] [Epoch 134] [Loss 0.115] [cls 0.164] [Acc 97.708]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s646ms | Loss: 0.323 | Acc: 91.970% (9197/10000)  79/79 \n",
            "[2022-11-03 18:29:04,433] [val] [Epoch 134] [Loss 0.323] [Acc 91.970]\n",
            "\n",
            "Epoch: 135\n",
            " [=====================================================================================>]  Step: 126ms | Tot: 52s359ms | Loss: 0.115 | Acc: 97.802% (48901/50000) | Cls: 0.165  391/391 \n",
            "[2022-11-03 18:29:57,575] [train] [Epoch 135] [Loss 0.115] [cls 0.165] [Acc 97.802]\n",
            " [====================================================================================>.]  Step: 10ms | Tot: 3s894ms | Loss: 0.325 | Acc: 91.970% (9197/10000)  79/79 \n",
            "[2022-11-03 18:30:02,163] [val] [Epoch 135] [Loss 0.325] [Acc 91.970]\n",
            "\n",
            "Epoch: 136\n",
            " [=====================================================================================>]  Step: 121ms | Tot: 51s577ms | Loss: 0.114 | Acc: 97.852% (48926/50000) | Cls: 0.165  391/391 \n",
            "[2022-11-03 18:30:54,541] [train] [Epoch 136] [Loss 0.114] [cls 0.165] [Acc 97.852]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s677ms | Loss: 0.323 | Acc: 92.000% (9200/10000)  79/79 \n",
            "[2022-11-03 18:30:57,679] [val] [Epoch 136] [Loss 0.323] [Acc 92.000]\n",
            "\n",
            "Epoch: 137\n",
            " [=====================================================================================>]  Step: 128ms | Tot: 51s563ms | Loss: 0.111 | Acc: 97.868% (48934/50000) | Cls: 0.160  391/391 \n",
            "[2022-11-03 18:31:50,047] [train] [Epoch 137] [Loss 0.111] [cls 0.160] [Acc 97.868]\n",
            " [====================================================================================>.]  Step: 10ms | Tot: 3s862ms | Loss: 0.324 | Acc: 91.940% (9194/10000)  79/79 \n",
            "[2022-11-03 18:31:54,482] [val] [Epoch 137] [Loss 0.324] [Acc 91.940]\n",
            "\n",
            "Epoch: 138\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 52s541ms | Loss: 0.111 | Acc: 97.876% (48938/50000) | Cls: 0.161  391/391 \n",
            "[2022-11-03 18:32:48,360] [train] [Epoch 138] [Loss 0.111] [cls 0.161] [Acc 97.876]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s649ms | Loss: 0.320 | Acc: 92.130% (9213/10000)  79/79 \n",
            "[2022-11-03 18:32:51,495] [val] [Epoch 138] [Loss 0.320] [Acc 92.130]\n",
            "\n",
            "Epoch: 139\n",
            " [=====================================================================================>]  Step: 124ms | Tot: 52s999ms | Loss: 0.111 | Acc: 97.862% (48931/50000) | Cls: 0.159  391/391 \n",
            "[2022-11-03 18:33:45,326] [train] [Epoch 139] [Loss 0.111] [cls 0.159] [Acc 97.862]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s583ms | Loss: 0.323 | Acc: 91.900% (9190/10000)  79/79 \n",
            "[2022-11-03 18:33:48,387] [val] [Epoch 139] [Loss 0.323] [Acc 91.900]\n",
            "\n",
            "Epoch: 140\n",
            " [=====================================================================================>]  Step: 130ms | Tot: 51s630ms | Loss: 0.105 | Acc: 98.036% (49018/50000) | Cls: 0.157  391/391 \n",
            "[2022-11-03 18:34:40,724] [train] [Epoch 140] [Loss 0.105] [cls 0.157] [Acc 98.036]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s648ms | Loss: 0.342 | Acc: 91.590% (9159/10000)  79/79 \n",
            "[2022-11-03 18:34:43,867] [val] [Epoch 140] [Loss 0.342] [Acc 91.590]\n",
            "\n",
            "Epoch: 141\n",
            " [=====================================================================================>]  Step: 127ms | Tot: 51s620ms | Loss: 0.107 | Acc: 97.928% (48964/50000) | Cls: 0.157  391/391 \n",
            "[2022-11-03 18:35:36,279] [train] [Epoch 141] [Loss 0.107] [cls 0.157] [Acc 97.928]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s659ms | Loss: 0.329 | Acc: 91.950% (9195/10000)  79/79 \n",
            "[2022-11-03 18:35:39,400] [val] [Epoch 141] [Loss 0.329] [Acc 91.950]\n",
            "\n",
            "Epoch: 142\n",
            " [=====================================================================================>]  Step: 130ms | Tot: 51s645ms | Loss: 0.101 | Acc: 98.070% (49035/50000) | Cls: 0.152  391/391 \n",
            "[2022-11-03 18:36:31,822] [train] [Epoch 142] [Loss 0.101] [cls 0.152] [Acc 98.070]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s687ms | Loss: 0.336 | Acc: 91.800% (9180/10000)  79/79 \n",
            "[2022-11-03 18:36:34,935] [val] [Epoch 142] [Loss 0.336] [Acc 91.800]\n",
            "\n",
            "Epoch: 143\n",
            " [=====================================================================================>]  Step: 129ms | Tot: 55s449ms | Loss: 0.103 | Acc: 98.058% (49029/50000) | Cls: 0.152  391/391 \n",
            "[2022-11-03 18:37:31,188] [train] [Epoch 143] [Loss 0.103] [cls 0.152] [Acc 98.058]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s735ms | Loss: 0.333 | Acc: 91.770% (9177/10000)  79/79 \n",
            "[2022-11-03 18:37:34,365] [val] [Epoch 143] [Loss 0.333] [Acc 91.770]\n",
            "\n",
            "Epoch: 144\n",
            " [=====================================================================================>]  Step: 127ms | Tot: 51s606ms | Loss: 0.100 | Acc: 98.054% (49027/50000) | Cls: 0.150  391/391 \n",
            "[2022-11-03 18:38:26,792] [train] [Epoch 144] [Loss 0.100] [cls 0.150] [Acc 98.054]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s695ms | Loss: 0.326 | Acc: 91.990% (9199/10000)  79/79 \n",
            "[2022-11-03 18:38:29,898] [val] [Epoch 144] [Loss 0.326] [Acc 91.990]\n",
            "\n",
            "Epoch: 145\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 51s651ms | Loss: 0.096 | Acc: 98.198% (49099/50000) | Cls: 0.146  391/391 \n",
            "[2022-11-03 18:39:22,382] [train] [Epoch 145] [Loss 0.096] [cls 0.146] [Acc 98.198]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s706ms | Loss: 0.329 | Acc: 92.000% (9200/10000)  79/79 \n",
            "[2022-11-03 18:39:25,508] [val] [Epoch 145] [Loss 0.329] [Acc 92.000]\n",
            "\n",
            "Epoch: 146\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 51s666ms | Loss: 0.096 | Acc: 98.244% (49122/50000) | Cls: 0.150  391/391 \n",
            "[2022-11-03 18:40:17,998] [train] [Epoch 146] [Loss 0.096] [cls 0.150] [Acc 98.244]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s604ms | Loss: 0.343 | Acc: 91.700% (9170/10000)  79/79 \n",
            "[2022-11-03 18:40:21,096] [val] [Epoch 146] [Loss 0.343] [Acc 91.700]\n",
            "\n",
            "Epoch: 147\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 52s373ms | Loss: 0.098 | Acc: 98.248% (49124/50000) | Cls: 0.146  391/391 \n",
            "[2022-11-03 18:41:14,283] [train] [Epoch 147] [Loss 0.098] [cls 0.146] [Acc 98.248]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s680ms | Loss: 0.342 | Acc: 91.700% (9170/10000)  79/79 \n",
            "[2022-11-03 18:41:17,372] [val] [Epoch 147] [Loss 0.342] [Acc 91.700]\n",
            "\n",
            "Epoch: 148\n",
            " [=====================================================================================>]  Step: 126ms | Tot: 51s623ms | Loss: 0.093 | Acc: 98.152% (49076/50000) | Cls: 0.146  391/391 \n",
            "[2022-11-03 18:42:09,819] [train] [Epoch 148] [Loss 0.093] [cls 0.146] [Acc 98.152]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s701ms | Loss: 0.335 | Acc: 91.860% (9186/10000)  79/79 \n",
            "[2022-11-03 18:42:12,932] [val] [Epoch 148] [Loss 0.335] [Acc 91.860]\n",
            "\n",
            "Epoch: 149\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 51s700ms | Loss: 0.089 | Acc: 98.362% (49181/50000) | Cls: 0.145  391/391 \n",
            "[2022-11-03 18:43:05,429] [train] [Epoch 149] [Loss 0.089] [cls 0.145] [Acc 98.362]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s664ms | Loss: 0.334 | Acc: 91.720% (9172/10000)  79/79 \n",
            "[2022-11-03 18:43:08,593] [val] [Epoch 149] [Loss 0.334] [Acc 91.720]\n",
            "\n",
            "Epoch: 150\n",
            " [=====================================================================================>]  Step: 128ms | Tot: 54s315ms | Loss: 0.094 | Acc: 98.234% (49117/50000) | Cls: 0.144  391/391 \n",
            "[2022-11-03 18:44:03,607] [train] [Epoch 150] [Loss 0.094] [cls 0.144] [Acc 98.234]\n",
            " [====================================================================================>.]  Step: 10ms | Tot: 3s804ms | Loss: 0.321 | Acc: 92.060% (9206/10000)  79/79 \n",
            "[2022-11-03 18:44:08,061] [val] [Epoch 150] [Loss 0.321] [Acc 92.060]\n",
            "\n",
            "Epoch: 151\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 51s560ms | Loss: 0.080 | Acc: 98.686% (49343/50000) | Cls: 0.124  391/391 \n",
            "[2022-11-03 18:45:00,526] [train] [Epoch 151] [Loss 0.080] [cls 0.124] [Acc 98.686]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s612ms | Loss: 0.326 | Acc: 92.060% (9206/10000)  79/79 \n",
            "[2022-11-03 18:45:03,640] [val] [Epoch 151] [Loss 0.326] [Acc 92.060]\n",
            "\n",
            "Epoch: 152\n",
            " [=====================================================================================>]  Step: 133ms | Tot: 51s654ms | Loss: 0.076 | Acc: 98.714% (49357/50000) | Cls: 0.123  391/391 \n",
            "[2022-11-03 18:45:56,067] [train] [Epoch 152] [Loss 0.076] [cls 0.123] [Acc 98.714]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s703ms | Loss: 0.315 | Acc: 92.410% (9241/10000)  79/79 \n",
            "[2022-11-03 18:45:59,184] [val] [Epoch 152] [Loss 0.315] [Acc 92.410]\n",
            "Saving..\n",
            "\n",
            "Epoch: 153\n",
            " [=====================================================================================>]  Step: 130ms | Tot: 51s723ms | Loss: 0.072 | Acc: 98.828% (49414/50000) | Cls: 0.118  391/391 \n",
            "[2022-11-03 18:46:56,520] [train] [Epoch 153] [Loss 0.072] [cls 0.118] [Acc 98.828]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s629ms | Loss: 0.317 | Acc: 92.380% (9238/10000)  79/79 \n",
            "[2022-11-03 18:46:59,647] [val] [Epoch 153] [Loss 0.317] [Acc 92.380]\n",
            "\n",
            "Epoch: 154\n",
            " [=====================================================================================>]  Step: 124ms | Tot: 52s259ms | Loss: 0.070 | Acc: 98.844% (49422/50000) | Cls: 0.118  391/391 \n",
            "[2022-11-03 18:47:52,823] [train] [Epoch 154] [Loss 0.070] [cls 0.118] [Acc 98.844]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s674ms | Loss: 0.318 | Acc: 92.390% (9239/10000)  79/79 \n",
            "[2022-11-03 18:47:55,988] [val] [Epoch 154] [Loss 0.318] [Acc 92.390]\n",
            "\n",
            "Epoch: 155\n",
            " [=====================================================================================>]  Step: 128ms | Tot: 52s333ms | Loss: 0.067 | Acc: 98.914% (49457/50000) | Cls: 0.117  391/391 \n",
            "[2022-11-03 18:48:49,156] [train] [Epoch 155] [Loss 0.067] [cls 0.117] [Acc 98.914]\n",
            " [====================================================================================>.]  Step: 10ms | Tot: 2s689ms | Loss: 0.318 | Acc: 92.340% (9234/10000)  79/79 \n",
            "[2022-11-03 18:48:52,290] [val] [Epoch 155] [Loss 0.318] [Acc 92.340]\n",
            "\n",
            "Epoch: 156\n",
            " [=====================================================================================>]  Step: 124ms | Tot: 53s303ms | Loss: 0.066 | Acc: 98.950% (49475/50000) | Cls: 0.115  391/391 \n",
            "[2022-11-03 18:49:46,434] [train] [Epoch 156] [Loss 0.066] [cls 0.115] [Acc 98.950]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s608ms | Loss: 0.320 | Acc: 92.400% (9240/10000)  79/79 \n",
            "[2022-11-03 18:49:49,508] [val] [Epoch 156] [Loss 0.320] [Acc 92.400]\n",
            "\n",
            "Epoch: 157\n",
            " [=====================================================================================>]  Step: 128ms | Tot: 51s572ms | Loss: 0.064 | Acc: 98.988% (49494/50000) | Cls: 0.113  391/391 \n",
            "[2022-11-03 18:50:41,865] [train] [Epoch 157] [Loss 0.064] [cls 0.113] [Acc 98.988]\n",
            " [====================================================================================>.]  Step: 10ms | Tot: 2s757ms | Loss: 0.320 | Acc: 92.290% (9229/10000)  79/79 \n",
            "[2022-11-03 18:50:45,219] [val] [Epoch 157] [Loss 0.320] [Acc 92.290]\n",
            "\n",
            "Epoch: 158\n",
            " [=====================================================================================>]  Step: 132ms | Tot: 52s416ms | Loss: 0.065 | Acc: 98.954% (49477/50000) | Cls: 0.112  391/391 \n",
            "[2022-11-03 18:51:38,986] [train] [Epoch 158] [Loss 0.065] [cls 0.112] [Acc 98.954]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s601ms | Loss: 0.325 | Acc: 92.410% (9241/10000)  79/79 \n",
            "[2022-11-03 18:51:42,142] [val] [Epoch 158] [Loss 0.325] [Acc 92.410]\n",
            "\n",
            "Epoch: 159\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 51s566ms | Loss: 0.064 | Acc: 98.964% (49482/50000) | Cls: 0.110  391/391 \n",
            "[2022-11-03 18:52:34,502] [train] [Epoch 159] [Loss 0.064] [cls 0.110] [Acc 98.964]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s664ms | Loss: 0.321 | Acc: 92.430% (9243/10000)  79/79 \n",
            "[2022-11-03 18:52:37,643] [val] [Epoch 159] [Loss 0.321] [Acc 92.430]\n",
            "Saving..\n",
            "\n",
            "Epoch: 160\n",
            " [=====================================================================================>]  Step: 127ms | Tot: 51s732ms | Loss: 0.061 | Acc: 99.064% (49532/50000) | Cls: 0.109  391/391 \n",
            "[2022-11-03 18:53:34,967] [train] [Epoch 160] [Loss 0.061] [cls 0.109] [Acc 99.064]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s636ms | Loss: 0.324 | Acc: 92.420% (9242/10000)  79/79 \n",
            "[2022-11-03 18:53:38,091] [val] [Epoch 160] [Loss 0.324] [Acc 92.420]\n",
            "\n",
            "Epoch: 161\n",
            " [=====================================================================================>]  Step: 123ms | Tot: 52s737ms | Loss: 0.062 | Acc: 99.032% (49516/50000) | Cls: 0.109  391/391 \n",
            "[2022-11-03 18:54:31,785] [train] [Epoch 161] [Loss 0.062] [cls 0.109] [Acc 99.032]\n",
            " [====================================================================================>.]  Step: 10ms | Tot: 4s263ms | Loss: 0.326 | Acc: 92.420% (9242/10000)  79/79 \n",
            "[2022-11-03 18:54:36,942] [val] [Epoch 161] [Loss 0.326] [Acc 92.420]\n",
            "\n",
            "Epoch: 162\n",
            " [=====================================================================================>]  Step: 123ms | Tot: 52s220ms | Loss: 0.061 | Acc: 99.044% (49522/50000) | Cls: 0.111  391/391 \n",
            "[2022-11-03 18:55:30,142] [train] [Epoch 162] [Loss 0.061] [cls 0.111] [Acc 99.044]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s615ms | Loss: 0.326 | Acc: 92.340% (9234/10000)  79/79 \n",
            "[2022-11-03 18:55:33,280] [val] [Epoch 162] [Loss 0.326] [Acc 92.340]\n",
            "\n",
            "Epoch: 163\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 51s665ms | Loss: 0.060 | Acc: 99.076% (49538/50000) | Cls: 0.110  391/391 \n",
            "[2022-11-03 18:56:25,756] [train] [Epoch 163] [Loss 0.060] [cls 0.110] [Acc 99.076]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s646ms | Loss: 0.327 | Acc: 92.370% (9237/10000)  79/79 \n",
            "[2022-11-03 18:56:28,880] [val] [Epoch 163] [Loss 0.327] [Acc 92.370]\n",
            "\n",
            "Epoch: 164\n",
            " [=====================================================================================>]  Step: 127ms | Tot: 51s730ms | Loss: 0.059 | Acc: 99.100% (49550/50000) | Cls: 0.109  391/391 \n",
            "[2022-11-03 18:57:21,363] [train] [Epoch 164] [Loss 0.059] [cls 0.109] [Acc 99.100]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s689ms | Loss: 0.330 | Acc: 92.350% (9235/10000)  79/79 \n",
            "[2022-11-03 18:57:24,466] [val] [Epoch 164] [Loss 0.330] [Acc 92.350]\n",
            "\n",
            "Epoch: 165\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 51s709ms | Loss: 0.059 | Acc: 99.104% (49552/50000) | Cls: 0.106  391/391 \n",
            "[2022-11-03 18:58:17,022] [train] [Epoch 165] [Loss 0.059] [cls 0.106] [Acc 99.104]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s723ms | Loss: 0.335 | Acc: 92.400% (9240/10000)  79/79 \n",
            "[2022-11-03 18:58:20,173] [val] [Epoch 165] [Loss 0.335] [Acc 92.400]\n",
            "\n",
            "Epoch: 166\n",
            " [=====================================================================================>]  Step: 127ms | Tot: 51s676ms | Loss: 0.058 | Acc: 99.132% (49566/50000) | Cls: 0.105  391/391 \n",
            "[2022-11-03 18:59:12,666] [train] [Epoch 166] [Loss 0.058] [cls 0.105] [Acc 99.132]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s631ms | Loss: 0.327 | Acc: 92.520% (9252/10000)  79/79 \n",
            "[2022-11-03 18:59:15,765] [val] [Epoch 166] [Loss 0.327] [Acc 92.520]\n",
            "Saving..\n",
            "\n",
            "Epoch: 167\n",
            " [=====================================================================================>]  Step: 127ms | Tot: 52s439ms | Loss: 0.058 | Acc: 99.104% (49552/50000) | Cls: 0.103  391/391 \n",
            "[2022-11-03 19:00:13,596] [train] [Epoch 167] [Loss 0.058] [cls 0.103] [Acc 99.104]\n",
            " [====================================================================================>.]  Step: 10ms | Tot: 2s608ms | Loss: 0.326 | Acc: 92.490% (9249/10000)  79/79 \n",
            "[2022-11-03 19:00:16,726] [val] [Epoch 167] [Loss 0.326] [Acc 92.490]\n",
            "\n",
            "Epoch: 168\n",
            " [=====================================================================================>]  Step: 129ms | Tot: 51s584ms | Loss: 0.058 | Acc: 99.112% (49556/50000) | Cls: 0.107  391/391 \n",
            "[2022-11-03 19:01:09,178] [train] [Epoch 168] [Loss 0.058] [cls 0.107] [Acc 99.112]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s655ms | Loss: 0.327 | Acc: 92.450% (9245/10000)  79/79 \n",
            "[2022-11-03 19:01:12,295] [val] [Epoch 168] [Loss 0.327] [Acc 92.450]\n",
            "\n",
            "Epoch: 169\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 54s168ms | Loss: 0.057 | Acc: 99.166% (49583/50000) | Cls: 0.104  391/391 \n",
            "[2022-11-03 19:02:07,201] [train] [Epoch 169] [Loss 0.057] [cls 0.104] [Acc 99.166]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s767ms | Loss: 0.325 | Acc: 92.420% (9242/10000)  79/79 \n",
            "[2022-11-03 19:02:10,379] [val] [Epoch 169] [Loss 0.325] [Acc 92.420]\n",
            "\n",
            "Epoch: 170\n",
            " [=====================================================================================>]  Step: 126ms | Tot: 52s433ms | Loss: 0.055 | Acc: 99.194% (49597/50000) | Cls: 0.101  391/391 \n",
            "[2022-11-03 19:03:03,517] [train] [Epoch 170] [Loss 0.055] [cls 0.101] [Acc 99.194]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s729ms | Loss: 0.329 | Acc: 92.380% (9238/10000)  79/79 \n",
            "[2022-11-03 19:03:06,702] [val] [Epoch 170] [Loss 0.329] [Acc 92.380]\n",
            "\n",
            "Epoch: 171\n",
            " [=====================================================================================>]  Step: 129ms | Tot: 51s610ms | Loss: 0.058 | Acc: 99.108% (49554/50000) | Cls: 0.106  391/391 \n",
            "[2022-11-03 19:03:59,105] [train] [Epoch 171] [Loss 0.058] [cls 0.106] [Acc 99.108]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s597ms | Loss: 0.328 | Acc: 92.390% (9239/10000)  79/79 \n",
            "[2022-11-03 19:04:02,180] [val] [Epoch 171] [Loss 0.328] [Acc 92.390]\n",
            "\n",
            "Epoch: 172\n",
            " [=====================================================================================>]  Step: 142ms | Tot: 51s887ms | Loss: 0.056 | Acc: 99.124% (49562/50000) | Cls: 0.104  391/391 \n",
            "[2022-11-03 19:04:54,969] [train] [Epoch 172] [Loss 0.056] [cls 0.104] [Acc 99.124]\n",
            " [====================================================================================>.]  Step: 10ms | Tot: 2s910ms | Loss: 0.324 | Acc: 92.590% (9259/10000)  79/79 \n",
            "[2022-11-03 19:04:58,528] [val] [Epoch 172] [Loss 0.324] [Acc 92.590]\n",
            "Saving..\n",
            "\n",
            "Epoch: 173\n",
            " [=====================================================================================>]  Step: 128ms | Tot: 51s681ms | Loss: 0.055 | Acc: 99.154% (49577/50000) | Cls: 0.104  391/391 \n",
            "[2022-11-03 19:05:55,689] [train] [Epoch 173] [Loss 0.055] [cls 0.104] [Acc 99.154]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s598ms | Loss: 0.326 | Acc: 92.530% (9253/10000)  79/79 \n",
            "[2022-11-03 19:05:58,769] [val] [Epoch 173] [Loss 0.326] [Acc 92.530]\n",
            "\n",
            "Epoch: 174\n",
            " [=====================================================================================>]  Step: 128ms | Tot: 54s459ms | Loss: 0.055 | Acc: 99.188% (49594/50000) | Cls: 0.101  391/391 \n",
            "[2022-11-03 19:06:53,978] [train] [Epoch 174] [Loss 0.055] [cls 0.101] [Acc 99.188]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s673ms | Loss: 0.334 | Acc: 92.320% (9232/10000)  79/79 \n",
            "[2022-11-03 19:06:57,057] [val] [Epoch 174] [Loss 0.334] [Acc 92.320]\n",
            "\n",
            "Epoch: 175\n",
            " [=====================================================================================>]  Step: 123ms | Tot: 51s648ms | Loss: 0.056 | Acc: 99.152% (49576/50000) | Cls: 0.104  391/391 \n",
            "[2022-11-03 19:07:49,440] [train] [Epoch 175] [Loss 0.056] [cls 0.104] [Acc 99.152]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s650ms | Loss: 0.329 | Acc: 92.370% (9237/10000)  79/79 \n",
            "[2022-11-03 19:07:52,561] [val] [Epoch 175] [Loss 0.329] [Acc 92.370]\n",
            "\n",
            "Epoch: 176\n",
            " [=====================================================================================>]  Step: 124ms | Tot: 52s363ms | Loss: 0.055 | Acc: 99.152% (49576/50000) | Cls: 0.102  391/391 \n",
            "[2022-11-03 19:08:45,714] [train] [Epoch 176] [Loss 0.055] [cls 0.102] [Acc 99.152]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s681ms | Loss: 0.331 | Acc: 92.400% (9240/10000)  79/79 \n",
            "[2022-11-03 19:08:48,809] [val] [Epoch 176] [Loss 0.331] [Acc 92.400]\n",
            "\n",
            "Epoch: 177\n",
            " [=====================================================================================>]  Step: 127ms | Tot: 51s608ms | Loss: 0.053 | Acc: 99.176% (49588/50000) | Cls: 0.099  391/391 \n",
            "[2022-11-03 19:09:41,234] [train] [Epoch 177] [Loss 0.053] [cls 0.099] [Acc 99.176]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s663ms | Loss: 0.332 | Acc: 92.500% (9250/10000)  79/79 \n",
            "[2022-11-03 19:09:44,376] [val] [Epoch 177] [Loss 0.332] [Acc 92.500]\n",
            "\n",
            "Epoch: 178\n",
            " [=====================================================================================>]  Step: 135ms | Tot: 52s391ms | Loss: 0.055 | Acc: 99.180% (49590/50000) | Cls: 0.100  391/391 \n",
            "[2022-11-03 19:10:37,527] [train] [Epoch 178] [Loss 0.055] [cls 0.100] [Acc 99.180]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s600ms | Loss: 0.333 | Acc: 92.380% (9238/10000)  79/79 \n",
            "[2022-11-03 19:10:40,603] [val] [Epoch 178] [Loss 0.333] [Acc 92.380]\n",
            "\n",
            "Epoch: 179\n",
            " [=====================================================================================>]  Step: 129ms | Tot: 51s691ms | Loss: 0.052 | Acc: 99.224% (49612/50000) | Cls: 0.099  391/391 \n",
            "[2022-11-03 19:11:33,013] [train] [Epoch 179] [Loss 0.052] [cls 0.099] [Acc 99.224]\n",
            " [====================================================================================>.]  Step: 10ms | Tot: 4s167ms | Loss: 0.331 | Acc: 92.540% (9254/10000)  79/79 \n",
            "[2022-11-03 19:11:37,941] [val] [Epoch 179] [Loss 0.331] [Acc 92.540]\n",
            "\n",
            "Epoch: 180\n",
            " [=====================================================================================>]  Step: 132ms | Tot: 53s247ms | Loss: 0.052 | Acc: 99.230% (49615/50000) | Cls: 0.101  391/391 \n",
            "[2022-11-03 19:12:32,450] [train] [Epoch 180] [Loss 0.052] [cls 0.101] [Acc 99.230]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s606ms | Loss: 0.330 | Acc: 92.480% (9248/10000)  79/79 \n",
            "[2022-11-03 19:12:35,538] [val] [Epoch 180] [Loss 0.330] [Acc 92.480]\n",
            "\n",
            "Epoch: 181\n",
            " [=====================================================================================>]  Step: 124ms | Tot: 51s953ms | Loss: 0.052 | Acc: 99.254% (49627/50000) | Cls: 0.095  391/391 \n",
            "[2022-11-03 19:13:28,364] [train] [Epoch 181] [Loss 0.052] [cls 0.095] [Acc 99.254]\n",
            " [====================================================================================>.]  Step: 10ms | Tot: 2s772ms | Loss: 0.330 | Acc: 92.400% (9240/10000)  79/79 \n",
            "[2022-11-03 19:13:31,816] [val] [Epoch 181] [Loss 0.330] [Acc 92.400]\n",
            "\n",
            "Epoch: 182\n",
            " [=====================================================================================>]  Step: 128ms | Tot: 51s580ms | Loss: 0.052 | Acc: 99.234% (49617/50000) | Cls: 0.101  391/391 \n",
            "[2022-11-03 19:14:24,155] [train] [Epoch 182] [Loss 0.052] [cls 0.101] [Acc 99.234]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s635ms | Loss: 0.326 | Acc: 92.620% (9262/10000)  79/79 \n",
            "[2022-11-03 19:14:27,280] [val] [Epoch 182] [Loss 0.326] [Acc 92.620]\n",
            "Saving..\n",
            "\n",
            "Epoch: 183\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 52s456ms | Loss: 0.054 | Acc: 99.202% (49601/50000) | Cls: 0.100  391/391 \n",
            "[2022-11-03 19:15:25,191] [train] [Epoch 183] [Loss 0.054] [cls 0.100] [Acc 99.202]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s604ms | Loss: 0.329 | Acc: 92.540% (9254/10000)  79/79 \n",
            "[2022-11-03 19:15:28,314] [val] [Epoch 183] [Loss 0.329] [Acc 92.540]\n",
            "\n",
            "Epoch: 184\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 51s660ms | Loss: 0.051 | Acc: 99.254% (49627/50000) | Cls: 0.096  391/391 \n",
            "[2022-11-03 19:16:20,768] [train] [Epoch 184] [Loss 0.051] [cls 0.096] [Acc 99.254]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s738ms | Loss: 0.331 | Acc: 92.530% (9253/10000)  79/79 \n",
            "[2022-11-03 19:16:23,957] [val] [Epoch 184] [Loss 0.331] [Acc 92.530]\n",
            "\n",
            "Epoch: 185\n",
            " [=====================================================================================>]  Step: 128ms | Tot: 54s296ms | Loss: 0.052 | Acc: 99.226% (49613/50000) | Cls: 0.100  391/391 \n",
            "[2022-11-03 19:17:19,075] [train] [Epoch 185] [Loss 0.052] [cls 0.100] [Acc 99.226]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s729ms | Loss: 0.327 | Acc: 92.500% (9250/10000)  79/79 \n",
            "[2022-11-03 19:17:22,237] [val] [Epoch 185] [Loss 0.327] [Acc 92.500]\n",
            "\n",
            "Epoch: 186\n",
            " [=====================================================================================>]  Step: 124ms | Tot: 51s669ms | Loss: 0.051 | Acc: 99.282% (49641/50000) | Cls: 0.097  391/391 \n",
            "[2022-11-03 19:18:14,745] [train] [Epoch 186] [Loss 0.051] [cls 0.097] [Acc 99.282]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s670ms | Loss: 0.331 | Acc: 92.490% (9249/10000)  79/79 \n",
            "[2022-11-03 19:18:17,906] [val] [Epoch 186] [Loss 0.331] [Acc 92.490]\n",
            "\n",
            "Epoch: 187\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 52s356ms | Loss: 0.050 | Acc: 99.282% (49641/50000) | Cls: 0.098  391/391 \n",
            "[2022-11-03 19:19:11,019] [train] [Epoch 187] [Loss 0.050] [cls 0.098] [Acc 99.282]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s612ms | Loss: 0.337 | Acc: 92.420% (9242/10000)  79/79 \n",
            "[2022-11-03 19:19:14,125] [val] [Epoch 187] [Loss 0.337] [Acc 92.420]\n",
            "\n",
            "Epoch: 188\n",
            " [=====================================================================================>]  Step: 124ms | Tot: 51s626ms | Loss: 0.049 | Acc: 99.292% (49646/50000) | Cls: 0.096  391/391 \n",
            "[2022-11-03 19:20:06,575] [train] [Epoch 188] [Loss 0.049] [cls 0.096] [Acc 99.292]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s615ms | Loss: 0.334 | Acc: 92.550% (9255/10000)  79/79 \n",
            "[2022-11-03 19:20:09,712] [val] [Epoch 188] [Loss 0.334] [Acc 92.550]\n",
            "\n",
            "Epoch: 189\n",
            " [=====================================================================================>]  Step: 127ms | Tot: 51s601ms | Loss: 0.050 | Acc: 99.256% (49628/50000) | Cls: 0.097  391/391 \n",
            "[2022-11-03 19:21:02,120] [train] [Epoch 189] [Loss 0.050] [cls 0.097] [Acc 99.256]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s704ms | Loss: 0.334 | Acc: 92.500% (9250/10000)  79/79 \n",
            "[2022-11-03 19:21:05,267] [val] [Epoch 189] [Loss 0.334] [Acc 92.500]\n",
            "\n",
            "Epoch: 190\n",
            " [=====================================================================================>]  Step: 124ms | Tot: 51s658ms | Loss: 0.049 | Acc: 99.340% (49670/50000) | Cls: 0.095  391/391 \n",
            "[2022-11-03 19:21:57,737] [train] [Epoch 190] [Loss 0.049] [cls 0.095] [Acc 99.340]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s735ms | Loss: 0.332 | Acc: 92.340% (9234/10000)  79/79 \n",
            "[2022-11-03 19:22:00,912] [val] [Epoch 190] [Loss 0.332] [Acc 92.340]\n",
            "\n",
            "Epoch: 191\n",
            " [=====================================================================================>]  Step: 130ms | Tot: 53s110ms | Loss: 0.050 | Acc: 99.286% (49643/50000) | Cls: 0.096  391/391 \n",
            "[2022-11-03 19:22:54,953] [train] [Epoch 191] [Loss 0.050] [cls 0.096] [Acc 99.286]\n",
            " [====================================================================================>.]  Step: 10ms | Tot: 4s302ms | Loss: 0.333 | Acc: 92.380% (9238/10000)  79/79 \n",
            "[2022-11-03 19:23:00,091] [val] [Epoch 191] [Loss 0.333] [Acc 92.380]\n",
            "\n",
            "Epoch: 192\n",
            " [=====================================================================================>]  Step: 126ms | Tot: 51s785ms | Loss: 0.049 | Acc: 99.282% (49641/50000) | Cls: 0.094  391/391 \n",
            "[2022-11-03 19:23:53,233] [train] [Epoch 192] [Loss 0.049] [cls 0.094] [Acc 99.282]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s783ms | Loss: 0.337 | Acc: 92.380% (9238/10000)  79/79 \n",
            "[2022-11-03 19:23:56,444] [val] [Epoch 192] [Loss 0.337] [Acc 92.380]\n",
            "\n",
            "Epoch: 193\n",
            " [=====================================================================================>]  Step: 129ms | Tot: 51s693ms | Loss: 0.049 | Acc: 99.290% (49645/50000) | Cls: 0.094  391/391 \n",
            "[2022-11-03 19:24:48,963] [train] [Epoch 193] [Loss 0.049] [cls 0.094] [Acc 99.290]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s625ms | Loss: 0.338 | Acc: 92.390% (9239/10000)  79/79 \n",
            "[2022-11-03 19:24:52,128] [val] [Epoch 193] [Loss 0.338] [Acc 92.390]\n",
            "\n",
            "Epoch: 194\n",
            " [=====================================================================================>]  Step: 126ms | Tot: 52s168ms | Loss: 0.047 | Acc: 99.324% (49662/50000) | Cls: 0.094  391/391 \n",
            "[2022-11-03 19:25:45,142] [train] [Epoch 194] [Loss 0.047] [cls 0.094] [Acc 99.324]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s657ms | Loss: 0.337 | Acc: 92.340% (9234/10000)  79/79 \n",
            "[2022-11-03 19:25:48,237] [val] [Epoch 194] [Loss 0.337] [Acc 92.340]\n",
            "\n",
            "Epoch: 195\n",
            " [=====================================================================================>]  Step: 126ms | Tot: 52s316ms | Loss: 0.049 | Acc: 99.298% (49649/50000) | Cls: 0.096  391/391 \n",
            "[2022-11-03 19:26:41,418] [train] [Epoch 195] [Loss 0.049] [cls 0.096] [Acc 99.298]\n",
            " [====================================================================================>.]  Step: 10ms | Tot: 2s683ms | Loss: 0.338 | Acc: 92.330% (9233/10000)  79/79 \n",
            "[2022-11-03 19:26:44,562] [val] [Epoch 195] [Loss 0.338] [Acc 92.330]\n",
            "\n",
            "Epoch: 196\n",
            " [=====================================================================================>]  Step: 126ms | Tot: 51s703ms | Loss: 0.049 | Acc: 99.312% (49656/50000) | Cls: 0.095  391/391 \n",
            "[2022-11-03 19:27:37,096] [train] [Epoch 196] [Loss 0.049] [cls 0.095] [Acc 99.312]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s697ms | Loss: 0.337 | Acc: 92.380% (9238/10000)  79/79 \n",
            "[2022-11-03 19:27:40,248] [val] [Epoch 196] [Loss 0.337] [Acc 92.380]\n",
            "\n",
            "Epoch: 197\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 53s612ms | Loss: 0.047 | Acc: 99.366% (49683/50000) | Cls: 0.094  391/391 \n",
            "[2022-11-03 19:28:34,698] [train] [Epoch 197] [Loss 0.047] [cls 0.094] [Acc 99.366]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s639ms | Loss: 0.337 | Acc: 92.410% (9241/10000)  79/79 \n",
            "[2022-11-03 19:28:37,843] [val] [Epoch 197] [Loss 0.337] [Acc 92.410]\n",
            "\n",
            "Epoch: 198\n",
            " [=====================================================================================>]  Step: 130ms | Tot: 52s377ms | Loss: 0.047 | Acc: 99.382% (49691/50000) | Cls: 0.092  391/391 \n",
            "[2022-11-03 19:29:31,056] [train] [Epoch 198] [Loss 0.047] [cls 0.092] [Acc 99.382]\n",
            " [====================================================================================>.]  Step: 10ms | Tot: 2s657ms | Loss: 0.336 | Acc: 92.440% (9244/10000)  79/79 \n",
            "[2022-11-03 19:29:34,257] [val] [Epoch 198] [Loss 0.336] [Acc 92.440]\n",
            "\n",
            "Epoch: 199\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 52s501ms | Loss: 0.047 | Acc: 99.328% (49664/50000) | Cls: 0.094  391/391 \n",
            "[2022-11-03 19:30:27,543] [train] [Epoch 199] [Loss 0.047] [cls 0.094] [Acc 99.328]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s759ms | Loss: 0.337 | Acc: 92.500% (9250/10000)  79/79 \n",
            "[2022-11-03 19:30:30,720] [val] [Epoch 199] [Loss 0.337] [Acc 92.500]\n",
            "Best Accuracy : 92.62000274658203\n",
            "[2022-11-03 19:30:30,720] [best] [Acc 92.620]\n"
          ]
        }
      ],
      "source": [
        "!python Learning-With-Retrospection/CS-KD_techinque/cs-kd/train.py --resume --sgpu 0 --lr 0.1 --epoch 200 --model CIFAR10_VGG16 --name cifar10_vgg16 --decay 1e-4 --dataset cifar10 --dataroot ~/data/ -cls --lamda 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2C6ngE_0_BxJ"
      },
      "source": [
        "## CIFAR100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiodQjj2_G1x",
        "outputId": "4f13abd2-598b-48ca-d20c-e05a3ac6ad91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==> Preparing dataset: cifar100\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Number of train dataset:  50000\n",
            "Number of validation dataset:  10000\n",
            "==> Building model: CIFAR100_VGG16\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\" to /root/.cache/torch/hub/checkpoints/vgg16_bn-6c64b313.pth\n",
            "100% 528M/528M [00:01<00:00, 283MB/s]\n",
            "1\n",
            "Using CUDA..\n",
            "\"./results/cifar100/CIFAR100_VGG16/TESTcifar100_vgg16\" exists. Overwrite [Y/n]? Y\n",
            "[2022-11-06 15:31:48,360] [main] Learning-With-Retrospection/CS-KD_techinque/cs-kd/train.py --sgpu 0 --lr 0.1 --epoch 200 --model CIFAR100_VGG16 --name TESTcifar100_vgg16 --decay 1e-4 --dataset cifar100 --dataroot /root/data/ -cls --lamda 1\n",
            "[2022-11-06 15:31:48,361] [main] Namespace(batch_size=128, cls=True, dataroot='/root/data/', dataset='cifar100', decay=0.0001, epoch=200, lamda=1.0, lr=0.1, model='CIFAR100_VGG16', name='TESTcifar100_vgg16', ngpu=1, resume=False, saveroot='./results', sgpu=0, temp=4.0)\n",
            "\n",
            "Epoch: 0\n",
            " [=====================================================================================>]  Step: 754ms | Tot: 51s62ms | Loss: 3.760 | Acc: 11.344% (5672/50000) | Cls: 0.334  391/391 \n",
            "[2022-11-06 15:32:43,325] [train] [Epoch 0] [Loss 3.760] [cls 0.334] [Acc 11.344]\n",
            " [====================================================================================>.]  Step: 118ms | Tot: 2s478ms | Loss: 3.472 | Acc: 16.050% (1605/10000)  79/79 \n",
            "[2022-11-06 15:32:46,190] [val] [Epoch 0] [Loss 3.472] [Acc 16.050]\n",
            "Saving..\n",
            "\n",
            "Epoch: 1\n",
            " [=====================================================================================>]  Step: 123ms | Tot: 50s39ms | Loss: 3.184 | Acc: 20.644% (10322/50000) | Cls: 0.472  391/391 \n",
            "[2022-11-06 15:33:41,823] [train] [Epoch 1] [Loss 3.184] [cls 0.472] [Acc 20.644]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s511ms | Loss: 3.073 | Acc: 22.710% (2271/10000)  79/79 \n",
            "[2022-11-06 15:33:44,709] [val] [Epoch 1] [Loss 3.073] [Acc 22.710]\n",
            "Saving..\n",
            "\n",
            "Epoch: 2\n",
            " [=====================================================================================>]  Step: 122ms | Tot: 50s80ms | Loss: 2.910 | Acc: 26.628% (13314/50000) | Cls: 0.521  391/391 \n",
            "[2022-11-06 15:34:39,986] [train] [Epoch 2] [Loss 2.910] [cls 0.521] [Acc 26.628]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s420ms | Loss: 2.889 | Acc: 29.590% (2959/10000)  79/79 \n",
            "[2022-11-06 15:34:42,863] [val] [Epoch 2] [Loss 2.889] [Acc 29.590]\n",
            "Saving..\n",
            "\n",
            "Epoch: 3\n",
            " [=====================================================================================>]  Step: 123ms | Tot: 50s169ms | Loss: 2.713 | Acc: 31.640% (15820/50000) | Cls: 0.548  391/391 \n",
            "[2022-11-06 15:35:38,158] [train] [Epoch 3] [Loss 2.713] [cls 0.548] [Acc 31.640]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s402ms | Loss: 2.462 | Acc: 36.530% (3653/10000)  79/79 \n",
            "[2022-11-06 15:35:41,048] [val] [Epoch 3] [Loss 2.462] [Acc 36.530]\n",
            "Saving..\n",
            "\n",
            "Epoch: 4\n",
            " [=====================================================================================>]  Step: 123ms | Tot: 50s97ms | Loss: 2.582 | Acc: 35.002% (17501/50000) | Cls: 0.560  391/391 \n",
            "[2022-11-06 15:36:36,262] [train] [Epoch 4] [Loss 2.582] [cls 0.560] [Acc 35.002]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s493ms | Loss: 2.660 | Acc: 34.820% (3482/10000)  79/79 \n",
            "[2022-11-06 15:36:39,173] [val] [Epoch 4] [Loss 2.660] [Acc 34.820]\n",
            "\n",
            "Epoch: 5\n",
            " [=====================================================================================>]  Step: 122ms | Tot: 49s971ms | Loss: 2.519 | Acc: 36.954% (18477/50000) | Cls: 0.562  391/391 \n",
            "[2022-11-06 15:37:29,871] [train] [Epoch 5] [Loss 2.519] [cls 0.562] [Acc 36.954]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s417ms | Loss: 3.030 | Acc: 29.210% (2921/10000)  79/79 \n",
            "[2022-11-06 15:37:32,715] [val] [Epoch 5] [Loss 3.030] [Acc 29.210]\n",
            "\n",
            "Epoch: 6\n",
            " [=====================================================================================>]  Step: 124ms | Tot: 50s31ms | Loss: 2.404 | Acc: 39.680% (19840/50000) | Cls: 0.574  391/391 \n",
            "[2022-11-06 15:38:23,398] [train] [Epoch 6] [Loss 2.404] [cls 0.574] [Acc 39.680]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s411ms | Loss: 2.164 | Acc: 44.360% (4436/10000)  79/79 \n",
            "[2022-11-06 15:38:26,226] [val] [Epoch 6] [Loss 2.164] [Acc 44.360]\n",
            "Saving..\n",
            "\n",
            "Epoch: 7\n",
            " [=====================================================================================>]  Step: 122ms | Tot: 50s139ms | Loss: 2.330 | Acc: 41.424% (20712/50000) | Cls: 0.587  391/391 \n",
            "[2022-11-06 15:39:21,545] [train] [Epoch 7] [Loss 2.330] [cls 0.587] [Acc 41.424]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s480ms | Loss: 2.330 | Acc: 42.330% (4233/10000)  79/79 \n",
            "[2022-11-06 15:39:24,387] [val] [Epoch 7] [Loss 2.330] [Acc 42.330]\n",
            "\n",
            "Epoch: 8\n",
            " [=====================================================================================>]  Step: 121ms | Tot: 49s991ms | Loss: 2.283 | Acc: 43.000% (21500/50000) | Cls: 0.576  391/391 \n",
            "[2022-11-06 15:40:15,120] [train] [Epoch 8] [Loss 2.283] [cls 0.576] [Acc 43.000]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s453ms | Loss: 2.286 | Acc: 44.490% (4449/10000)  79/79 \n",
            "[2022-11-06 15:40:18,011] [val] [Epoch 8] [Loss 2.286] [Acc 44.490]\n",
            "Saving..\n",
            "\n",
            "Epoch: 9\n",
            " [=====================================================================================>]  Step: 123ms | Tot: 50s94ms | Loss: 2.187 | Acc: 45.174% (22587/50000) | Cls: 0.590  391/391 \n",
            "[2022-11-06 15:41:13,371] [train] [Epoch 9] [Loss 2.187] [cls 0.590] [Acc 45.174]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s406ms | Loss: 2.228 | Acc: 44.240% (4424/10000)  79/79 \n",
            "[2022-11-06 15:41:16,260] [val] [Epoch 9] [Loss 2.228] [Acc 44.240]\n",
            "\n",
            "Epoch: 10\n",
            " [=====================================================================================>]  Step: 123ms | Tot: 50s25ms | Loss: 2.161 | Acc: 46.236% (23118/50000) | Cls: 0.586  391/391 \n",
            "[2022-11-06 15:42:07,003] [train] [Epoch 10] [Loss 2.161] [cls 0.586] [Acc 46.236]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s494ms | Loss: 2.118 | Acc: 47.230% (4723/10000)  79/79 \n",
            "[2022-11-06 15:42:09,896] [val] [Epoch 10] [Loss 2.118] [Acc 47.230]\n",
            "Saving..\n",
            "\n",
            "Epoch: 11\n",
            " [=====================================================================================>]  Step: 123ms | Tot: 50s140ms | Loss: 3.000 | Acc: 30.158% (15079/50000) | Cls: 0.442  391/391 \n",
            "[2022-11-06 15:43:05,182] [train] [Epoch 11] [Loss 3.000] [cls 0.442] [Acc 30.158]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s493ms | Loss: 3.861 | Acc: 14.540% (1454/10000)  79/79 \n",
            "[2022-11-06 15:43:08,065] [val] [Epoch 11] [Loss 3.861] [Acc 14.540]\n",
            "\n",
            "Epoch: 12\n",
            " [=====================================================================================>]  Step: 123ms | Tot: 49s946ms | Loss: 3.114 | Acc: 26.200% (13100/50000) | Cls: 0.495  391/391 \n",
            "[2022-11-06 15:43:58,757] [train] [Epoch 12] [Loss 3.114] [cls 0.495] [Acc 26.200]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s444ms | Loss: 2.550 | Acc: 37.500% (3750/10000)  79/79 \n",
            "[2022-11-06 15:44:01,672] [val] [Epoch 12] [Loss 2.550] [Acc 37.500]\n",
            "\n",
            "Epoch: 13\n",
            " [=====================================================================================>]  Step: 121ms | Tot: 50s77ms | Loss: 2.389 | Acc: 41.336% (20668/50000) | Cls: 0.583  391/391 \n",
            "[2022-11-06 15:44:52,458] [train] [Epoch 13] [Loss 2.389] [cls 0.583] [Acc 41.336]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s477ms | Loss: 2.384 | Acc: 42.860% (4286/10000)  79/79 \n",
            "[2022-11-06 15:44:55,323] [val] [Epoch 13] [Loss 2.384] [Acc 42.860]\n",
            "\n",
            "Epoch: 14\n",
            " [=====================================================================================>]  Step: 122ms | Tot: 50s18ms | Loss: 2.209 | Acc: 45.486% (22743/50000) | Cls: 0.596  391/391 \n",
            "[2022-11-06 15:45:45,969] [train] [Epoch 14] [Loss 2.209] [cls 0.596] [Acc 45.486]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s466ms | Loss: 2.409 | Acc: 42.980% (4298/10000)  79/79 \n",
            "[2022-11-06 15:45:48,867] [val] [Epoch 14] [Loss 2.409] [Acc 42.980]\n",
            "\n",
            "Epoch: 15\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 49s995ms | Loss: 2.170 | Acc: 46.556% (23278/50000) | Cls: 0.594  391/391 \n",
            "[2022-11-06 15:46:39,519] [train] [Epoch 15] [Loss 2.170] [cls 0.594] [Acc 46.556]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s416ms | Loss: 2.201 | Acc: 47.710% (4771/10000)  79/79 \n",
            "[2022-11-06 15:46:42,387] [val] [Epoch 15] [Loss 2.201] [Acc 47.710]\n",
            "Saving..\n",
            "\n",
            "Epoch: 16\n",
            " [=====================================================================================>]  Step: 122ms | Tot: 50s70ms | Loss: 2.062 | Acc: 49.090% (24545/50000) | Cls: 0.593  391/391 \n",
            "[2022-11-06 15:47:37,732] [train] [Epoch 16] [Loss 2.062] [cls 0.593] [Acc 49.090]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s451ms | Loss: 2.092 | Acc: 48.750% (4875/10000)  79/79 \n",
            "[2022-11-06 15:47:40,585] [val] [Epoch 16] [Loss 2.092] [Acc 48.750]\n",
            "Saving..\n",
            "\n",
            "Epoch: 17\n",
            " [=====================================================================================>]  Step: 126ms | Tot: 50s80ms | Loss: 2.021 | Acc: 50.626% (25313/50000) | Cls: 0.586  391/391 \n",
            "[2022-11-06 15:48:35,980] [train] [Epoch 17] [Loss 2.021] [cls 0.586] [Acc 50.626]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s399ms | Loss: 2.068 | Acc: 49.460% (4946/10000)  79/79 \n",
            "[2022-11-06 15:48:38,815] [val] [Epoch 17] [Loss 2.068] [Acc 49.460]\n",
            "Saving..\n",
            "\n",
            "Epoch: 18\n",
            " [=====================================================================================>]  Step: 125ms | Tot: 50s92ms | Loss: 1.999 | Acc: 51.050% (25525/50000) | Cls: 0.592  391/391 \n",
            "[2022-11-06 15:49:34,211] [train] [Epoch 18] [Loss 1.999] [cls 0.592] [Acc 51.050]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s401ms | Loss: 2.027 | Acc: 50.860% (5086/10000)  79/79 \n",
            "[2022-11-06 15:49:37,056] [val] [Epoch 18] [Loss 2.027] [Acc 50.860]\n",
            "Saving..\n",
            "\n",
            "Epoch: 19\n",
            " [=====================================================================================>]  Step: 120ms | Tot: 50s12ms | Loss: 1.941 | Acc: 52.370% (26185/50000) | Cls: 0.585  391/391 \n",
            "[2022-11-06 15:50:32,572] [train] [Epoch 19] [Loss 1.941] [cls 0.585] [Acc 52.370]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s507ms | Loss: 2.007 | Acc: 52.400% (5240/10000)  79/79 \n",
            "[2022-11-06 15:50:35,484] [val] [Epoch 19] [Loss 2.007] [Acc 52.400]\n",
            "Saving..\n",
            "\n",
            "Epoch: 20\n",
            " [=====================================================================================>]  Step: 122ms | Tot: 49s972ms | Loss: 1.896 | Acc: 53.556% (26778/50000) | Cls: 0.593  391/391 \n",
            "[2022-11-06 15:51:30,814] [train] [Epoch 20] [Loss 1.896] [cls 0.593] [Acc 53.556]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s464ms | Loss: 2.009 | Acc: 51.450% (5145/10000)  79/79 \n",
            "[2022-11-06 15:51:33,683] [val] [Epoch 20] [Loss 2.009] [Acc 51.450]\n",
            "\n",
            "Epoch: 21\n",
            " [=====================================================================================>]  Step: 124ms | Tot: 49s904ms | Loss: 1.874 | Acc: 54.340% (27170/50000) | Cls: 0.575  391/391 \n",
            "[2022-11-06 15:52:24,327] [train] [Epoch 21] [Loss 1.874] [cls 0.575] [Acc 54.340]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s493ms | Loss: 2.221 | Acc: 47.540% (4754/10000)  79/79 \n",
            "[2022-11-06 15:52:27,199] [val] [Epoch 21] [Loss 2.221] [Acc 47.540]\n",
            "\n",
            "Epoch: 22\n",
            " [=====================================================================================>]  Step: 123ms | Tot: 49s986ms | Loss: 1.953 | Acc: 52.564% (26282/50000) | Cls: 0.597  391/391 \n",
            "[2022-11-06 15:53:17,875] [train] [Epoch 22] [Loss 1.953] [cls 0.597] [Acc 52.564]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s422ms | Loss: 2.130 | Acc: 49.020% (4902/10000)  79/79 \n",
            "[2022-11-06 15:53:20,788] [val] [Epoch 22] [Loss 2.130] [Acc 49.020]\n",
            "\n",
            "Epoch: 23\n",
            " [=====================================================================================>]  Step: 122ms | Tot: 49s957ms | Loss: 1.851 | Acc: 54.832% (27416/50000) | Cls: 0.589  391/391 \n",
            "[2022-11-06 15:54:11,501] [train] [Epoch 23] [Loss 1.851] [cls 0.589] [Acc 54.832]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s473ms | Loss: 2.043 | Acc: 52.400% (5240/10000)  79/79 \n",
            "[2022-11-06 15:54:14,425] [val] [Epoch 23] [Loss 2.043] [Acc 52.400]\n",
            "\n",
            "Epoch: 24\n",
            " [=====================================================================================>]  Step: 127ms | Tot: 49s972ms | Loss: 2.268 | Acc: 46.728% (23364/50000) | Cls: 0.513  391/391 \n",
            "[2022-11-06 15:55:05,181] [train] [Epoch 24] [Loss 2.268] [cls 0.513] [Acc 46.728]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s418ms | Loss: 3.922 | Acc: 10.800% (1080/10000)  79/79 \n",
            "[2022-11-06 15:55:07,993] [val] [Epoch 24] [Loss 3.922] [Acc 10.800]\n",
            "\n",
            "Epoch: 25\n",
            " [=====================================================================================>]  Step: 122ms | Tot: 49s890ms | Loss: 3.249 | Acc: 21.336% (10668/50000) | Cls: 0.468  391/391 \n",
            "[2022-11-06 15:55:58,638] [train] [Epoch 25] [Loss 3.249] [cls 0.468] [Acc 21.336]\n",
            " [====================================================================================>.]  Step: 8ms | Tot: 2s469ms | Loss: 2.657 | Acc: 33.860% (3386/10000)  79/79 \n",
            "[2022-11-06 15:56:01,511] [val] [Epoch 25] [Loss 2.657] [Acc 33.860]\n",
            "\n",
            "Epoch: 26\n",
            " [=====================================================================================>]  Step: 123ms | Tot: 50s1ms | Loss: 2.350 | Acc: 41.124% (20562/50000) | Cls: 0.613  391/391 \n",
            "[2022-11-06 15:56:52,120] [train] [Epoch 26] [Loss 2.350] [cls 0.613] [Acc 41.124]\n",
            " [====================================================================================>.]  Step: 9ms | Tot: 2s455ms | Loss: 2.184 | Acc: 44.890% (4489/10000)  79/79 \n",
            "[2022-11-06 15:56:55,006] [val] [Epoch 26] [Loss 2.184] [Acc 44.890]\n",
            "\n",
            "Epoch: 27\n"
          ]
        }
      ],
      "source": [
        "!python Learning-With-Retrospection/CS-KD_techinque/cs-kd/train.py --sgpu 0 --lr 0.1 --epoch 200 --model CIFAR100_VGG16 --name TESTcifar100_vgg16 --decay 1e-4 --dataset cifar100 --dataroot ~/data/ -cls --lamda 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPG6auWv--kk"
      },
      "source": [
        "# Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yU0dJsUehiDF",
        "outputId": "11b92fed-fdda-419d-94cd-201e40d35c84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6X6OH-fQh5N0"
      },
      "outputs": [],
      "source": [
        "# !cp -r results drive/MyDrive/CS747/project/results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_cEJHz6dEQv"
      },
      "outputs": [],
      "source": [
        "# !cp -r drive/MyDrive/CS747/project/results ."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "k36nunYh_WNW",
        "2fIgjp4gbHjj",
        "2C6ngE_0_BxJ"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
